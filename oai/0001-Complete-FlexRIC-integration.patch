From 93b31b6eca4bc9d942f070cc66cb625604d873e7 Mon Sep 17 00:00:00 2001
From: Robert Schmidt <robert.schmidt@eurecom.fr>
Date: Wed, 2 Jun 2021 14:49:46 +0200
Subject: [PATCH] Complete FlexRIC integration

---
 cmake_targets/CMakeLists.txt                  |  53 +-
 cmake_targets/build_oai                       |   2 +
 cmake_targets/tools/MODULES/FindFlatCC.cmake  |  28 +
 doc/SW_archi.md                               |   2 +-
 executables/nr-softmodem.c                    |   7 +
 openair1/PHY/NR_TRANSPORT/nr_dlsch.c          |   2 +-
 openair1/PHY/defs_common.h                    |   3 +-
 openair2/COMMON/platform_constants.h          |   2 +-
 .../MAC/flexran_agent_mac_internal.c          |  11 +-
 .../ENB_APP/MESSAGES/V2/config_common.proto   |  31 +
 openair2/ENB_APP/enb_config.c                 |   5 +-
 openair2/ENB_APP/flexran_agent_ran_api.c      | 144 ++-
 openair2/ENB_APP/flexric_agent.c              | 801 ++++++++++++++++
 openair2/GNB_APP/flexric_agent_nsa.c          | 770 +++++++++++++++
 openair2/GNB_APP/gnb_config.c                 |   1 +
 openair2/LAYER2/MAC/eNB_scheduler_dlsch.c     |  18 +-
 openair2/LAYER2/MAC/mac.h                     |   2 +
 openair2/LAYER2/MAC/slicing/slicing.c         | 907 +++++++++++++++++-
 openair2/LAYER2/MAC/slicing/slicing.h         |  29 +
 openair2/LAYER2/MAC/ue_procedures.c           |   3 +-
 openair2/LAYER2/NR_MAC_gNB/config.c           |   2 +-
 openair2/LAYER2/NR_MAC_gNB/gNB_scheduler.c    | 135 +++
 .../LAYER2/NR_MAC_gNB/gNB_scheduler_dlsch.c   |  95 +-
 .../NR_MAC_gNB/gNB_scheduler_primitives.c     |   6 +
 .../LAYER2/NR_MAC_gNB/gNB_scheduler_uci.c     |  14 +-
 .../LAYER2/NR_MAC_gNB/gNB_scheduler_ulsch.c   |  14 +-
 openair2/LAYER2/NR_MAC_gNB/mac_proto.h        |   2 +-
 openair2/LAYER2/NR_MAC_gNB/main.c             |   3 +-
 openair2/LAYER2/NR_MAC_gNB/nr_mac_gNB.h       |  57 +-
 .../LAYER2/NR_MAC_gNB/slicing/nr_slicing.c    | 483 ++++++++++
 .../LAYER2/NR_MAC_gNB/slicing/nr_slicing.h    |  74 ++
 .../NR_MAC_gNB/slicing/nr_slicing_internal.h  |  46 +
 openair2/LAYER2/PDCP_v10.1.0/pdcp.c           | 117 ++-
 openair2/LAYER2/PDCP_v10.1.0/pdcp.h           |  10 +-
 openair2/LAYER2/nr_pdcp/nr_pdcp_entity.c      |  37 +
 openair2/LAYER2/nr_pdcp/nr_pdcp_entity.h      |  32 +
 openair2/LAYER2/nr_pdcp/nr_pdcp_oai_api.c     |  38 +
 openair2/LAYER2/nr_rlc/nr_rlc_entity.c        |  16 +
 openair2/LAYER2/nr_rlc/nr_rlc_entity.h        |  53 +
 openair2/LAYER2/nr_rlc/nr_rlc_entity_am.c     |  54 +-
 openair2/LAYER2/nr_rlc/nr_rlc_entity_tm.c     |  17 +
 openair2/LAYER2/nr_rlc/nr_rlc_entity_um.c     |  41 +
 openair2/LAYER2/nr_rlc/nr_rlc_oai_api.c       |  36 +
 openair2/PHY_INTERFACE/phy_stub_UE.c          |  12 +-
 openair2/RRC/LTE/L2_interface_ue.c            |  67 +-
 openair2/RRC/LTE/MESSAGES/asn1_msg.c          |   2 +-
 openair2/RRC/LTE/rrc_UE.c                     |   1 +
 openair2/RRC/LTE/rrc_eNB.c                    |  61 +-
 openair2/RRC/NR/nr_rrc_defs.h                 |   3 +
 openair2/RRC/NR/rrc_gNB.c                     |   1 +
 openair2/RRC/NR/rrc_gNB_reconfig.c            |  18 +-
 openair3/UTILS/mme_default_values.h           |   2 +-
 targets/COMMON/openairinterface5g_limits.h    |   2 +-
 targets/RT/USER/lte-softmodem.c               |   6 +
 targets/RT/USER/lte-ue.c                      |  53 +
 55 files changed, 4268 insertions(+), 163 deletions(-)
 create mode 100644 cmake_targets/tools/MODULES/FindFlatCC.cmake
 create mode 100644 openair2/ENB_APP/flexric_agent.c
 create mode 100644 openair2/GNB_APP/flexric_agent_nsa.c
 create mode 100644 openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.c
 create mode 100644 openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.h
 create mode 100644 openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing_internal.h

diff --git a/cmake_targets/CMakeLists.txt b/cmake_targets/CMakeLists.txt
index 8d8e88455a..721fd3899f 100644
--- a/cmake_targets/CMakeLists.txt
+++ b/cmake_targets/CMakeLists.txt
@@ -156,6 +156,8 @@ set (OPENAIR_BIN_DIR ${CMAKE_CURRENT_BINARY_DIR}${CMAKE_FILES_DIRECTORY})
 project (OpenAirInterface)
 
 
+list(APPEND CMAKE_MODULE_PATH ${OPENAIR_DIR}/cmake_targets/tools/MODULES)
+message(STATUS ${CMAKE_MODULE_PATH})
 
 ##############################################
 # Base CUDA setting
@@ -1308,6 +1310,40 @@ add_custom_target(flapp_all DEPENDS
 )
 #include_directories(${OPENAIR2_DIR}/ENB_APP)
 
+set(FlatCC_HINT_INCLUDE_DIR "~/flatcc/include/")
+set(FlatCC_LIBRARY_DIR "~/flatcc/lib/")
+find_package(FlatCC REQUIRED)
+find_package(FlexricAgent 0.2.2 EXACT REQUIRED)
+if(FlexricAgent_FOUND)
+  message(STATUS "Found FlexricAgent library")
+  add_library(flexric_agent ${OPENAIR2_DIR}/ENB_APP/flexric_agent.c)
+  target_link_libraries(flexric_agent
+                        PUBLIC
+                          Flexric::flexric_agent
+                          Flexric::fb_mac_stats_rf
+                          Flexric::fb_rslicing_rf
+                          Flexric::fb_rlc_stats_rf
+                          Flexric::fb_pdcp_stats_rf
+                          Flexric::fb_rrc_stats_rf
+                          Flexric::fb_rrc_conf_rf
+                          Flexric::fb_rrc_event_rf)
+  add_library(flexric_agent_nsa ${OPENAIR2_DIR}/GNB_APP/flexric_agent_nsa.c)
+  target_link_libraries(flexric_agent_nsa
+                        PUBLIC
+                          Flexric::flexric_agent
+                          Flexric::fb_mac_stats_rf
+                          Flexric::fb_rslicing_rf
+                          Flexric::fb_rlc_stats_rf
+                          Flexric::fb_pdcp_stats_rf
+                          Flexric::fb_rrc_stats_rf
+                          Flexric::fb_rrc_conf_rf
+                          Flexric::fb_rrc_event_rf
+                          L2_NR) # need to link L2_NR or doesn't find nr_nvs_dl_init()?
+  add_definitions(-DUSE_FLEXRIC)
+else()
+  message(WARNING "FlexricAgent library not present, not building agent")
+endif()
+
 set(PROTOBUF_LIB "protobuf-c")
 
 FIND_PATH(LIBYAML_INCLUDE_DIR NAMES yaml.h)
@@ -2126,6 +2162,7 @@ set (MAC_NR_SRC
   ${NR_GNB_MAC_DIR}/gNB_scheduler_phytest.c
   ${NR_GNB_MAC_DIR}/gNB_scheduler_uci.c
   ${NR_GNB_MAC_DIR}/gNB_scheduler_RA.c
+  ${NR_GNB_MAC_DIR}/slicing/nr_slicing.c
  )
 
 
@@ -2192,6 +2229,9 @@ add_library(L2
   ${MCE_APP_SRC}
   )
 add_dependencies(L2 rrc_flag s1ap_flag x2_flag m2_flag m3_flag)
+if(FlexricAgent_FOUND)
+  target_link_libraries(L2 Flexric::fb_rrc_stats_rf Flexric::fb_rrc_event_rf)
+endif()
 
 add_library(MAC_NR
   ${MAC_NR_SRC}
@@ -2217,6 +2257,9 @@ add_library(L2_LTE_NR
   ${ENB_APP_SRC}
   ${MCE_APP_SRC}
 )
+if(FlexricAgent_FOUND)
+  target_link_libraries(L2_LTE_NR Flexric::fb_rrc_stats_rf Flexric::fb_rrc_event_rf)
+endif()
   
 add_dependencies(L2_NR rrc_flag nr_rrc_flag s1ap_flag x2_flag)
 
@@ -2833,7 +2876,6 @@ target_link_libraries(rfsimulator SIMU_COMMON ${ATLAS_LIBRARIES})
 add_library(oai_iqplayer MODULE 
 	${OPENAIR_TARGETS}/ARCH/iqplayer/iqplayer_lib.c
 	)
-set(CMAKE_MODULE_PATH "${OPENAIR_DIR}/cmake_targets/tools/MODULES" "${CMAKE_MODULE_PATH}")
 
 #include T directory even if the T is off because T macros are in the code
 #no matter what
@@ -2947,6 +2989,9 @@ target_link_libraries (lte-softmodem
   PHY_COMMON PHY PHY_RU LFDS L2 L2_LTE NFAPI_COMMON_LIB NFAPI_LIB NFAPI_VNF_LIB NFAPI_PNF_LIB NFAPI_USER_LIB MISC_NFAPI_LTE_LIB LFDS7
   ${MSC_LIB} ${RAL_LIB} ${NAS_UE_LIB} ${ITTI_LIB} ${FLPT_MSG_LIB} ${ASYNC_IF_LIB} ${FLEXRAN_AGENT_LIB} ${FSPT_MSG_LIB} ${PROTO_AGENT_LIB}
   -Wl,--end-group z dl)
+if(FlexricAgent_FOUND)
+  target_link_libraries(lte-softmodem flexric_agent)
+endif()
   
 target_link_libraries (lte-softmodem ${LIBXML2_LIBRARIES})
 target_link_libraries (lte-softmodem pthread m ${CONFIG_LIB} rt crypt ${CRYPTO_LIBRARIES} ${OPENSSL_LIBRARIES} sctp ${PROTOBUF_LIB}  ${CMAKE_DL_LIBS} ${LIBYAML_LIBRARIES})
@@ -3131,6 +3176,12 @@ target_link_libraries (nr-softmodem
   NGAP_LIB NGAP_GNB S1AP_LIB S1AP_ENB L2_LTE_NR L2_NR MAC_NR_COMMON NFAPI_COMMON_LIB NFAPI_LIB NFAPI_VNF_LIB NFAPI_PNF_LIB NFAPI_USER_LIB
   X2AP_LIB X2AP_ENB F1AP_LIB F1AP M2AP_LIB M2AP_ENB M3AP_LIB M3AP_ENB ${PROTO_AGENT_LIB} ${FSPT_MSG_LIB}
   -Wl,--end-group z dl)
+if(FlexricAgent_FOUND)
+  # for reasons I don't comprehend, RRC_LIB is linked into nr-softmodem. Hence,
+  # we also need flexric_agent because otherwise there are undefined references
+  # that the linker can't resolve
+  target_link_libraries(nr-softmodem flexric_agent_nsa flexric_agent)
+endif()
 
 target_link_libraries (nr-softmodem ${LIBXML2_LIBRARIES})
 target_link_libraries (nr-softmodem pthread m ${CONFIG_LIB} rt crypt ${CRYPTO_LIBRARIES} ${OPENSSL_LIBRARIES} sctp  ${XFORMS_LIBRARIES} ${PROTOBUF_LIB}  ${CMAKE_DL_LIBS} ${LIBYAML_LIBRARIES} ${ATLAS_LIBRARIES})
diff --git a/cmake_targets/build_oai b/cmake_targets/build_oai
index 279b9489e0..33f161a6c3 100755
--- a/cmake_targets/build_oai
+++ b/cmake_targets/build_oai
@@ -633,6 +633,8 @@ function main() {
     echo "set ( SANITIZE_ADDRESS $SANITIZE_ADDRESS )"                     >> $cmake_file
     echo 'include(${CMAKE_CURRENT_SOURCE_DIR}/../CMakeLists.txt)'         >> $cmake_file
     cd  $DIR/$build_dir/build
+    CMAKE_CMD="$CMAKE_CMD -DFlatCC_HINT_INCLUDE_DIR=~/flatcc/include/ -DFlatCC_LIBRARY_DIR=~/flatcc/lib/"
+    echo $CMAKE_CMD
     eval $CMAKE_CMD
 
     execlist=""
diff --git a/cmake_targets/tools/MODULES/FindFlatCC.cmake b/cmake_targets/tools/MODULES/FindFlatCC.cmake
new file mode 100644
index 0000000000..9f548c3b54
--- /dev/null
+++ b/cmake_targets/tools/MODULES/FindFlatCC.cmake
@@ -0,0 +1,28 @@
+# FlatCC_FOUND - system has FlatCC
+# Provides target FlatCC::FlatCC to link against FlatCC library
+
+include(FindPackageHandleStandardArgs)
+
+set(FlatCC_HINT_INCLUDE_DIR "" CACHE STRING "The Flatbuffers include directory")
+set_property(CACHE FlatCC_HINT_INCLUDE_DIR PROPERTY TYPE STRING)
+
+set(FlatCC_LIBRARY_DIR "" CACHE STRING "The Flatbuffers link directory")
+set_property(CACHE FlatCC_LIBRARY_DIR PROPERTY TYPE STRING)
+
+find_library(FlatCC_LIBRARY NAMES libflatccrt.a HINTS ${FlatCC_LIBRARY_DIR})
+find_path(FlatCC_INCLUDE_DIR NAMES flatcc/flatcc.h HINTS ${FlatCC_HINT_INCLUDE_DIR})
+
+find_package_handle_standard_args(FlatCC REQUIRED_VARS FlatCC_LIBRARY FlatCC_INCLUDE_DIR)
+
+if (FlatCC_FOUND)
+  mark_as_advanced(FlatCC_LIBRARY)
+  mark_as_advanced(FlatCC_INCLUDE_DIR)
+endif()
+
+if (FlatCC_FOUND AND NOT TARGET FlatCC::FlatCC)
+  add_library(FlatCC::FlatCC STATIC IMPORTED)
+  set_property(TARGET FlatCC::FlatCC PROPERTY IMPORTED_LOCATION ${FlatCC_LIBRARY})
+  #target_include_directories(FlatCC::FlatCC INTERFACE ${FlatCC_INCLUDE_DIR})
+  # https://gitlab.kitware.com/cmake/cmake/-/issues/15689
+  set_property(TARGET FlatCC::FlatCC APPEND PROPERTY INTERFACE_INCLUDE_DIRECTORIES ${FlatCC_INCLUDE_DIR})
+endif()
diff --git a/doc/SW_archi.md b/doc/SW_archi.md
index e5856d63bc..2576381f7d 100644
--- a/doc/SW_archi.md
+++ b/doc/SW_archi.md
@@ -215,7 +215,7 @@ nr_preprocessor_phytest()], multiple users in FR1
   2)  Checks the quantity of waiting data in RLC
   3)  Either set up resource allocation directly (e.g., for a single UE,
       phytest), or call into a function to perform actual resource allocation.
-      Currently, this is done using pf_dl() which implements a basic
+      Currently, this is done using nr_pf_dl() which implements a basic
       proportional fair scheduler:
       * for every UE, check for retransmission and allocate as necessary
       * Calculate the PF coefficient and put eligible UEs into a list
diff --git a/executables/nr-softmodem.c b/executables/nr-softmodem.c
index 353751a66a..48ae4d658e 100644
--- a/executables/nr-softmodem.c
+++ b/executables/nr-softmodem.c
@@ -806,6 +806,13 @@ if(!IS_SOFTMODEM_NOS1)
     wait_nfapi_init("main?");
   }
 
+#ifdef USE_FLEXRIC
+    extern void flexric_start_nsa(void);
+    flexric_start_nsa();
+#else
+#warning "compiling without FlexricAgent"
+#endif
+
   printf("wait RUs\n");
   wait_RUs();
   printf("ALL RUs READY!\n");
diff --git a/openair1/PHY/NR_TRANSPORT/nr_dlsch.c b/openair1/PHY/NR_TRANSPORT/nr_dlsch.c
index 96918792a0..9e8bcee7be 100644
--- a/openair1/PHY/NR_TRANSPORT/nr_dlsch.c
+++ b/openair1/PHY/NR_TRANSPORT/nr_dlsch.c
@@ -159,7 +159,7 @@ uint8_t nr_generate_pdsch(PHY_VARS_gNB *gNB,
     uint16_t nb_re = ((12*rel15->NrOfSymbols)-nb_re_dmrs*dmrs_len-xOverhead)*rel15->rbSize*rel15->nrOfLayers;
     uint8_t Qm = rel15->qamModOrder[0];
     uint32_t encoded_length = nb_re*Qm;
-    int16_t mod_dmrs[n_dmrs<<1] __attribute__ ((aligned(16)));
+    int16_t mod_dmrs[n_dmrs*4] __attribute__ ((aligned(16)));
 
     /* PTRS */
     uint16_t beta_ptrs = 1;
diff --git a/openair1/PHY/defs_common.h b/openair1/PHY/defs_common.h
index b9c776f1c8..908a5d18bf 100644
--- a/openair1/PHY/defs_common.h
+++ b/openair1/PHY/defs_common.h
@@ -869,7 +869,8 @@ typedef enum {
   RA_RESPONSE=2,
   RA_WAIT_CR=3,
   PUSCH=4,
-  RESYNCH=5
+  RESYNCH=5,
+  PRACH_INACTIVE=6
 } UE_MODE_t;
 
 #define FOREACH_PARALLEL(GEN)   \
diff --git a/openair2/COMMON/platform_constants.h b/openair2/COMMON/platform_constants.h
index acfc0920aa..9292cc0535 100644
--- a/openair2/COMMON/platform_constants.h
+++ b/openair2/COMMON/platform_constants.h
@@ -75,7 +75,7 @@
       #define MAX_eNB                      2
       #define MAX_gNB                      2
     #else
-      #define MAX_MOBILES_PER_ENB         4
+      #define MAX_MOBILES_PER_ENB         128
       #define MAX_MOBILES_PER_ENB_NB_IoT  4
       #define MAX_MOBILES_PER_GNB         2//16
       #define MAX_eNB                      2
diff --git a/openair2/ENB_APP/CONTROL_MODULES/MAC/flexran_agent_mac_internal.c b/openair2/ENB_APP/CONTROL_MODULES/MAC/flexran_agent_mac_internal.c
index e05fa98854..f4db9ee259 100644
--- a/openair2/ENB_APP/CONTROL_MODULES/MAC/flexran_agent_mac_internal.c
+++ b/openair2/ENB_APP/CONTROL_MODULES/MAC/flexran_agent_mac_internal.c
@@ -1092,9 +1092,14 @@ void apply_update_dl_slice_config(mid_t mod_id, Protocol__FlexSliceDlUlConfig *d
 
   Protocol__FlexSliceAlgorithm dl_algo = flexran_get_dl_slice_algo(mod_id);
   if (dl->has_algorithm && dl_algo != dl->algorithm) {
-    LOG_I(FLEXRAN_AGENT, "loading new DL slice algorithm %d\n", dl->algorithm);
-    dl_algo = dl->algorithm;
-    flexran_set_dl_slice_algo(mod_id, dl_algo);
+    int rc = flexran_set_dl_slice_algo(mod_id, dl->algorithm);
+    if (rc != 1) {
+      LOG_E(FLEXRAN_AGENT, "cannot load slice algorithm %d: error code %d\n", dl->algorithm, rc);
+      return;
+    } else {
+      LOG_I(FLEXRAN_AGENT, "loading new DL slice algorithm %d\n", dl->algorithm);
+      dl_algo = dl->algorithm; // mark this as the new algo to prevent a new lookup
+    }
   }
 
   /* first update existing slices, then create new. Thus, we go through the
diff --git a/openair2/ENB_APP/MESSAGES/V2/config_common.proto b/openair2/ENB_APP/MESSAGES/V2/config_common.proto
index 2f2267b628..36d917e112 100644
--- a/openair2/ENB_APP/MESSAGES/V2/config_common.proto
+++ b/openair2/ENB_APP/MESSAGES/V2/config_common.proto
@@ -65,6 +65,7 @@ enum flex_slice_algorithm {
   None = 0;
   Static = 1;
   NVS = 2;
+  SCN19 = 3;
 }
 
 message flex_slice_static {
@@ -72,12 +73,42 @@ message flex_slice_static {
   optional uint32 posHigh = 2;
 }
 
+message flex_slice_nvs {
+  message nvs_rate {
+    optional float Mbps_required = 1;
+    optional float Mbps_reference = 2;
+  }
+  oneof type {
+    nvs_rate rate = 1;
+    float pct_reserved = 2;
+  }
+}
+
+message flex_slice_scn19 {
+  message scn19_dynamic {
+    optional float Mbps_required = 1;
+    optional float Mbps_reference = 2;
+  }
+  message scn19_ondemand {
+    optional float pct_reserved = 1;
+    optional uint32 tau = 2;
+    optional float log_delta = 3;
+  }
+  oneof type {
+    scn19_dynamic dynamic = 1;
+    flex_slice_static fixed = 2;
+    scn19_ondemand ondemand = 3;
+  }
+}
+
 message flex_slice {
   optional uint32 id = 1;
   optional string label = 2;
   optional string scheduler = 3;
   oneof params {
     flex_slice_static static = 10;
+    flex_slice_nvs nvs = 11;
+    flex_slice_scn19 scn19 = 12;
   }
 }
 
diff --git a/openair2/ENB_APP/enb_config.c b/openair2/ENB_APP/enb_config.c
index fe706b2143..057cb4e358 100644
--- a/openair2/ENB_APP/enb_config.c
+++ b/openair2/ENB_APP/enb_config.c
@@ -358,6 +358,9 @@ int RCconfig_RRC(uint32_t i, eNB_RRC_INST *rrc, int macrlc_has_f1) {
       enb_id = *(ENBParamList.paramarray[i][ENB_ENB_ID_IDX].uptr);
     }
 
+    rrc->node_id        = *(ENBParamList.paramarray[0][ENB_ENB_ID_IDX].uptr);
+    rrc->node_name = strdup(*(ENBParamList.paramarray[0][ENB_ENB_NAME_IDX].strptr));
+
     LOG_I(RRC,"Instance %d: Southbound Transport %s\n",i,*(ENBParamList.paramarray[i][ENB_TRANSPORT_S_PREFERENCE_IDX].strptr));
 
     if (strcmp(*(ENBParamList.paramarray[i][ENB_TRANSPORT_S_PREFERENCE_IDX].strptr), "f1") == 0) {
@@ -365,9 +368,7 @@ int RCconfig_RRC(uint32_t i, eNB_RRC_INST *rrc, int macrlc_has_f1) {
       char aprefix[MAX_OPTNAME_SIZE*2 + 8];
       sprintf(aprefix,"%s.[%u].%s",ENB_CONFIG_STRING_ENB_LIST,i,ENB_CONFIG_STRING_SCTP_CONFIG);
       config_get( SCTPParams,sizeof(SCTPParams)/sizeof(paramdef_t),aprefix);
-      rrc->node_id        = *(ENBParamList.paramarray[0][ENB_ENB_ID_IDX].uptr);
       LOG_I(ENB_APP,"F1AP: gNB_CU_id[%d] %d\n",k,rrc->node_id);
-      rrc->node_name = strdup(*(ENBParamList.paramarray[0][ENB_ENB_NAME_IDX].strptr));
       LOG_I(ENB_APP,"F1AP: gNB_CU_name[%d] %s\n",k,rrc->node_name);
       rrc->eth_params_s.local_if_name            = strdup(*(ENBParamList.paramarray[i][ENB_LOCAL_S_IF_NAME_IDX].strptr));
       rrc->eth_params_s.my_addr                  = strdup(*(ENBParamList.paramarray[i][ENB_LOCAL_S_ADDRESS_IDX].strptr));
diff --git a/openair2/ENB_APP/flexran_agent_ran_api.c b/openair2/ENB_APP/flexran_agent_ran_api.c
index 68d1f3311f..aa9a98c7e3 100644
--- a/openair2/ENB_APP/flexran_agent_ran_api.c
+++ b/openair2/ENB_APP/flexran_agent_ran_api.c
@@ -3023,6 +3023,10 @@ Protocol__FlexSliceAlgorithm flexran_get_dl_slice_algo(mid_t mod_id) {
   switch (RC.mac[mod_id]->pre_processor_dl.algorithm) {
     case STATIC_SLICING:
       return PROTOCOL__FLEX_SLICE_ALGORITHM__Static;
+    case NVS_SLICING:
+      return PROTOCOL__FLEX_SLICE_ALGORITHM__NVS;
+    case SCN19_SLICING:
+      return PROTOCOL__FLEX_SLICE_ALGORITHM__SCN19;
     default:
       return PROTOCOL__FLEX_SLICE_ALGORITHM__None;
   }
@@ -3035,15 +3039,23 @@ int flexran_set_dl_slice_algo(mid_t mod_id, Protocol__FlexSliceAlgorithm algo) {
 
   pp_impl_param_t dl = mac->pre_processor_dl;
   switch (algo) {
-    case PROTOCOL__FLEX_SLICE_ALGORITHM__Static:
-      mac->pre_processor_dl = static_dl_init(mod_id, cc_id);
-      break;
-    default:
+    case PROTOCOL__FLEX_SLICE_ALGORITHM__None:
       mac->pre_processor_dl.algorithm = 0;
       mac->pre_processor_dl.dl = dlsch_scheduler_pre_processor;
       mac->pre_processor_dl.dl_algo.data = mac->pre_processor_dl.dl_algo.setup();
       mac->pre_processor_dl.slices = NULL;
       break;
+    case PROTOCOL__FLEX_SLICE_ALGORITHM__Static:
+      mac->pre_processor_dl = static_dl_init(mod_id, cc_id);
+      break;
+    case PROTOCOL__FLEX_SLICE_ALGORITHM__NVS:
+      mac->pre_processor_dl = nvs_dl_init(mod_id, cc_id);
+      break;
+    case PROTOCOL__FLEX_SLICE_ALGORITHM__SCN19:
+      mac->pre_processor_dl = scn19_dl_init(mod_id, cc_id);
+      break;
+    default:
+      return -1;
   }
   if (dl.slices)
     dl.destroy(&dl.slices);
@@ -3131,6 +3143,42 @@ int flexran_create_dl_slice(mid_t mod_id, const Protocol__FlexSlice *s, void *ob
       ((static_slice_param_t *)params)->posLow = s->static_->poslow;
       ((static_slice_param_t *)params)->posHigh = s->static_->poshigh;
       break;
+    case PROTOCOL__FLEX_SLICE__PARAMS_NVS:
+      params = malloc(sizeof(nvs_slice_param_t));
+      if (!params) return 0;
+      if (s->nvs->type_case == PROTOCOL__FLEX_SLICE_NVS__TYPE_RATE) {
+        ((nvs_slice_param_t *)params)->type = NVS_RATE;
+        ((nvs_slice_param_t *)params)->Mbps_reserved = s->nvs->rate->mbps_required;
+        ((nvs_slice_param_t *)params)->Mbps_reference = s->nvs->rate->mbps_reference;
+      } else {
+        ((nvs_slice_param_t *)params)->type = NVS_RES;
+        ((nvs_slice_param_t *)params)->pct_reserved = s->nvs->pct_reserved;
+      }
+      break;
+    case PROTOCOL__FLEX_SLICE__PARAMS_SCN19:
+      params = malloc(sizeof(scn19_slice_param_t));
+      if (!params) return 0;
+      switch (s->scn19->type_case) {
+        case PROTOCOL__FLEX_SLICE_SCN19__TYPE_DYNAMIC:
+          ((scn19_slice_param_t *)params)->type = SCN19_DYN;
+          ((scn19_slice_param_t *)params)->Mbps_reserved = s->scn19->dynamic->mbps_required;
+          ((scn19_slice_param_t *)params)->Mbps_reference = s->scn19->dynamic->mbps_reference;
+          break;
+        case PROTOCOL__FLEX_SLICE_SCN19__TYPE_FIXED:
+          ((scn19_slice_param_t *)params)->type = SCN19_FIX;
+          ((scn19_slice_param_t *)params)->posLow = s->scn19->fixed->poslow;
+          ((scn19_slice_param_t *)params)->posHigh = s->scn19->fixed->poshigh;
+          break;
+        case PROTOCOL__FLEX_SLICE_SCN19__TYPE_ONDEMAND:
+          ((scn19_slice_param_t *)params)->type = SCN19_OND;
+          ((scn19_slice_param_t *)params)->pct_reserved = s->scn19->ondemand->pct_reserved;
+          ((scn19_slice_param_t *)params)->tau = s->scn19->ondemand->tau;
+          ((scn19_slice_param_t *)params)->log_delta = s->scn19->ondemand->log_delta;
+          break;
+        default:
+          return 0;
+      }
+      break;
     default:
       break;
   }
@@ -3187,6 +3235,65 @@ void flexran_get_dl_slice(mid_t mod_id,
       slice->static_->poshigh = ((static_slice_param_t *)s_->algo_data)->posHigh;
       slice->params_case = PROTOCOL__FLEX_SLICE__PARAMS_STATIC;
       break;
+    case PROTOCOL__FLEX_SLICE_ALGORITHM__NVS:
+      slice->nvs = malloc(sizeof(Protocol__FlexSliceNvs));
+      if (!slice->nvs) return;
+      protocol__flex_slice_nvs__init(slice->nvs);
+      if (((nvs_slice_param_t *)s_->algo_data)->type == NVS_RATE) {
+        slice->nvs->rate = malloc(sizeof(Protocol__FlexSliceNvs__NvsRate));
+        if (!slice->nvs->rate) return;
+        protocol__flex_slice_nvs__nvs_rate__init(slice->nvs->rate);
+        slice->nvs->rate->mbps_required = ((nvs_slice_param_t *)s_->algo_data)->Mbps_reserved;
+        slice->nvs->rate->has_mbps_required = 1;
+        slice->nvs->rate->mbps_reference = ((nvs_slice_param_t *)s_->algo_data)->Mbps_reference;
+        slice->nvs->rate->has_mbps_reference = 1;
+        slice->nvs->type_case = PROTOCOL__FLEX_SLICE_NVS__TYPE_RATE;
+      } else {
+        slice->nvs->pct_reserved = ((nvs_slice_param_t *)s_->algo_data)->pct_reserved;
+        slice->nvs->type_case = PROTOCOL__FLEX_SLICE_NVS__TYPE_PCT_RESERVED;
+      }
+      slice->params_case = PROTOCOL__FLEX_SLICE__PARAMS_NVS;
+      break;
+    case PROTOCOL__FLEX_SLICE_ALGORITHM__SCN19:
+      slice->scn19 = malloc(sizeof(Protocol__FlexSliceScn19));
+      if (!slice->scn19) return;
+      protocol__flex_slice_scn19__init(slice->scn19);
+      switch (((scn19_slice_param_t *)s_->algo_data)->type) {
+        case SCN19_DYN:
+          slice->scn19->dynamic = malloc(sizeof(Protocol__FlexSliceScn19__Scn19Dynamic));
+          if (!slice->scn19->dynamic) return;
+          protocol__flex_slice_scn19__scn19_dynamic__init(slice->scn19->dynamic);
+          slice->scn19->dynamic->mbps_required = ((scn19_slice_param_t *)s_->algo_data)->Mbps_reserved;
+          slice->scn19->dynamic->has_mbps_required = 1;
+          slice->scn19->dynamic->mbps_reference = ((scn19_slice_param_t *)s_->algo_data)->Mbps_reference;
+          slice->scn19->dynamic->has_mbps_reference = 1;
+          slice->scn19->type_case = PROTOCOL__FLEX_SLICE_SCN19__TYPE_DYNAMIC;
+          break;
+        case SCN19_FIX:
+          slice->scn19->fixed = malloc(sizeof(Protocol__FlexSliceStatic));
+          if (!slice->scn19->fixed) return;
+          protocol__flex_slice_static__init(slice->scn19->fixed);
+          slice->scn19->fixed->has_poslow = 1;
+          slice->scn19->fixed->poslow = ((scn19_slice_param_t *)s_->algo_data)->posLow;
+          slice->scn19->fixed->has_poshigh = 1;
+          slice->scn19->fixed->poshigh = ((scn19_slice_param_t *)s_->algo_data)->posHigh;
+          slice->scn19->type_case = PROTOCOL__FLEX_SLICE_SCN19__TYPE_FIXED;
+          break;
+        case SCN19_OND:
+          slice->scn19->ondemand = malloc(sizeof(Protocol__FlexSliceScn19__Scn19Ondemand));
+          if (!slice->scn19->ondemand) return;
+          protocol__flex_slice_scn19__scn19_ondemand__init(slice->scn19->ondemand);
+          slice->scn19->ondemand->pct_reserved = ((scn19_slice_param_t *)s_->algo_data)->pct_reserved;
+          slice->scn19->ondemand->has_pct_reserved = 1;
+          slice->scn19->ondemand->tau = ((scn19_slice_param_t *)s_->algo_data)->tau;
+          slice->scn19->ondemand->has_tau = 1;
+          slice->scn19->ondemand->log_delta = ((scn19_slice_param_t *)s_->algo_data)->log_delta;
+          slice->scn19->ondemand->has_log_delta = 1;
+          slice->scn19->type_case = PROTOCOL__FLEX_SLICE_SCN19__TYPE_ONDEMAND;
+          break;
+      }
+      slice->params_case = PROTOCOL__FLEX_SLICE__PARAMS_SCN19;
+      break;
     default:
       break;
   }
@@ -3208,6 +3315,18 @@ int flexran_create_ul_slice(mid_t mod_id, const Protocol__FlexSlice *s, void *ob
       ((static_slice_param_t *)params)->posLow = s->static_->poslow;
       ((static_slice_param_t *)params)->posHigh = s->static_->poshigh;
       break;
+    /*case PROTOCOL__FLEX_SLICE__PARAMS_NVS:
+      params = malloc(sizeof(nvs_slice_param_t));
+      if (!params) return 0;
+      if (s->nvs->type_case == PROTOCOL__FLEX_SLICE_NVS__TYPE_RATE) {
+        ((nvs_slice_param_t *)params)->type = NVS_RATE;
+        ((nvs_slice_param_t *)params)->Mbps_reserved = s->nvs->rate->Mbps_required;
+        ((nvs_slice_param_t *)params)->Mbps_reference = s->nvs->rate->Mbps_reference;
+      } else {
+        ((nvs_slice_param_t *)params)->type = NVS_RES;
+        ((nvs_slice_param_t *)params)->pct_reserved = s->nvs->pct_reserved;
+      }
+      break;*/
     default:
       break;
   }
@@ -3264,10 +3383,25 @@ void flexran_get_ul_slice(mid_t mod_id,
       slice->static_->poshigh = ((static_slice_param_t *)s_->algo_data)->posHigh;
       slice->params_case = PROTOCOL__FLEX_SLICE__PARAMS_STATIC;
       break;
+    /*case PROTOCOL__FLEX_SLICE_ALGORITHM__NVS:
+      slice->nvs = malloc(sizeof(Protocol__FlexSliceNvs));
+      if (!slice->nvs) return;
+      protocol__flex_slice_nvs__init(slice->nvs);
+      if (((nvs_slice_param_t *)s_->algo_data)->type == NVS_RATE) {
+        slice->nvs->rate = malloc(sizeof(Protocol__FlexSliceNvs__NvsRate));
+        if (!slice->nvs->rate) return;
+        protocol__flex_slice_nvs__nvs_rate__init(slice->nvs->rate);
+        slice->nvs->rate->Mbps_required = ((nvs_slice_param_t *)s_->algo_data)->Mbps_reserved;
+        slice->nvs->rate->Mbps_reference = ((nvs_slice_param_t *)s_->algo_data)->Mbps_reference;
+        slice->nvs->type_case = PROTOCOL__FLEX_SLICE_NVS__TYPE_RATE;
+      } else {
+        slice->nvs->pct_reserved = ((nvs_slice_param_t *)s_->algo_data)->pct_reserved;
+        slice->nvs->type_case = PROTOCOL__FLEX_SLICE_NVS__TYPE_PCT_RESERVED;
+      }
+      slice->params_case = PROTOCOL__FLEX_SLICE__PARAMS_NVS;*/
     default:
       break;
   }
-
 }
 
 int flexran_get_num_ul_slices(mid_t mod_id) {
diff --git a/openair2/ENB_APP/flexric_agent.c b/openair2/ENB_APP/flexric_agent.c
new file mode 100644
index 0000000000..df89b4f6b3
--- /dev/null
+++ b/openair2/ENB_APP/flexric_agent.c
@@ -0,0 +1,801 @@
+#include <assert.h>
+#include <pthread.h>
+
+#include <dlfcn.h>
+
+/* the define redefines the definition of plmn_t that is pulled through
+ * ran_context.h */
+#define plmn_t plmn_t_WE_DONT_NEED
+#include "common/ran_context.h"
+extern RAN_CONTEXT_t RC;
+#undef plmn_t
+
+//#include "RRC/LTE/rrc_eNB_UE_context.h"
+//#include "pdcp.h"
+#include "openair2/LAYER2/MAC/slicing/slicing.h"
+
+#include "flexric_agent.h"
+#include "mac_stats_rf.h"
+#include "rslicing_rf.h"
+#include "rlc_stats_rf.h"
+#include "pdcp_stats_rf.h"
+#include "rrc_stats_rf.h"
+#include "rrc_conf_rf.h"
+#include "rrc_event_rf.h"
+
+e2ap_agent_t* flexric_ag;
+static const int mod_id = 0;
+static const int CC_id = 0;
+
+static
+void mac_gen_hdr(flatcc_builder_t* B)
+{
+  mac_stats_IndicationHeader_start(B);
+  mac_stats_IndicationHeader_frame_force_add(B, RC.mac[mod_id]->frame);
+  mac_stats_IndicationHeader_slot_force_add(B, RC.mac[mod_id]->subframe);
+  mac_stats_IndicationHeader_end_as_root(B);
+}
+
+static
+void mac_gen_msg(flatcc_builder_t* B, const mac_stats_report_style_t* style)
+{
+  const size_t num_ues = RC.mac[mod_id]->UE_info.num_UEs;
+  mac_stats_IndicationMessage_start(B);
+  mac_stats_IndicationMessage_ueStats_start(B);
+  const UE_list_t* ue_list = &RC.mac[mod_id]->UE_info.list;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    const eNB_UE_STATS* uestats = &RC.mac[mod_id]->UE_info.eNB_UE_stats[CC_id][ue_id];
+    const UE_sched_ctrl_t *sched_ctrl = &RC.mac[mod_id]->UE_info.UE_sched_ctrl[ue_id];
+    const UE_TEMPLATE *template = &RC.mac[mod_id]->UE_info.UE_template[CC_id][ue_id];
+    mac_stats_UEStats_vec_push_start(B);
+    mac_stats_UEStats_dlAggrPrb_force_add(B, uestats->total_rbs_used);
+    mac_stats_UEStats_ulAggrPrb_force_add(B, uestats->total_rbs_used_rx);
+    mac_stats_UEStats_dlAggrTbs_force_add(B, uestats->total_pdu_bytes);
+    mac_stats_UEStats_ulAggrTbs_force_add(B, uestats->total_ulsch_TBS);
+    mac_stats_UEStats_dlAggrSdus_force_add(B, uestats->num_mac_sdu_tx);
+    mac_stats_UEStats_ulAggrSdus_force_add(B, uestats->num_mac_sdu_rx);
+    mac_stats_UEStats_dlAggrBytesSdus_force_add(B, uestats->total_sdu_bytes);
+    uint64_t ul_sdu_bytes = 0;
+    for (int i = 0; i < NB_RB_MAX; ++i)
+      ul_sdu_bytes += uestats->num_bytes_rx[i];
+    mac_stats_UEStats_ulAggrBytesSdus_force_add(B, ul_sdu_bytes);
+    mac_stats_UEStats_dlAggrRetxPrb_force_add(B, uestats->rbs_used_retx);
+    mac_stats_UEStats_ulAggrRetxPrb_force_add(B, uestats->rbs_used_retx_rx);
+    if (style->type == MAC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+      mac_stats_UEStats_puschSnr_add(B, sched_ctrl->pusch_snr[CC_id]);
+      mac_stats_UEStats_pucchSnr_add(B, sched_ctrl->pucch1_snr[CC_id]);
+
+      mac_stats_UEStats_bsr_start(B);
+      const uint8_t lcgid = 0; /* below is aggregated value across all LCGIDs */
+      const uint32_t bufferSize = template->estimated_ul_buffer - template->scheduled_ul_bytes;
+      mac_stats_UEStats_bsr_push_create(B, lcgid, bufferSize);
+      mac_stats_UEStats_bsr_end(B);
+
+      const size_t numDlHarq = 4;
+      mac_stats_UEStats_dlHarq_start(B);
+      uint32_t* vdl = mac_stats_UEStats_dlHarq_extend(B, numDlHarq + 1);
+      for (uint8_t j = 0; j < numDlHarq; ++j)
+        vdl[j] = uestats->dlsch_rounds[j];
+      vdl[numDlHarq] = uestats->dlsch_errors;
+      mac_stats_UEStats_dlHarq_end(B);
+
+      const size_t numUlHarq = 4;
+      mac_stats_UEStats_ulHarq_start(B);
+      uint32_t* vul = mac_stats_UEStats_ulHarq_extend(B, numUlHarq + 1);
+      for (uint8_t j = 0; j < numUlHarq; ++j)
+        vul[j] = uestats->ulsch_rounds[j];
+      vul[numUlHarq] = uestats->ulsch_errors;
+      mac_stats_UEStats_ulHarq_end(B);
+    }
+    mac_stats_UEStats_rnti_force_add(B, uestats->crnti);
+    if (style->type == MAC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+      mac_stats_UEStats_wbCqi_add(B, sched_ctrl->dl_cqi[CC_id]);
+      mac_stats_UEStats_dlMcs1_add(B, uestats->dlsch_mcs1);
+      mac_stats_UEStats_ulMcs1_add(B, uestats->ulsch_mcs1);
+      //mac_stats_UEStats_dlMcs2_add(B, 0);
+      //mac_stats_UEStats_ulMcs2_add(B, 0);
+      mac_stats_UEStats_phr_add(B, template->phr_info);
+    }
+    mac_stats_UEStats_vec_push_end(B);
+  }
+  mac_stats_IndicationMessage_ueStats_end(B);
+  mac_stats_IndicationMessage_end_as_root(B);
+}
+
+static
+void rslicing_get_slice_configuration(flatcc_builder_t* B, size_t idx, mac_rslicing_SliceAlgorithm_enum_t algo)
+{
+  slice_t *s_ = RC.mac[mod_id]->pre_processor_dl.slices->s[idx];
+
+  mac_rslicing_Slice_vec_push_start(B);
+  // in order of mac_rslicing_Slice_create()
+  mac_rslicing_Slice_id_force_add(B, s_->id);
+  if (s_->label) {
+    flatbuffers_string_ref_t label = flatbuffers_string_create_str(B, s_->label);
+    mac_rslicing_Slice_label_add(B, label);
+  }
+  flatbuffers_string_ref_t scheduler = flatbuffers_string_create_str(B, s_->dl_algo.name);
+  mac_rslicing_Slice_scheduler_add(B, scheduler);
+
+  mac_rslicing_SliceParams_union_ref_t p;
+  switch (algo) {
+    case mac_rslicing_SliceAlgorithm_Static: {
+        uint16_t posLow = ((static_slice_param_t *)s_->algo_data)->posLow;
+        uint16_t posHigh = ((static_slice_param_t *)s_->algo_data)->posHigh;
+        mac_rslicing_StaticSlice_start(B);
+        mac_rslicing_StaticSlice_posLow_force_add(B, posLow);
+        mac_rslicing_StaticSlice_posHigh_force_add(B, posHigh);
+        mac_rslicing_StaticSlice_ref_t stat = mac_rslicing_StaticSlice_end(B);
+        p = mac_rslicing_SliceParams_as_static(stat);
+      }
+      break;
+    case mac_rslicing_SliceAlgorithm_NVS: {
+        if (((nvs_slice_param_t *)s_->algo_data)->type == NVS_RATE) {
+          const float rsvd = ((nvs_slice_param_t *)s_->algo_data)->Mbps_reserved;
+          const float ref = ((nvs_slice_param_t *)s_->algo_data)->Mbps_reference;
+          mac_rslicing_NvsRate_ref_t nvsrate = mac_rslicing_NvsRate_create(B, rsvd, ref);
+          mac_rslicing_NvsSliceConfig_union_ref_t unvsrate = mac_rslicing_NvsSliceConfig_as_rate(nvsrate);
+          mac_rslicing_NvsSlice_ref_t nvs1 = mac_rslicing_NvsSlice_create(B, unvsrate);
+          p = mac_rslicing_SliceParams_as_nvs(nvs1);
+        } else {
+          const float rsvd = ((nvs_slice_param_t *)s_->algo_data)->pct_reserved;
+          mac_rslicing_NvsCapacity_ref_t nvscap = mac_rslicing_NvsCapacity_create(B, rsvd);
+          mac_rslicing_NvsSliceConfig_union_ref_t unvscap = mac_rslicing_NvsSliceConfig_as_capacity(nvscap);
+          mac_rslicing_NvsSlice_ref_t nvs2 = mac_rslicing_NvsSlice_create(B, unvscap);
+          p = mac_rslicing_SliceParams_as_nvs(nvs2);
+        }
+      }
+      break;
+    case mac_rslicing_SliceAlgorithm_None:
+    default:
+      assert(0 && "illegal code path");
+      break;
+  }
+  mac_rslicing_Slice_params_add(B, p);
+  mac_rslicing_Slice_vec_push_end(B);
+}
+
+static
+mac_rslicing_SliceAlgorithm_enum_t rslicing_get_slice_algorithm(int algo)
+{
+  switch (algo) {
+    case STATIC_SLICING:
+      return mac_rslicing_SliceAlgorithm_Static;
+    case NVS_SLICING:
+      return mac_rslicing_SliceAlgorithm_NVS;
+    default:
+      return mac_rslicing_SliceAlgorithm_None;
+  }
+}
+
+static
+void rslicing_read_slice_conf(flatcc_builder_t* B)
+{
+  eNB_MAC_INST *mac = RC.mac[mod_id];
+  assert(mac);
+  pp_impl_param_t* pp_dl = &RC.mac[mod_id]->pre_processor_dl;
+
+  mac_rslicing_IndicationMessage_start(B);
+  mac_rslicing_IndicationMessage_sliceConfig_start(B);
+    mac_rslicing_SliceConfig_dl_start(B);
+      mac_rslicing_SliceAlgorithm_enum_t dl_algo = rslicing_get_slice_algorithm(mac->pre_processor_dl.algorithm);
+      mac_rslicing_UlDlSliceConfig_algorithm_force_add(B, dl_algo);
+      size_t n_dl_slices = pp_dl->slices ? pp_dl->slices->num : 0;
+      if (n_dl_slices > 0) {
+        mac_rslicing_UlDlSliceConfig_slices_start(B);
+        for (size_t i = 0; i < n_dl_slices; ++i)
+          rslicing_get_slice_configuration(B, i, dl_algo);
+        mac_rslicing_UlDlSliceConfig_slices_end(B);
+      } else {
+        flatbuffers_string_ref_t sched_dl = flatbuffers_string_create_str(B, pp_dl->dl_algo.name);
+        mac_rslicing_UlDlSliceConfig_scheduler_add(B, sched_dl);
+      }
+    mac_rslicing_SliceConfig_dl_end(B);
+
+    // TODO: UL
+  mac_rslicing_IndicationMessage_sliceConfig_end(B);
+
+  mac_rslicing_IndicationMessage_ueSliceConfig_start(B);
+  mac_rslicing_UeSliceConfig_ues_start(B);
+  const UE_info_t* ue_info = &RC.mac[mod_id]->UE_info;
+  const UE_list_t* ue_list = &ue_info->list;
+  const slice_info_t *dl_slices = RC.mac[mod_id]->pre_processor_dl.slices;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    const uint32_t rnti = ue_info->eNB_UE_stats[CC_id][ue_id].crnti;
+    // in order of mac_rslicing_UeSliceAssoc_create()
+    mac_rslicing_UeSliceAssoc_start(B);
+    if (dl_algo != mac_rslicing_SliceAlgorithm_None) {
+      const int dl_slice_idx = dl_slices->UE_assoc_slice[ue_id];
+      if (dl_slice_idx >= 0) { // is associated to a slice
+        const uint32_t dlslice = dl_slices->s[dl_slice_idx]->id;
+        mac_rslicing_UeSliceAssoc_dlId_force_add(B, dlslice);
+      }
+    }
+    // TODO UL
+    mac_rslicing_UeSliceAssoc_rnti_force_add(B, rnti);
+    mac_rslicing_UeSliceConfig_ues_push(B, mac_rslicing_UeSliceAssoc_end(B));
+  }
+  mac_rslicing_UeSliceConfig_ues_end(B);
+  mac_rslicing_IndicationMessage_ueSliceConfig_end(B);
+  mac_rslicing_IndicationMessage_end_as_root(B);
+}
+
+static
+void rslicing_set_new_dl_slice_algo(mac_rslicing_SliceAlgorithm_enum_t algo)
+{
+  eNB_MAC_INST *mac = RC.mac[mod_id];
+  assert(mac);
+
+  pp_impl_param_t dl = mac->pre_processor_dl;
+  switch (algo) {
+    case mac_rslicing_SliceAlgorithm_Static:
+      mac->pre_processor_dl = static_dl_init(mod_id, CC_id);
+      break;
+    case mac_rslicing_SliceAlgorithm_NVS:
+      mac->pre_processor_dl = nvs_dl_init(mod_id, CC_id);
+      break;
+    default:
+      mac->pre_processor_dl.algorithm = 0;
+      mac->pre_processor_dl.dl = dlsch_scheduler_pre_processor;
+      mac->pre_processor_dl.dl_algo.data = mac->pre_processor_dl.dl_algo.setup();
+      mac->pre_processor_dl.slices = NULL;
+      break;
+  }
+  if (dl.slices)
+    dl.destroy(&dl.slices);
+  if (dl.dl_algo.data)
+    dl.dl_algo.unset(&dl.dl_algo.data);
+}
+
+static
+int rslicing_set_dl_scheduler(const char* sched)
+{
+  void *d = dlsym(NULL, sched);
+  if (!d) return -2;
+  pp_impl_param_t *dl_pp = &RC.mac[mod_id]->pre_processor_dl;
+  dl_pp->dl_algo.unset(&dl_pp->dl_algo.data);
+  dl_pp->dl_algo = *(default_sched_dl_algo_t *) d;
+  dl_pp->dl_algo.data = dl_pp->dl_algo.setup();
+  return 0;
+}
+
+static
+int rslicing_add_mod_dl_slice(mac_rslicing_SliceAlgorithm_enum_t current_algo, mac_rslicing_Slice_table_t slice)
+{
+  void *params = NULL;
+  mac_rslicing_SliceParams_union_t p = mac_rslicing_Slice_params_union(slice);
+  switch (p.type) {
+    case mac_rslicing_SliceParams_static:
+      assert(current_algo == mac_rslicing_SliceAlgorithm_Static);
+      // TODO: this should be copied inside addmod_slice() to avoid unnecessary
+      // copies, but reuse the old code for the moment
+      params = malloc(sizeof(static_slice_param_t));
+      if (!params) return -1;
+      mac_rslicing_StaticSlice_table_t sttc = p.value;
+      ((static_slice_param_t *)params)->posLow = mac_rslicing_StaticSlice_posLow(sttc);
+      ((static_slice_param_t *)params)->posHigh = mac_rslicing_StaticSlice_posHigh(sttc);
+      break;
+    case mac_rslicing_SliceParams_nvs: {
+        assert(current_algo == mac_rslicing_SliceAlgorithm_NVS);
+        params = malloc(sizeof(nvs_slice_param_t));
+        if (!params) return -1;
+        mac_rslicing_NvsSlice_table_t nvs = p.value;
+        mac_rslicing_NvsSliceConfig_union_t unvs = mac_rslicing_NvsSlice_config_union(nvs);
+        if (unvs.type == mac_rslicing_NvsSliceConfig_rate) {
+          mac_rslicing_NvsRate_table_t rate = unvs.value;
+          ((nvs_slice_param_t *)params)->type = NVS_RATE;
+          ((nvs_slice_param_t *)params)->Mbps_reserved = mac_rslicing_NvsRate_mbpsRequired(rate);
+          ((nvs_slice_param_t *)params)->Mbps_reference = mac_rslicing_NvsRate_mbpsReference(rate);
+        } else {
+          assert(unvs.type == mac_rslicing_NvsSliceConfig_capacity);
+          mac_rslicing_NvsCapacity_table_t cap = unvs.value;
+          ((nvs_slice_param_t *)params)->type = NVS_RES;
+          ((nvs_slice_param_t *)params)->pct_reserved = mac_rslicing_NvsCapacity_pctReserved(cap);
+        }
+      }
+      break;
+    default:
+      LOG_E(MAC, "unhandled slicing type\n");
+      return -1000;
+      break;
+  }
+  pp_impl_param_t *dl = &RC.mac[mod_id]->pre_processor_dl;
+  void *algo = &dl->dl_algo; // default scheduler
+  if (mac_rslicing_Slice_scheduler_is_present(slice)) {
+    algo = dlsym(NULL, mac_rslicing_Slice_scheduler(slice));
+    if (!algo) {
+      free(params);
+      LOG_E(MAC, "cannot locate scheduler '%s'\n", mac_rslicing_Slice_scheduler(slice));
+      return -15;
+    }
+  }
+  char *l = NULL;
+  if (mac_rslicing_Slice_label_is_present(slice))
+      l = strdup(mac_rslicing_Slice_label(slice));
+  uint8_t sid = mac_rslicing_Slice_id(slice);
+  return dl->addmod_slice(dl->slices, sid, l, algo, params);
+}
+
+static
+int rslicing_find_dl_slice(uint32_t id)
+{
+  slice_info_t *si = RC.mac[mod_id]->pre_processor_dl.slices;
+  for (int i = 0; i < si->num; ++i)
+    if (si->s[i]->id == id)
+      return i;
+  return -1;
+}
+
+static
+int rslicing_del_dl_slice(uint32_t id)
+{
+  const int idx = rslicing_find_dl_slice(id);
+  if (idx < 0)
+    return -1;
+  pp_impl_param_t *dl = &RC.mac[mod_id]->pre_processor_dl;
+  return dl->remove_slice(dl->slices, idx);
+}
+
+static
+rslicing_rc_t rslicing_handle_add_mod_slice_command(mac_rslicing_AddModSliceCommand_table_t t)
+{
+  assert(t);
+
+  eNB_MAC_INST *mac = RC.mac[mod_id];
+  assert(mac);
+  pp_impl_param_t* pp_dl = &RC.mac[mod_id]->pre_processor_dl;
+
+  mac_rslicing_SliceConfig_table_t new_sc = mac_rslicing_AddModSliceCommand_sliceConfig(t);
+  if (mac_rslicing_SliceConfig_dl_is_present(new_sc)) {
+    mac_rslicing_UlDlSliceConfig_table_t dl = mac_rslicing_SliceConfig_dl(new_sc);
+    mac_rslicing_SliceAlgorithm_enum_t current_algo = rslicing_get_slice_algorithm(mac->pre_processor_dl.algorithm);
+    mac_rslicing_SliceAlgorithm_enum_t new_algo = mac_rslicing_UlDlSliceConfig_algorithm(dl);
+    pthread_mutex_lock(&mac->pp_dl_mutex);
+    if (mac_rslicing_UlDlSliceConfig_algorithm_is_present(dl)
+        && current_algo != new_algo) {
+      rslicing_set_new_dl_slice_algo(new_algo);
+      current_algo = new_algo;
+      LOG_I(MAC, "set new algorithm %s\n", mac_rslicing_SliceAlgorithm_name(new_algo));
+    }
+
+    mac_rslicing_Slice_vec_t slices = mac_rslicing_UlDlSliceConfig_slices(dl);
+    size_t slices_len = mac_rslicing_Slice_vec_len(slices);
+    for (size_t i = 0; i < slices_len; ++i) {
+      mac_rslicing_Slice_table_t slice = mac_rslicing_Slice_vec_at(slices, i);
+      const int rc = rslicing_add_mod_dl_slice(current_algo, slice);
+      if (rc < 0) {
+        pthread_mutex_unlock(&mac->pp_dl_mutex);
+        LOG_E(MAC, "error code %d while updating slices\n", rc);
+        return (rslicing_rc_t) { .success = false, .error_msg = strdup("error updating slices") };
+      }
+    }
+
+    if (current_algo == mac_rslicing_SliceAlgorithm_None
+        && mac_rslicing_UlDlSliceConfig_scheduler_is_present(dl)) {
+      LOG_I(MAC, "set scheduler %s\n", mac_rslicing_UlDlSliceConfig_scheduler(dl));
+      const int rc = rslicing_set_dl_scheduler(mac_rslicing_UlDlSliceConfig_scheduler(dl));
+      if (rc < 0) {
+        pthread_mutex_unlock(&mac->pp_dl_mutex);
+        LOG_E(MAC, "error code %d while updating scheduler\n", rc);
+        return (rslicing_rc_t) { .success = false, .error_msg = strdup("error setting scheduler") };
+      }
+    }
+    pthread_mutex_unlock(&mac->pp_dl_mutex);
+  }
+  if (mac_rslicing_SliceConfig_ul_is_present(new_sc))
+    LOG_W(MAC, "*** Ignoring UL slice configuration\n");
+  return (rslicing_rc_t) { .success = true, .error_msg = NULL };
+}
+
+static
+rslicing_rc_t rslicing_handle_del_slice_command(mac_rslicing_DelSliceCommand_table_t t)
+{
+  eNB_MAC_INST *mac = RC.mac[mod_id];
+  assert(mac);
+
+  mac_rslicing_DelSliceConfig_table_t dsc = mac_rslicing_DelSliceCommand_delSliceConfig(t);
+  flatbuffers_uint32_vec_t ul_ids = mac_rslicing_DelSliceConfig_ul(dsc);
+  size_t n_ul_ids = flatbuffers_uint32_vec_len(ul_ids);
+  if (n_ul_ids > 0)
+    LOG_E(MAC, "ignoring dl slice command for ul slices\n");
+
+  flatbuffers_uint32_vec_t dl_ids = mac_rslicing_DelSliceConfig_dl(dsc);
+  size_t n_dl_ids = flatbuffers_uint32_vec_len(dl_ids);
+  if (n_dl_ids == 0)
+    return (rslicing_rc_t) { .success = true, .error_msg = NULL };
+
+  pthread_mutex_lock(&mac->pp_dl_mutex);
+  for (size_t i = 0; i < n_dl_ids; ++i) {
+    LOG_I(MAC, "attempt to delete slice ID %d\n", dl_ids[i]);
+    const int rc = rslicing_del_dl_slice(dl_ids[i]);
+    if (rc < 0) {
+      pthread_mutex_unlock(&mac->pp_dl_mutex);
+      LOG_E(MAC, "error code %d while deleting slice ID %d\n", rc, dl_ids[i]);
+      return (rslicing_rc_t) { .success = false, .error_msg = strdup("error deleting slices") };
+    }
+  }
+  pthread_mutex_unlock(&mac->pp_dl_mutex);
+  return (rslicing_rc_t) { .success = true, .error_msg = NULL };
+}
+
+static
+int rslicing_get_ue_id(uint16_t rnti)
+{
+  const UE_info_t* ue_info = &RC.mac[mod_id]->UE_info;
+  const UE_list_t* ue_list = &ue_info->list;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    if (ue_info->UE_template[CC_id][ue_id].rnti == rnti)
+      return ue_id;
+  }
+  return -1;
+}
+
+static
+int rslicing_associate_ue_to_dl_slice(uint16_t rnti, uint32_t id)
+{
+  int idx = rslicing_find_dl_slice(id);
+  if (idx < 0)
+    return -100;
+  int ue_id = rslicing_get_ue_id(rnti);
+  if (ue_id < 0)
+    return -101;
+  LOG_I(MAC, "associate UE RNTI %04x ID %d to slice ID %d idx %d\n",
+        rnti, ue_id, id, idx);
+  pp_impl_param_t *dl = &RC.mac[mod_id]->pre_processor_dl;
+  dl->move_UE(dl->slices, ue_id, idx);
+  return 0;
+}
+
+static
+rslicing_rc_t rslicing_handle_ue_assoc_command(mac_rslicing_UeSliceAssocCommand_table_t t)
+{
+  eNB_MAC_INST *mac = RC.mac[mod_id];
+  assert(mac);
+
+  mac_rslicing_UeSliceConfig_table_t new_uesc = mac_rslicing_UeSliceAssocCommand_ueSliceConfig(t);
+  mac_rslicing_UeSliceAssoc_vec_t new_ues = mac_rslicing_UeSliceConfig_ues(new_uesc);
+  size_t n_new_ues = mac_rslicing_UeSliceAssoc_vec_len(new_ues);
+  for (size_t i = 0; i < n_new_ues; ++i) {
+    mac_rslicing_UeSliceAssoc_table_t uesa = mac_rslicing_UeSliceAssoc_vec_at(new_ues, i);
+    uint16_t rnti = mac_rslicing_UeSliceAssoc_rnti(uesa);
+    if (mac_rslicing_UeSliceAssoc_ulId_is_present(uesa))
+      LOG_W(MAC, "ignoring UL slice association for RNTI %04x\n", rnti);
+    if (!mac_rslicing_UeSliceAssoc_dlId_is_present(uesa)) {
+      pthread_mutex_unlock(&mac->pp_dl_mutex);
+      LOG_E(MAC, "expected DL slice association for UE RNTI %04x\n", rnti);
+      return (rslicing_rc_t) { .success = false, .error_msg = strdup("error associating UEs") };
+    }
+    uint32_t id = mac_rslicing_UeSliceAssoc_dlId(uesa);
+    int rc = rslicing_associate_ue_to_dl_slice(rnti, id);
+    if (rc < 0) {
+      pthread_mutex_unlock(&mac->pp_dl_mutex);
+      LOG_E(MAC, "error code %d while associating RNTI %04x\n", rc, rnti);
+      return (rslicing_rc_t) { .success = false, .error_msg = strdup("error associating UEs") };
+    }
+  }
+  pthread_mutex_unlock(&mac->pp_dl_mutex);
+  return (rslicing_rc_t) { .success = true, .error_msg = NULL };
+}
+
+static
+void rlc_gen_hdr(flatcc_builder_t* B)
+{
+  rlc_stats_IndicationHeader_start(B);
+  rlc_stats_IndicationHeader_frame_force_add(B, RC.mac[mod_id]->frame);
+  rlc_stats_IndicationHeader_slot_force_add(B, RC.mac[mod_id]->subframe);
+  rlc_stats_IndicationHeader_end_as_root(B);
+}
+
+static
+void rlc_gen_msg(flatcc_builder_t* B, const rlc_stats_report_style_t* style)
+{
+  const int frame = RC.mac[mod_id]->frame;
+  const int subframe = RC.mac[mod_id]->subframe;
+  rlc_stats_IndicationMessage_start(B);
+  rlc_stats_IndicationMessage_ueStats_start(B);
+  // use MAC structures to get RNTIs
+  const UE_list_t* ue_list = &RC.mac[mod_id]->UE_info.list;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    // add in the order of rlc_stats_UEStats_create
+    rlc_stats_UEStats_vec_push_start(B);
+    const int lcid = 3;
+    const uint16_t rnti = RC.mac[mod_id]->UE_info.eNB_UE_stats[CC_id][ue_id].crnti;
+    rlc_stats_UEStats_rb_start(B);
+    //for every LC ID (ideally...)
+    {
+      mac_rlc_status_resp_t rlc_stats =
+          mac_rlc_status_ind(mod_id, rnti, mod_id, frame, subframe,
+                             ENB_FLAG_YES, MBMS_FLAG_NO, lcid, 0, 0);
+      // add in the order of rlc_stats_RBStats_create
+      rlc_stats_RBStats_vec_push_start(B);
+      //rlc_stats_RBStats_txPduBytes_force_add(B, tmp++);
+      //rlc_stats_RBStats_rxPduBytes_force_add(B, tmp++);
+      //if (style->type == RLC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        //rlc_stats_RBStats_txPduDdBytes_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduDdBytes_force_add(B, tmp++);
+        rlc_stats_RBStats_txBufOccBytes_force_add(B, rlc_stats.bytes_in_buffer);
+        //rlc_stats_RBStats_rxBufOccBytes_force_add(B, tmp++);
+      //}
+      //rlc_stats_RBStats_txPduRetxBytes_force_add(B, tmp++);
+      if (style->type == RLC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        //rlc_stats_RBStats_rxPduOwBytes_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduDupBytes_force_add(B, tmp++);
+      }
+      //rlc_stats_RBStats_txPduPkts_force_add(B, tmp++);
+      //rlc_stats_RBStats_rxPduPkts_force_add(B, tmp++);
+      if (style->type == RLC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        //rlc_stats_RBStats_txPduDdPkts_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduDdPkts_force_add(B, tmp++);
+      }
+      rlc_stats_RBStats_txBufOccPkts_force_add(B, rlc_stats.pdus_in_buffer);
+      //rlc_stats_RBStats_rxBufOccPkts_force_add(B, tmp++);
+      //rlc_stats_RBStats_txPduRetxPkts_force_add(B, tmp++);
+      if (style->type == RLC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        rlc_stats_RBStats_txBufWdMs_force_add(B, 1337);
+        //rlc_stats_RBStats_rxPduOwPkts_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduDupPkts_force_add(B, tmp++);
+        rlc_stats_RBStats_txPduWtMs_force_add(B, 1337);
+        //rlc_stats_RBStats_rxPduRotoutMs_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduPotoutMs_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduSptoutMs_force_add(B, tmp++);
+      }
+      rlc_stats_RBStats_rbid_force_add(B, lcid);
+      rlc_stats_RBStats_vec_push_end(B);
+    }
+    rlc_stats_UEStats_rb_end(B);
+    rlc_stats_UEStats_rnti_force_add(B, rnti);
+    rlc_stats_UEStats_vec_push_end(B);
+  }
+  rlc_stats_IndicationMessage_ueStats_end(B);
+  rlc_stats_IndicationMessage_end_as_root(B);
+}
+
+void pdcp_gen_hdr(flatcc_builder_t* B)
+{
+  pdcp_stats_IndicationHeader_start(B);
+  pdcp_stats_IndicationHeader_frame_force_add(B, pdcp_enb[mod_id].frame);
+  pdcp_stats_IndicationHeader_slot_force_add(B, pdcp_enb[mod_id].subframe);
+  pdcp_stats_IndicationHeader_end_as_root(B);
+}
+
+void pdcp_gen_msg(flatcc_builder_t* B, const pdcp_stats_report_style_t* style)
+{
+  assert(style->type == PDCP_STATS_REPORT_STYLE_TYPE_MINIMAL);
+  pdcp_stats_IndicationMessage_start(B);
+  pdcp_stats_IndicationMessage_ueStats_start(B);
+  for (int pdcp_uid = 0; pdcp_uid < MAX_MOBILES_PER_ENB; ++pdcp_uid) {
+    if (pdcp_enb[0].rnti[pdcp_uid] == 0)
+      continue;
+    // add in the order of pdcp_UEStats_create
+    pdcp_stats_UEStats_vec_push_start(B);
+    pdcp_stats_UEStats_rb_start(B);
+    for (size_t lcid = 3; lcid < 4; ++lcid) {
+      // add in the order of pdcp_RBStats_create
+      pdcp_stats_RBStats_vec_push_start(B);
+      pdcp_stats_RBStats_txPduPkts_force_add(B, Pdcp_stats_tx[mod_id][pdcp_uid][lcid]);
+      pdcp_stats_RBStats_rxPduPkts_force_add(B, Pdcp_stats_rx[mod_id][pdcp_uid][lcid]);
+      pdcp_stats_RBStats_txPduBytes_force_add(B, Pdcp_stats_tx_bytes[mod_id][pdcp_uid][lcid]);
+      pdcp_stats_RBStats_rxPduBytes_force_add(B, Pdcp_stats_rx_bytes[mod_id][pdcp_uid][lcid]);
+      pdcp_stats_RBStats_txPduSn_force_add(B, Pdcp_stats_tx_sn[mod_id][pdcp_uid][lcid]);
+      pdcp_stats_RBStats_rxPduSn_force_add(B, Pdcp_stats_rx_sn[mod_id][pdcp_uid][lcid]);
+      pdcp_stats_RBStats_rbid_force_add(B, lcid);
+      pdcp_stats_RBStats_vec_push_end(B);
+    }
+    pdcp_stats_UEStats_rb_end(B);
+    pdcp_stats_UEStats_rnti_add(B, pdcp_enb[mod_id].rnti[pdcp_uid]);
+    pdcp_stats_UEStats_vec_push_end(B);
+  }
+  pdcp_stats_IndicationMessage_ueStats_end(B);
+  pdcp_stats_IndicationMessage_end_as_root(B);
+}
+
+rrc_common_Plmn_ref_t create_short_plmn(flatcc_builder_t* B, uint16_t mcc, uint16_t mnc, uint8_t mnc_length)
+{
+  // Note: in order of rrc_common_Plmn_create()
+  rrc_common_Plmn_start(B);
+  rrc_common_Plmn_mcc_force_add(B, mcc);
+  rrc_common_Plmn_mnc_force_add(B, mnc);
+  rrc_common_Plmn_mnc_length_force_add(B, mnc_length);
+  return rrc_common_Plmn_end(B);
+}
+
+void fill_rrc_conf_msg(flatcc_builder_t* B, const rrc_conf_report_style_t* style)
+{
+  assert(B);
+  assert(style->type == RRC_CONF_REPORT_STYLE_TYPE_MINIMAL || style->type == RRC_CONF_REPORT_STYLE_TYPE_COMPLETE);
+  const RrcConfigurationReq* rrc_conf = &RC.rrc[mod_id]->configuration;
+  rrc_conf_IndicationMessage_start(B);
+  rrc_conf_IndicationMessage_bsStats_start(B);
+  // Note: add in order of rrc_conf_BSStats_create()
+    if (RC.rrc[mod_id]->node_name)
+      rrc_conf_BSStats_baseStationName_create_str(B, RC.rrc[mod_id]->node_name);
+    rrc_conf_BSStats_plmnInfo_start(B);
+    for (size_t i = 0; i < rrc_conf->num_plmn; ++i) {
+      rrc_common_Plmn_ref_t plmn = create_short_plmn(B, rrc_conf->mcc[i], rrc_conf->mnc[i], rrc_conf->mnc_digit_length[i]);
+      rrc_conf_BSStats_plmnInfo_push_create(B, plmn, rrc_conf->tac, /* no ranac */0, rrc_conf->cell_identity);
+    }
+    rrc_conf_BSStats_plmnInfo_end(B);
+    rrc_conf_BSStats_carriers_start(B);
+    /* OAI currently only supports one CC */
+    for (size_t cc = 0; cc < 1; ++cc) {
+      // Note: add in order of rrc_conf_CarrierInfo_create()
+      rrc_conf_CarrierInfo_vec_push_start(B);
+      rrc_conf_CarrierInfo_dlFreqHz_add(B, rrc_conf->downlink_frequency[cc]);
+      rrc_conf_CarrierInfo_ulFreqHz_add(B, rrc_conf->downlink_frequency[cc] + rrc_conf->uplink_frequency_offset[cc]);
+      if (style->type == RRC_CONF_REPORT_STYLE_TYPE_COMPLETE) {
+        //rrc_conf_CarrierInfo_lte_add();
+      }
+      rrc_conf_CarrierInfo_phyCellId_force_add(B, rrc_conf->Nid_cell[cc]);
+      rrc_conf_CarrierInfo_band_add(B, rrc_conf->eutra_band[cc]);
+      rrc_conf_CarrierInfo_dlBandwidthPrb_add(B, rrc_conf->N_RB_DL[cc]);
+      rrc_conf_CarrierInfo_ulBandwidthPrb_add(B, rrc_conf->N_RB_DL[cc]);
+      rrc_conf_CarrierInfo_txAntennaPorts_add(B, rrc_conf->nb_antenna_ports[cc]);
+      rrc_conf_CarrierInfo_rxAnennaPorts_add(B, rrc_conf->nb_antenna_ports[cc]);
+      rrc_conf_CarrierInfo_vec_push_end(B);
+    }
+    rrc_conf_BSStats_carriers_end(B);
+    rrc_conf_BSStats_rat_force_add(B, rrc_common_RAT_LTE);
+  rrc_conf_IndicationMessage_bsStats_end(B);
+  rrc_conf_IndicationMessage_end_as_root(B);
+}
+
+void fill_rrc_stats_msg(struct flatcc_builder* B, const rrc_stats_report_style_t* style, void* ctxt)
+{
+  assert(B);
+  assert(ctxt);
+  assert(style->type == RRC_STATS_REPORT_STYLE_TYPE_MINIMAL);
+
+  const rrc_eNB_ue_context_t* ue_ctxt = (rrc_eNB_ue_context_t*)ctxt;
+  const LTE_MeasResults_t* measResults = ue_ctxt->ue_context.measResults;
+
+  rrc_stats_IndicationMessage_start(B);
+  rrc_stats_IndicationMessage_measReport_start(B);
+  // only a single measReport. The point of the list is to accumulate them in
+  // the controller
+  // Note: add in order of rrc_stats_MeasReport_create()
+
+    rrc_stats_MeasReport_vec_push_start(B);
+    rrc_stats_MeasReport_measId_force_add(B, measResults->measId);
+    rrc_stats_MeasReport_pCellResult_create(B,
+          measResults->measResultPCell.rsrpResult - 140,
+          (float) measResults->measResultPCell.rsrqResult / 2 - 20,
+          0);
+
+    if (measResults->measResultNeighCells
+        && measResults->measResultNeighCells->present == LTE_MeasResults__measResultNeighCells_PR_measResultListEUTRA) {
+      rrc_stats_MeasReport_neighMeas_start(B);
+      const LTE_MeasResultListEUTRA_t* lte_measResult = &measResults->measResultNeighCells->choice.measResultListEUTRA;
+      for (size_t j = 0; j < lte_measResult->list.count; ++j) {
+        const LTE_MeasResultEUTRA_t* r = lte_measResult->list.array[j];
+        rrc_stats_NeighMeas_vec_push_start(B);
+        // Note: add in order of rrc_stats_NeighMeas_create()
+        //rrc_common_Plmn_ref_t plmn = create_short_plmn(B, 208, 95, 2);
+        //rrc_stats_NeighMeas_plmnInfo_create(B, plmn, 0, 0, 507);
+        long rsrp = r->measResult.rsrpResult ? *r->measResult.rsrpResult - 140 : -42;
+        long rsrq = r->measResult.rsrqResult ? (float) *r->measResult.rsrqResult / 2 - 20 : -42;
+        rrc_stats_NeighMeas_measResult_create(B, rsrp, rsrq, 0);
+        rrc_stats_NeighMeas_phyCellId_force_add(B, r->physCellId);
+        rrc_stats_NeighMeas_rat_force_add(B, rrc_common_RAT_LTE);
+        rrc_stats_NeighMeas_vec_push_end(B);
+      }
+      rrc_stats_MeasReport_neighMeas_end(B);
+    }
+
+    rrc_stats_MeasReport_vec_push_end(B);
+
+  rrc_stats_IndicationMessage_measReport_end(B);
+  rrc_stats_IndicationMessage_end_as_root(B);
+}
+
+void rrc_event_fill_attach_msg(struct flatcc_builder* B, const rrc_event_report_style_t* style, void* selected_plmn_id)
+{
+  assert(B);
+  rrc_event_IndicationMessage_start(B);
+  // in order rrc_event_IndicationMessage_create()
+  rrc_event_IndicationMessage_rat_force_add(B, rrc_common_RAT_LTE);
+
+  if (selected_plmn_id)
+    rrc_event_IndicationMessage_selectedPlmnId_force_add(B, *(long*)selected_plmn_id);
+  rrc_event_IndicationMessage_end_as_root(B);
+}
+
+void rrc_event_fill_complete_msg(struct flatcc_builder* B, const rrc_event_report_style_t* style, void *ctxt)
+{
+  assert(B);
+  assert(ctxt);
+  rrc_event_IndicationMessage_start(B);
+  // in order rrc_event_IndicationMessage_create()
+  //rrc_event_IndicationMessage_imsi_create_str(B, "");
+  rrc_event_IndicationMessage_rat_force_add(B, rrc_common_RAT_LTE);
+  rrc_event_IndicationMessage_end_as_root(B);
+}
+
+static
+global_e2_node_id_t get_node_id(void)
+{
+  assert(RC.rrc[mod_id]);
+  const plmn_t plmn = {
+    .mcc = RC.rrc[mod_id]->configuration.mcc[CC_id],
+    .mnc = RC.rrc[mod_id]->configuration.mnc[CC_id],
+    .mnc_digit_len = RC.rrc[mod_id]->configuration.mnc_digit_length[CC_id]
+  };
+  const global_e2_node_id_t ge2ni = {
+    .type = ngran_gNB,
+    .plmn = plmn,
+    .nb_id = RC.rrc[mod_id]->configuration.Nid_cell[CC_id]
+  };
+  return ge2ni;
+}
+
+void* start_agent(void* arg)
+{
+  e2ap_agent_t* flexric_ag = (e2ap_agent_t*) arg;
+  e2ap_start_agent(flexric_ag); /* blocking */
+  return NULL;
+}
+
+void flexric_start(void)
+{
+  printf("***********************************\n");
+  printf("****** STARTING FLEXRIC AGENT *****\n");
+  printf("***********************************\n");
+
+  const char* ip = "192.168.12.246";
+  const uint16_t port = 36421;
+
+  flexric_ag = e2ap_init_agent(ip, port, get_node_id());
+
+  const mac_stats_report_style_t mac_style[2] = {
+    { .type = MAC_STATS_REPORT_STYLE_TYPE_MINIMAL },
+    { .type = MAC_STATS_REPORT_STYLE_TYPE_COMPLETE }
+  };
+  mac_stats_callbacks_t mac_cb = {
+    .hdr = mac_gen_hdr,
+    .msg = mac_gen_msg
+  };
+  sm_mac_stats_register_ran_function(flexric_ag, mac_cb, mac_style, 2);
+
+  const mac_rslicing_SliceAlgorithm_enum_t algos[3] = {
+    mac_rslicing_SliceAlgorithm_None,
+    mac_rslicing_SliceAlgorithm_Static
+  };
+  rslicing_cb_t rslicing_cb = {
+    .read = rslicing_read_slice_conf,
+    .add_mod = rslicing_handle_add_mod_slice_command,
+    .del = rslicing_handle_del_slice_command,
+    .ue_assoc = rslicing_handle_ue_assoc_command
+  };
+  sm_mac_rslicing_register_ran_function(flexric_ag, algos, 3, rslicing_cb);
+
+  const rlc_stats_report_style_t rlc_style = { .type = RLC_STATS_REPORT_STYLE_TYPE_MINIMAL };
+  rlc_stats_callbacks_t rlc_cb = {
+    .hdr = rlc_gen_hdr,
+    .msg = rlc_gen_msg
+  };
+  sm_rlc_stats_register_ran_function(flexric_ag, rlc_cb, &rlc_style, 1);
+
+  const pdcp_stats_report_style_t pdcp_style = { .type = PDCP_STATS_REPORT_STYLE_TYPE_MINIMAL };
+  pdcp_stats_callbacks_t pdcp_cb = {
+    .hdr = pdcp_gen_hdr,
+    .msg = pdcp_gen_msg
+  };
+  sm_pdcp_stats_register_ran_function(flexric_ag, pdcp_cb, &pdcp_style, 1);
+
+  const rrc_stats_report_style_t rrc_stats_style = { .type = RRC_STATS_REPORT_STYLE_TYPE_MINIMAL };
+  sm_rrc_stats_register_ran_function(flexric_ag, &rrc_stats_style, 1);
+
+  const rrc_conf_report_style_t rrc_conf_style = { .type = RRC_CONF_REPORT_STYLE_TYPE_MINIMAL };
+  sm_rrc_conf_register_ran_function(flexric_ag, fill_rrc_conf_msg, &rrc_conf_style, 1);
+
+  const rrc_event_report_style_t style = { .type = rrc_event_ReportStyleType_Minimal };
+  sm_rrc_event_register_ran_function(flexric_ag, &style, 1);
+
+  pthread_t t_agent;
+  int rc = pthread_create(&t_agent, NULL, start_agent, flexric_ag);
+  assert(rc == 0);
+}
+
+void flexric_stop(void)
+{
+  e2ap_free_agent(flexric_ag);
+}
diff --git a/openair2/GNB_APP/flexric_agent_nsa.c b/openair2/GNB_APP/flexric_agent_nsa.c
new file mode 100644
index 0000000000..e15bd12470
--- /dev/null
+++ b/openair2/GNB_APP/flexric_agent_nsa.c
@@ -0,0 +1,770 @@
+#include <assert.h>
+#include <pthread.h>
+
+/* the define redefines the definition of plmn_t that is pulled through
+ * ran_context.h */
+#define plmn_t plmn_t_WE_DONT_NEED
+#include "common/ran_context.h"
+extern RAN_CONTEXT_t RC;
+#undef plmn_t
+
+//#include "RRC/LTE/rrc_eNB_UE_context.h"
+//#include "pdcp.h"
+
+#include "openair2/LAYER2/NR_MAC_gNB/nr_mac_gNB.h"
+#include "openair2/LAYER2/NR_MAC_gNB/mac_proto.h"
+#include "openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.h"
+#include "LAYER2/nr_rlc/nr_rlc_entity.h"
+#include "LAYER2/nr_pdcp/nr_pdcp_entity.h"
+
+#include "flexric_agent.h"
+#include "mac_stats_rf.h"
+#include "rslicing_rf.h"
+#include "rlc_stats_rf.h"
+#include "pdcp_stats_rf.h"
+//#include "rrc_stats_rf.h"
+#include "rrc_conf_rf.h"
+
+e2ap_agent_t* flexric_ag;
+static const int mod_id = 0;
+static const int CC_id = 0;
+
+static
+void mac_gen_hdr(flatcc_builder_t* B)
+{
+  mac_stats_IndicationHeader_start(B);
+  mac_stats_IndicationHeader_frame_force_add(B, RC.nrmac[mod_id]->frame);
+  mac_stats_IndicationHeader_slot_force_add(B, RC.nrmac[mod_id]->slot);
+  mac_stats_IndicationHeader_end_as_root(B);
+}
+
+static
+void mac_gen_msg(flatcc_builder_t* B, const mac_stats_report_style_t* style)
+{
+  const NR_UE_info_t* UE_info = &RC.nrmac[mod_id]->UE_info;
+  const size_t num_ues = UE_info->num_UEs;
+  mac_stats_IndicationMessage_start(B);
+  mac_stats_IndicationMessage_ueStats_start(B);
+  const NR_list_t* ue_list = &UE_info->list;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    const NR_mac_stats_t* uestats = &UE_info->mac_stats[ue_id];
+    const NR_UE_sched_ctrl_t* sched_ctrl = &UE_info->UE_sched_ctrl[ue_id];
+    mac_stats_UEStats_vec_push_start(B);
+    mac_stats_UEStats_dlAggrPrb_force_add(B, uestats->dlsch_total_rbs);
+    mac_stats_UEStats_ulAggrPrb_force_add(B, uestats->ulsch_total_rbs);
+    mac_stats_UEStats_dlAggrTbs_force_add(B, uestats->dlsch_total_bytes);
+    mac_stats_UEStats_ulAggrTbs_force_add(B, uestats->ulsch_total_bytes_rx);
+    mac_stats_UEStats_dlAggrSdus_force_add(B, uestats->dlsch_num_mac_sdu);
+    mac_stats_UEStats_ulAggrSdus_force_add(B, uestats->ulsch_num_mac_sdu);
+    /* handles only default DRB -> 3 */
+    mac_stats_UEStats_dlAggrBytesSdus_force_add(B, uestats->lc_bytes_tx[3]);
+    mac_stats_UEStats_ulAggrBytesSdus_force_add(B, uestats->lc_bytes_rx[3]);
+    mac_stats_UEStats_dlAggrRetxPrb_force_add(B, uestats->dlsch_total_rbs_retx);
+    mac_stats_UEStats_ulAggrRetxPrb_force_add(B, uestats->ulsch_total_rbs_retx);
+    if (style->type == MAC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+      mac_stats_UEStats_puschSnr_force_add(B, (float) sched_ctrl->pusch_snrx10 / 10);
+      mac_stats_UEStats_pucchSnr_force_add(B, (float) sched_ctrl->pucch_snrx10 / 10);
+
+      mac_stats_UEStats_bsr_start(B);
+      const uint8_t lcgid = 0;
+      const uint32_t bufferSize = sched_ctrl->estimated_ul_buffer - sched_ctrl->sched_ul_bytes;
+      mac_stats_UEStats_bsr_push_create(B, lcgid, bufferSize);
+      mac_stats_UEStats_bsr_end(B);
+
+      const size_t numDlHarq = 4;
+      mac_stats_UEStats_dlHarq_start(B);
+      uint32_t* v = mac_stats_UEStats_dlHarq_extend(B, numDlHarq);
+      for (uint8_t j = 0; j < numDlHarq; ++j)
+        v[j] = uestats->dlsch_rounds[j];
+      mac_stats_UEStats_dlHarq_end(B);
+
+      const size_t numUlHarq = 4;
+      mac_stats_UEStats_ulHarq_start(B);
+      uint32_t* w = mac_stats_UEStats_ulHarq_extend(B, numUlHarq);
+      for (uint8_t j = 0; j < numUlHarq; ++j)
+        w[j] = uestats->ulsch_rounds[j];
+      mac_stats_UEStats_ulHarq_end(B);
+    }
+    mac_stats_UEStats_rnti_force_add(B, UE_info->rnti[ue_id]);
+    if (style->type == MAC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+      // no CQI measurements implemented in OAI yet
+      //mac_stats_UEStats_wbCqi_add(B, 3);
+      mac_stats_UEStats_dlMcs1_force_add(B, sched_ctrl->sched_pdsch.mcs);
+      mac_stats_UEStats_ulMcs1_force_add(B, sched_ctrl->sched_pusch.mcs);
+      //mac_stats_UEStats_dlMcs2_force_add(B, 0);
+      //mac_stats_UEStats_ulMcs2_force_add(B, 0);
+      mac_stats_UEStats_phr_force_add(B, sched_ctrl->ph);
+    }
+    mac_stats_UEStats_vec_push_end(B);
+  }
+  mac_stats_IndicationMessage_ueStats_end(B);
+  mac_stats_IndicationMessage_end_as_root(B);
+}
+
+static
+void rslicing_get_slice_configuration(flatcc_builder_t* B, size_t idx, mac_rslicing_SliceAlgorithm_enum_t algo)
+{
+  nr_slice_t *s_ = RC.nrmac[mod_id]->pre_processor_dl.slices->s[idx];
+
+  mac_rslicing_Slice_vec_push_start(B);
+  // in order of mac_rslicing_Slice_create()
+  mac_rslicing_Slice_id_force_add(B, s_->id);
+  if (s_->label) {
+    flatbuffers_string_ref_t label = flatbuffers_string_create_str(B, s_->label);
+    mac_rslicing_Slice_label_add(B, label);
+  }
+  flatbuffers_string_ref_t scheduler = flatbuffers_string_create_str(B, s_->dl_algo.name);
+  mac_rslicing_Slice_scheduler_add(B, scheduler);
+
+  mac_rslicing_SliceParams_union_ref_t p;
+  switch (algo) {
+    case mac_rslicing_SliceAlgorithm_NVS: {
+        if (((nvs_nr_slice_param_t *)s_->algo_data)->type == NVS_RATE) {
+          const float rsvd = ((nvs_nr_slice_param_t *)s_->algo_data)->Mbps_reserved;
+          const float ref = ((nvs_nr_slice_param_t *)s_->algo_data)->Mbps_reference;
+          mac_rslicing_NvsRate_ref_t nvsrate = mac_rslicing_NvsRate_create(B, rsvd, ref);
+          mac_rslicing_NvsSliceConfig_union_ref_t unvsrate = mac_rslicing_NvsSliceConfig_as_rate(nvsrate);
+          mac_rslicing_NvsSlice_ref_t nvs1 = mac_rslicing_NvsSlice_create(B, unvsrate);
+          p = mac_rslicing_SliceParams_as_nvs(nvs1);
+        } else {
+          const float rsvd = ((nvs_nr_slice_param_t *)s_->algo_data)->pct_reserved;
+          mac_rslicing_NvsCapacity_ref_t nvscap = mac_rslicing_NvsCapacity_create(B, rsvd);
+          mac_rslicing_NvsSliceConfig_union_ref_t unvscap = mac_rslicing_NvsSliceConfig_as_capacity(nvscap);
+          mac_rslicing_NvsSlice_ref_t nvs2 = mac_rslicing_NvsSlice_create(B, unvscap);
+          p = mac_rslicing_SliceParams_as_nvs(nvs2);
+        }
+      }
+      break;
+    case mac_rslicing_SliceAlgorithm_None:
+    default:
+      assert(0 && "illegal code path");
+      break;
+  }
+  mac_rslicing_Slice_params_add(B, p);
+  mac_rslicing_Slice_vec_push_end(B);
+}
+
+static
+mac_rslicing_SliceAlgorithm_enum_t rslicing_get_slice_algorithm(int algo)
+{
+  switch (algo) {
+    case NVS_SLICING:
+      return mac_rslicing_SliceAlgorithm_NVS;
+    default:
+      return mac_rslicing_SliceAlgorithm_None;
+  }
+}
+
+static
+void rslicing_read_slice_conf(flatcc_builder_t* B)
+{
+  gNB_MAC_INST *nrmac = RC.nrmac[mod_id];
+  assert(nrmac);
+  nr_pp_impl_param_dl_t* pp_dl = &RC.nrmac[mod_id]->pre_processor_dl;
+
+  mac_rslicing_IndicationMessage_start(B);
+  mac_rslicing_IndicationMessage_sliceConfig_start(B);
+    mac_rslicing_SliceConfig_dl_start(B);
+      mac_rslicing_SliceAlgorithm_enum_t dl_algo = rslicing_get_slice_algorithm(nrmac->pre_processor_dl.algorithm);
+      mac_rslicing_UlDlSliceConfig_algorithm_force_add(B, dl_algo);
+      size_t n_dl_slices = pp_dl->slices ? pp_dl->slices->num : 0;
+      if (n_dl_slices > 0) {
+        mac_rslicing_UlDlSliceConfig_slices_start(B);
+        for (size_t i = 0; i < n_dl_slices; ++i)
+          rslicing_get_slice_configuration(B, i, dl_algo);
+        mac_rslicing_UlDlSliceConfig_slices_end(B);
+      } else {
+        flatbuffers_string_ref_t sched_dl = flatbuffers_string_create_str(B, pp_dl->dl_algo.name);
+        mac_rslicing_UlDlSliceConfig_scheduler_add(B, sched_dl);
+      }
+    mac_rslicing_SliceConfig_dl_end(B);
+
+    // TODO: UL
+  mac_rslicing_IndicationMessage_sliceConfig_end(B);
+
+  mac_rslicing_IndicationMessage_ueSliceConfig_start(B);
+  mac_rslicing_UeSliceConfig_ues_start(B);
+  const NR_UE_info_t* ue_info = &RC.nrmac[mod_id]->UE_info;
+  const NR_list_t* ue_list = &ue_info->list;
+  const nr_slice_info_t *dl_slices = RC.nrmac[mod_id]->pre_processor_dl.slices;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    const uint32_t rnti = ue_info->rnti[ue_id];
+    // in order of mac_rslicing_UeSliceAssoc_create()
+    mac_rslicing_UeSliceAssoc_start(B);
+    if (dl_algo != mac_rslicing_SliceAlgorithm_None) {
+      const int dl_slice_idx = dl_slices->UE_assoc_slice[ue_id];
+      if (dl_slice_idx >= 0) { // is associated to a slice
+        const uint32_t dlslice = dl_slices->s[dl_slice_idx]->id;
+        mac_rslicing_UeSliceAssoc_dlId_force_add(B, dlslice);
+      }
+    }
+    // TODO UL
+    mac_rslicing_UeSliceAssoc_rnti_force_add(B, rnti);
+    mac_rslicing_UeSliceConfig_ues_push(B, mac_rslicing_UeSliceAssoc_end(B));
+  }
+  mac_rslicing_UeSliceConfig_ues_end(B);
+  mac_rslicing_IndicationMessage_ueSliceConfig_end(B);
+  mac_rslicing_IndicationMessage_end_as_root(B);
+}
+
+static
+void rslicing_set_new_dl_slice_algo(mac_rslicing_SliceAlgorithm_enum_t algo)
+{
+  gNB_MAC_INST *nrmac = RC.nrmac[mod_id];
+  assert(nrmac);
+
+  nr_pp_impl_param_dl_t dl = nrmac->pre_processor_dl;
+  switch (algo) {
+    case mac_rslicing_SliceAlgorithm_NVS:
+      nrmac->pre_processor_dl = nvs_nr_dl_init(mod_id, CC_id);
+      break;
+    default:
+      nrmac->pre_processor_dl.algorithm = 0;
+      nrmac->pre_processor_dl = nr_init_fr1_dlsch_preprocessor(mod_id, CC_id);
+      nrmac->pre_processor_dl.slices = NULL;
+      break;
+  }
+  if (dl.slices)
+    dl.destroy(&dl.slices);
+  if (dl.dl_algo.data)
+    dl.dl_algo.unset(&dl.dl_algo.data);
+}
+
+static
+int rslicing_add_mod_dl_slice(mac_rslicing_SliceAlgorithm_enum_t current_algo, mac_rslicing_Slice_table_t slice)
+{
+  void *params = NULL;
+  mac_rslicing_SliceParams_union_t p = mac_rslicing_Slice_params_union(slice);
+  switch (p.type) {
+    case mac_rslicing_SliceParams_nvs: {
+        assert(current_algo == mac_rslicing_SliceAlgorithm_NVS);
+        params = malloc(sizeof(nvs_nr_slice_param_t));
+        if (!params) return -1;
+        mac_rslicing_NvsSlice_table_t nvs = p.value;
+        mac_rslicing_NvsSliceConfig_union_t unvs = mac_rslicing_NvsSlice_config_union(nvs);
+        if (unvs.type == mac_rslicing_NvsSliceConfig_rate) {
+          mac_rslicing_NvsRate_table_t rate = unvs.value;
+          ((nvs_nr_slice_param_t *)params)->type = NVS_RATE;
+          ((nvs_nr_slice_param_t *)params)->Mbps_reserved = mac_rslicing_NvsRate_mbpsRequired(rate);
+          ((nvs_nr_slice_param_t *)params)->Mbps_reference = mac_rslicing_NvsRate_mbpsReference(rate);
+        } else {
+          assert(unvs.type == mac_rslicing_NvsSliceConfig_capacity);
+          mac_rslicing_NvsCapacity_table_t cap = unvs.value;
+          ((nvs_nr_slice_param_t *)params)->type = NVS_RES;
+          ((nvs_nr_slice_param_t *)params)->pct_reserved = mac_rslicing_NvsCapacity_pctReserved(cap);
+        }
+      }
+      break;
+    default:
+      LOG_E(MAC, "unhandled slicing type\n");
+      return -1000;
+      break;
+  }
+  nr_pp_impl_param_dl_t *dl = &RC.nrmac[mod_id]->pre_processor_dl;
+  void *algo = &dl->dl_algo; // default scheduler
+  if (mac_rslicing_Slice_scheduler_is_present(slice)) {
+    LOG_W(MAC, "ignoring scheduler %s\n", mac_rslicing_Slice_scheduler(slice));
+  }
+  char *l = NULL;
+  if (mac_rslicing_Slice_label_is_present(slice))
+      l = strdup(mac_rslicing_Slice_label(slice));
+  uint8_t sid = mac_rslicing_Slice_id(slice);
+  return dl->addmod_slice(dl->slices, sid, l, algo, params);
+}
+
+static
+int rslicing_find_dl_slice(uint32_t id)
+{
+  nr_slice_info_t *si = RC.nrmac[mod_id]->pre_processor_dl.slices;
+  for (int i = 0; i < si->num; ++i)
+    if (si->s[i]->id == id)
+      return i;
+  return -1;
+}
+
+static
+int rslicing_del_dl_slice(uint32_t id)
+{
+  const int idx = rslicing_find_dl_slice(id);
+  if (idx < 0)
+    return -1;
+  nr_pp_impl_param_dl_t *dl = &RC.nrmac[mod_id]->pre_processor_dl;
+  return dl->remove_slice(dl->slices, idx);
+}
+
+static
+rslicing_rc_t rslicing_handle_add_mod_slice_command(mac_rslicing_AddModSliceCommand_table_t t)
+{
+  assert(t);
+
+  gNB_MAC_INST *nrmac = RC.nrmac[mod_id];
+  assert(nrmac);
+  nr_pp_impl_param_dl_t* pp_dl = &RC.nrmac[mod_id]->pre_processor_dl;
+
+  mac_rslicing_SliceConfig_table_t new_sc = mac_rslicing_AddModSliceCommand_sliceConfig(t);
+  if (mac_rslicing_SliceConfig_dl_is_present(new_sc)) {
+    mac_rslicing_UlDlSliceConfig_table_t dl = mac_rslicing_SliceConfig_dl(new_sc);
+    mac_rslicing_SliceAlgorithm_enum_t current_algo = rslicing_get_slice_algorithm(nrmac->pre_processor_dl.algorithm);
+    mac_rslicing_SliceAlgorithm_enum_t new_algo = mac_rslicing_UlDlSliceConfig_algorithm(dl);
+    pthread_mutex_lock(&nrmac->pp_mutex);
+    if (mac_rslicing_UlDlSliceConfig_algorithm_is_present(dl)
+        && current_algo != new_algo) {
+      rslicing_set_new_dl_slice_algo(new_algo);
+      current_algo = new_algo;
+      LOG_I(MAC, "set new algorithm %s\n", mac_rslicing_SliceAlgorithm_name(new_algo));
+    }
+
+    mac_rslicing_Slice_vec_t slices = mac_rslicing_UlDlSliceConfig_slices(dl);
+    size_t slices_len = mac_rslicing_Slice_vec_len(slices);
+    for (size_t i = 0; i < slices_len; ++i) {
+      mac_rslicing_Slice_table_t slice = mac_rslicing_Slice_vec_at(slices, i);
+      const int rc = rslicing_add_mod_dl_slice(current_algo, slice);
+      if (rc < 0) {
+        pthread_mutex_unlock(&nrmac->pp_mutex);
+        LOG_E(MAC, "error code %d while updating slices\n", rc);
+        return (rslicing_rc_t) { .success = false, .error_msg = strdup("error updating slices") };
+      }
+    }
+    pthread_mutex_unlock(&nrmac->pp_mutex);
+  }
+  if (mac_rslicing_SliceConfig_ul_is_present(new_sc))
+    LOG_W(MAC, "*** Ignoring UL slice configuration\n");
+  return (rslicing_rc_t) { .success = true, .error_msg = NULL };
+}
+
+static
+rslicing_rc_t rslicing_handle_del_slice_command(mac_rslicing_DelSliceCommand_table_t t)
+{
+  gNB_MAC_INST *nrmac = RC.nrmac[mod_id];
+  assert(nrmac);
+
+  mac_rslicing_DelSliceConfig_table_t dsc = mac_rslicing_DelSliceCommand_delSliceConfig(t);
+  flatbuffers_uint32_vec_t ul_ids = mac_rslicing_DelSliceConfig_ul(dsc);
+  size_t n_ul_ids = flatbuffers_uint32_vec_len(ul_ids);
+  if (n_ul_ids > 0)
+    LOG_E(MAC, "ignoring dl slice command for ul slices\n");
+
+  flatbuffers_uint32_vec_t dl_ids = mac_rslicing_DelSliceConfig_dl(dsc);
+  size_t n_dl_ids = flatbuffers_uint32_vec_len(dl_ids);
+  if (n_dl_ids == 0)
+    return (rslicing_rc_t) { .success = true, .error_msg = NULL };
+
+  pthread_mutex_lock(&nrmac->pp_mutex);
+  for (size_t i = 0; i < n_dl_ids; ++i) {
+    LOG_I(MAC, "attempt to delete slice ID %d\n", dl_ids[i]);
+    const int rc = rslicing_del_dl_slice(dl_ids[i]);
+    if (rc < 0) {
+      pthread_mutex_unlock(&nrmac->pp_mutex);
+      LOG_E(MAC, "error code %d while deleting slice ID %d\n", rc, dl_ids[i]);
+      return (rslicing_rc_t) { .success = false, .error_msg = strdup("error deleting slices") };
+    }
+  }
+  pthread_mutex_unlock(&nrmac->pp_mutex);
+  return (rslicing_rc_t) { .success = true, .error_msg = NULL };
+}
+
+static
+int rslicing_get_ue_id(uint16_t rnti)
+{
+  const NR_UE_info_t* ue_info = &RC.nrmac[mod_id]->UE_info;
+  const NR_list_t* ue_list = &ue_info->list;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    if (ue_info->rnti[ue_id] == rnti)
+      return ue_id;
+  }
+  return -1;
+}
+
+static
+int rslicing_associate_ue_to_dl_slice(uint16_t rnti, uint32_t id)
+{
+  int idx = rslicing_find_dl_slice(id);
+  if (idx < 0)
+    return -100;
+  int ue_id = rslicing_get_ue_id(rnti);
+  if (ue_id < 0)
+    return -101;
+  LOG_I(MAC, "associate UE RNTI %04x ID %d to slice ID %d idx %d\n",
+        rnti, ue_id, id, idx);
+  nr_pp_impl_param_dl_t *dl = &RC.nrmac[mod_id]->pre_processor_dl;
+  dl->move_UE(dl->slices, ue_id, idx);
+  return 0;
+}
+
+static
+rslicing_rc_t rslicing_handle_ue_assoc_command(mac_rslicing_UeSliceAssocCommand_table_t t)
+{
+  gNB_MAC_INST *nrmac = RC.nrmac[mod_id];
+  assert(nrmac);
+
+  mac_rslicing_UeSliceConfig_table_t new_uesc = mac_rslicing_UeSliceAssocCommand_ueSliceConfig(t);
+  mac_rslicing_UeSliceAssoc_vec_t new_ues = mac_rslicing_UeSliceConfig_ues(new_uesc);
+  size_t n_new_ues = mac_rslicing_UeSliceAssoc_vec_len(new_ues);
+  for (size_t i = 0; i < n_new_ues; ++i) {
+    mac_rslicing_UeSliceAssoc_table_t uesa = mac_rslicing_UeSliceAssoc_vec_at(new_ues, i);
+    uint16_t rnti = mac_rslicing_UeSliceAssoc_rnti(uesa);
+    if (mac_rslicing_UeSliceAssoc_ulId_is_present(uesa))
+      LOG_W(MAC, "ignoring UL slice association for RNTI %04x\n", rnti);
+    if (!mac_rslicing_UeSliceAssoc_dlId_is_present(uesa)) {
+      pthread_mutex_unlock(&nrmac->pp_mutex);
+      LOG_E(MAC, "expected DL slice association for UE RNTI %04x\n", rnti);
+      return (rslicing_rc_t) { .success = false, .error_msg = strdup("error associating UEs") };
+    }
+    uint32_t id = mac_rslicing_UeSliceAssoc_dlId(uesa);
+    int rc = rslicing_associate_ue_to_dl_slice(rnti, id);
+    if (rc < 0) {
+      pthread_mutex_unlock(&nrmac->pp_mutex);
+      LOG_E(MAC, "error code %d while associating RNTI %04x\n", rc, rnti);
+      return (rslicing_rc_t) { .success = false, .error_msg = strdup("error associating UEs") };
+    }
+  }
+  pthread_mutex_unlock(&nrmac->pp_mutex);
+  return (rslicing_rc_t) { .success = true, .error_msg = NULL };
+}
+
+static
+void rlc_gen_hdr(flatcc_builder_t* B)
+{
+  rlc_stats_IndicationHeader_start(B);
+  rlc_stats_IndicationHeader_frame_force_add(B, RC.nrmac[mod_id]->frame);
+  rlc_stats_IndicationHeader_slot_force_add(B, RC.nrmac[mod_id]->slot);
+  rlc_stats_IndicationHeader_end_as_root(B);
+}
+
+static
+void rlc_gen_msg(flatcc_builder_t* B, const rlc_stats_report_style_t* style)
+{
+  int nr_rlc_get_statistics(
+    int rnti,
+    int srb_flag,
+    int rb_id,
+    nr_rlc_statistics_t *out);
+  rlc_stats_IndicationMessage_start(B);
+  rlc_stats_IndicationMessage_ueStats_start(B);
+  // use MAC structures to get RNTIs
+  const NR_UE_info_t* UE_info = &RC.nrmac[mod_id]->UE_info;
+  const NR_list_t* ue_list = &UE_info->list;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    // add in the order of rlc_stats_UEStats_create
+    rlc_stats_UEStats_vec_push_start(B);
+    const uint16_t rnti = UE_info->rnti[ue_id];
+    rlc_stats_UEStats_rb_start(B);
+    //for every LC ID (ideally...)
+    {
+      nr_rlc_statistics_t rlc;
+      const int srb_flag = 0;
+      const int rb_id = 1;
+      const int rc = nr_rlc_get_statistics(rnti, srb_flag, rb_id, &rlc);
+      assert(rc == 1);
+
+      // add in the order of rlc_stats_RBStats_create
+      rlc_stats_RBStats_vec_push_start(B);
+      rlc_stats_RBStats_txPduBytes_force_add(B, rlc.txpdu_bytes);
+      rlc_stats_RBStats_rxPduBytes_force_add(B, rlc.rxpdu_bytes);
+      if (style->type == RLC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        rlc_stats_RBStats_txPduDdBytes_force_add(B, rlc.txpdu_dd_bytes);
+        rlc_stats_RBStats_rxPduDdBytes_force_add(B, rlc.rxpdu_dd_bytes);
+        // TODO in stats or do RLC ind?
+        //rlc_stats_RBStats_txBufOccBytes_force_add(B, rlc.bytes_in_buffer);
+        //rlc_stats_RBStats_rxBufOccBytes_force_add(B, rlc.b);
+      }
+      rlc_stats_RBStats_txPduRetxBytes_force_add(B, rlc.txpdu_retx_bytes);
+      if (style->type == RLC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        rlc_stats_RBStats_rxPduOwBytes_force_add(B, rlc.rxpdu_ow_bytes);
+        rlc_stats_RBStats_rxPduDupBytes_force_add(B, rlc.rxpdu_dup_bytes);
+      }
+      rlc_stats_RBStats_txPduPkts_force_add(B, rlc.txpdu_pkts);
+      rlc_stats_RBStats_rxPduPkts_force_add(B, rlc.rxpdu_pkts);
+      if (style->type == RLC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        rlc_stats_RBStats_txPduDdPkts_force_add(B, rlc.txpdu_dd_pkts);
+        rlc_stats_RBStats_rxPduDdPkts_force_add(B, rlc.rxpdu_dd_pkts);
+      }
+      // TODO in stats or do RLC ind?
+      //rlc_stats_RBStats_txBufOccPkts_force_add(B, rlc_stats.pdus_in_buffer);
+      //rlc_stats_RBStats_rxBufOccPkts_force_add(B, tmp++);
+      rlc_stats_RBStats_txPduRetxPkts_force_add(B, rlc.txpdu_retx_pkts);
+      if (style->type == RLC_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        //rlc_stats_RBStats_txBufWdMs_force_add(B, tmp++);
+        rlc_stats_RBStats_rxPduOwPkts_force_add(B, rlc.rxpdu_ow_bytes);
+        rlc_stats_RBStats_rxPduDupPkts_force_add(B, rlc.rxpdu_dup_pkts);
+        //rlc_stats_RBStats_txPduWtMs_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduRotoutMs_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduPotoutMs_force_add(B, tmp++);
+        //rlc_stats_RBStats_rxPduSptoutMs_force_add(B, tmp++);
+      }
+      rlc_stats_RBStats_rbid_force_add(B, rb_id + 2);
+      rlc_stats_RBStats_vec_push_end(B);
+    }
+    rlc_stats_UEStats_rb_end(B);
+    rlc_stats_UEStats_rnti_force_add(B, rnti);
+    rlc_stats_UEStats_vec_push_end(B);
+  }
+  rlc_stats_IndicationMessage_ueStats_end(B);
+  rlc_stats_IndicationMessage_end_as_root(B);
+}
+
+static
+void pdcp_gen_hdr(flatcc_builder_t* B)
+{
+  pdcp_stats_IndicationHeader_start(B);
+  // There is no frame/slot combination that we might obtain from PDCP
+  //pdcp_stats_IndicationHeader_frame_force_add(B, pdcp_enb[mod_id].frame);
+  //pdcp_stats_IndicationHeader_slot_force_add(B, pdcp_enb[mod_id].subframe);
+  pdcp_stats_IndicationHeader_end_as_root(B);
+}
+
+static
+void pdcp_gen_msg(flatcc_builder_t* B, const pdcp_stats_report_style_t* style)
+{
+  int nr_pdcp_get_statistics(
+    int rnti,
+    int srb_flag,
+    int rb_id,
+    nr_pdcp_statistics_t *out);
+  pdcp_stats_IndicationMessage_start(B);
+  pdcp_stats_IndicationMessage_ueStats_start(B);
+  // for the moment and while we don't have a split base station, we use the
+  // MAC structures to obtain the RNTIs which we use to query the PDCP
+  const NR_UE_info_t* UE_info = &RC.nrmac[mod_id]->UE_info;
+  const NR_list_t* ue_list = &UE_info->list;
+  for (int ue_id = ue_list->head; ue_id >= 0; ue_id = ue_list->next[ue_id]) {
+    const uint16_t rnti = UE_info->rnti[ue_id];
+
+    nr_pdcp_statistics_t pdcp;
+    const int srb_flag = 0;
+    const int rb_id = 1;
+    const int rc = nr_pdcp_get_statistics(rnti, srb_flag, rb_id, &pdcp);
+    assert(rc);
+
+    // add in the order of pdcp_UEStats_create
+    pdcp_stats_UEStats_vec_push_start(B);
+    pdcp_stats_UEStats_rb_start(B);
+    //for (size_t lcid = 3; lcid < 4; ++lcid) {
+    {
+      // add in the order of pdcp_RBStats_create
+      pdcp_stats_RBStats_vec_push_start(B);
+      pdcp_stats_RBStats_txPduPkts_force_add(B, pdcp.txpdu_pkts);
+      pdcp_stats_RBStats_rxPduPkts_force_add(B, pdcp.rxpdu_pkts);
+      pdcp_stats_RBStats_txPduBytes_force_add(B, pdcp.txpdu_bytes);
+      pdcp_stats_RBStats_rxPduBytes_force_add(B, pdcp.rxpdu_bytes);
+      pdcp_stats_RBStats_txPduSn_force_add(B, pdcp.txpdu_sn);
+      pdcp_stats_RBStats_rxPduSn_force_add(B, pdcp.rxpdu_sn);
+      if (style->type == PDCP_STATS_REPORT_STYLE_TYPE_COMPLETE) {
+        // not implemented
+        //pdcp_stats_RBStats_rxPduOoPkts_force_add(B, pdcp.rxpdu_);
+        //// not implemented
+        //pdcp_stats_RBStats_rxPduOoBytes_force_add(B, tmp++);
+        pdcp_stats_RBStats_rxPduDdPkts_force_add(B, pdcp.rxpdu_dd_pkts);
+        pdcp_stats_RBStats_rxPduDdBytes_force_add(B, pdcp.rxpdu_dd_bytes);
+        // not implemented
+        //pdcp_stats_RBStats_rxPduRoCount_force_add(B, );
+      }
+      pdcp_stats_RBStats_rbid_force_add(B, rb_id);
+      pdcp_stats_RBStats_vec_push_end(B);
+    }
+    pdcp_stats_UEStats_rb_end(B);
+    pdcp_stats_UEStats_rnti_force_add(B, rnti);
+    pdcp_stats_UEStats_vec_push_end(B);
+  }
+  pdcp_stats_IndicationMessage_ueStats_end(B);
+  pdcp_stats_IndicationMessage_end_as_root(B);
+}
+
+static
+rrc_common_Plmn_ref_t create_short_plmn(flatcc_builder_t* B, uint16_t mcc, uint16_t mnc, uint8_t mnc_length)
+{
+  // Note: in order of rrc_common_Plmn_create()
+  rrc_common_Plmn_start(B);
+  rrc_common_Plmn_mcc_force_add(B, mcc);
+  rrc_common_Plmn_mnc_force_add(B, mnc);
+  rrc_common_Plmn_mnc_length_force_add(B, mnc_length);
+  return rrc_common_Plmn_end(B);
+}
+
+static
+void fill_rrc_conf_msg(flatcc_builder_t* B, const rrc_conf_report_style_t* style)
+{
+  assert(B);
+  assert(style->type == RRC_CONF_REPORT_STYLE_TYPE_MINIMAL || style->type == RRC_CONF_REPORT_STYLE_TYPE_COMPLETE);
+  const gNB_RRC_INST* rrc = RC.nrrrc[mod_id];
+  rrc_conf_IndicationMessage_start(B);
+  rrc_conf_IndicationMessage_bsStats_start(B);
+  // Note: add in order of rrc_conf_BSStats_create()
+    if (rrc->node_name)
+      rrc_conf_BSStats_baseStationName_create_str(B, rrc->node_name);
+    rrc_conf_BSStats_plmnInfo_start(B);
+    /* only one PLMN currently */
+    //for (size_t i = 0; i < rrc_conf->num_plmn; ++i) {
+      rrc_common_Plmn_ref_t plmn = create_short_plmn(B, rrc->configuration.mcc[0], rrc->configuration.mnc[0], rrc->configuration.mnc_digit_length[0]);
+      rrc_conf_BSStats_plmnInfo_push_create(B, plmn, rrc->configuration.tac, /* no ranac */0, rrc->configuration.cell_identity);
+    //}
+    rrc_conf_BSStats_plmnInfo_end(B);
+    rrc_conf_BSStats_carriers_start(B);
+    /* OAI currently only supports one CC */
+    for (size_t cc = 0; cc < 1; ++cc) {
+      NR_ServingCellConfigCommon_t *scc = rrc->configuration.scc;
+      // Note: add in order of rrc_conf_CarrierInfo_create()
+      rrc_conf_CarrierInfo_vec_push_start(B);
+      rrc_conf_CarrierInfo_dlFreqHz_add(B, *scc->downlinkConfigCommon->frequencyInfoDL->frequencyBandList.list.array[0]);
+      rrc_conf_CarrierInfo_ulFreqHz_add(B, *scc->uplinkConfigCommon->frequencyInfoUL->frequencyBandList->list.array[0]);
+      if (style->type == RRC_CONF_REPORT_STYLE_TYPE_COMPLETE) {
+        if (rrc->configuration.scc->ssbSubcarrierSpacing)
+          rrc_conf_CarrierInfo_nr_create(B, *rrc->configuration.scc->ssbSubcarrierSpacing);
+      }
+      rrc_conf_CarrierInfo_phyCellId_force_add(B, *scc->physCellId);
+      //rrc_conf_CarrierInfo_band_add(B, rrc_conf->eutra_band[cc]);
+      rrc_conf_CarrierInfo_dlBandwidthPrb_add(B, scc->downlinkConfigCommon->frequencyInfoDL->scs_SpecificCarrierList.list.array[0]->carrierBandwidth);
+      rrc_conf_CarrierInfo_ulBandwidthPrb_add(B, scc->downlinkConfigCommon->frequencyInfoDL->scs_SpecificCarrierList.list.array[0]->carrierBandwidth);
+      rrc_conf_CarrierInfo_txAntennaPorts_add(B, rrc->configuration.pdsch_AntennaPorts);
+      rrc_conf_CarrierInfo_rxAnennaPorts_add(B, rrc->configuration.pusch_AntennaPorts);
+      rrc_conf_CarrierInfo_vec_push_end(B);
+    }
+    rrc_conf_BSStats_carriers_end(B);
+    rrc_conf_BSStats_rat_force_add(B, rrc_common_RAT_NR);
+  rrc_conf_IndicationMessage_bsStats_end(B);
+  rrc_conf_IndicationMessage_end_as_root(B);
+}
+
+/*
+void fill_rrc_stats_msg(struct flatcc_builder* B, const rrc_stats_report_style_t* style, void* ctxt)
+{
+  assert(B);
+  assert(ctxt);
+  assert(style->type == RRC_STATS_REPORT_STYLE_TYPE_MINIMAL);
+
+  const rrc_eNB_ue_context_t* ue_ctxt = (rrc_eNB_ue_context_t*)ctxt;
+  const LTE_MeasResults_t* measResults = ue_ctxt->ue_context.measResults;
+
+  rrc_stats_IndicationMessage_start(B);
+  rrc_stats_IndicationMessage_measReport_start(B);
+  // only a single measReport. The point of the list is to accumulate them in
+  // the controller
+  // Note: add in order of rrc_stats_MeasReport_create()
+
+    rrc_stats_MeasReport_vec_push_start(B);
+    rrc_stats_MeasReport_measId_force_add(B, measResults->measId);
+    rrc_stats_MeasReport_pCellResult_create(B,
+          measResults->measResultPCell.rsrpResult - 140,
+          (float) measResults->measResultPCell.rsrqResult / 2 - 20,
+          0);
+
+    rrc_stats_MeasReport_neighMeas_start(B);
+    const LTE_MeasResultListEUTRA_t* lte_measResult = &measResults->measResultNeighCells->choice.measResultListEUTRA;
+    for (size_t j = 0; j < lte_measResult->list.count; ++j) {
+      const LTE_MeasResultEUTRA_t* r = lte_measResult->list.array[j];
+      rrc_stats_NeighMeas_vec_push_start(B);
+      // Note: add in order of rrc_stats_NeighMeas_create()
+      //rrc_common_Plmn_ref_t plmn = create_short_plmn(B, 208, 95, 2);
+      //rrc_stats_NeighMeas_plmnInfo_create(B, plmn, 0, 0, 507);
+      long rsrp = r->measResult.rsrpResult ? *r->measResult.rsrpResult - 140 : -42;
+      long rsrq = r->measResult.rsrqResult ? (float) *r->measResult.rsrqResult / 2 - 20 : -42;
+      rrc_stats_NeighMeas_measResult_create(B, rsrp, rsrq, 0);
+      rrc_stats_NeighMeas_phyCellId_force_add(B, r->physCellId);
+      rrc_stats_NeighMeas_rat_force_add(B, rrc_common_RAT_LTE);
+      rrc_stats_NeighMeas_vec_push_end(B);
+    }
+    rrc_stats_MeasReport_neighMeas_end(B);
+
+    rrc_stats_MeasReport_vec_push_end(B);
+
+  rrc_stats_IndicationMessage_measReport_end(B);
+  rrc_stats_IndicationMessage_end_as_root(B);
+}
+*/
+
+static
+global_e2_node_id_t get_node_id(void)
+{
+  const gNB_RRC_INST* rrc = RC.nrrrc[mod_id];
+  assert(rrc);
+  const plmn_t plmn = {
+    .mcc = rrc->configuration.mcc[0],
+    .mnc = rrc->configuration.mnc[0],
+    .mnc_digit_len = rrc->configuration.mnc_digit_length[0]
+  };
+  const global_e2_node_id_t ge2ni = {
+    .type = ngran_gNB,
+    .plmn = plmn,
+    .nb_id = rrc->configuration.cell_identity
+  };
+  return ge2ni;
+}
+
+static
+void* start_agent(void* arg)
+{
+  e2ap_agent_t* flexric_ag = (e2ap_agent_t*) arg;
+  e2ap_start_agent(flexric_ag); /* blocking */
+  return NULL;
+}
+
+void flexric_start_nsa(void)
+{
+  printf("***********************************\n");
+  printf("****** STARTING FLEXRIC AGENT *****\n");
+  printf("***********************************\n");
+
+  const char* ip = "192.168.12.246";
+  const uint16_t port = 36421;
+
+  flexric_ag = e2ap_init_agent(ip, port, get_node_id());
+
+  const mac_stats_report_style_t mac_style[2] = {
+    { .type = MAC_STATS_REPORT_STYLE_TYPE_MINIMAL },
+    { .type = MAC_STATS_REPORT_STYLE_TYPE_COMPLETE }
+  };
+  mac_stats_callbacks_t mac_cb = {
+    .hdr = mac_gen_hdr,
+    .msg = mac_gen_msg
+  };
+  sm_mac_stats_register_ran_function(flexric_ag, mac_cb, mac_style, 2);
+
+  const mac_rslicing_SliceAlgorithm_enum_t algos[3] = {
+    mac_rslicing_SliceAlgorithm_None,
+    mac_rslicing_SliceAlgorithm_Static
+  };
+  rslicing_cb_t rslicing_cb = {
+    .read = rslicing_read_slice_conf,
+    .add_mod = rslicing_handle_add_mod_slice_command,
+    .del = rslicing_handle_del_slice_command,
+    .ue_assoc = rslicing_handle_ue_assoc_command
+  };
+  sm_mac_rslicing_register_ran_function(flexric_ag, algos, 3, rslicing_cb);
+
+  const rlc_stats_report_style_t rlc_style = { .type = RLC_STATS_REPORT_STYLE_TYPE_COMPLETE };
+  rlc_stats_callbacks_t rlc_cb = {
+    .hdr = rlc_gen_hdr,
+    .msg = rlc_gen_msg
+  };
+  sm_rlc_stats_register_ran_function(flexric_ag, rlc_cb, &rlc_style, 1);
+
+  const pdcp_stats_report_style_t pdcp_style[2] = {
+    { .type = MAC_STATS_REPORT_STYLE_TYPE_MINIMAL },
+    { .type = MAC_STATS_REPORT_STYLE_TYPE_COMPLETE }
+  };
+  pdcp_stats_callbacks_t pdcp_cb = {
+    .hdr = pdcp_gen_hdr,
+    .msg = pdcp_gen_msg
+  };
+  sm_pdcp_stats_register_ran_function(flexric_ag, pdcp_cb, pdcp_style, 2);
+
+  /*
+  const rrc_stats_report_style_t rrc_stats_style = { .type = RRC_STATS_REPORT_STYLE_TYPE_MINIMAL };
+  sm_rrc_stats_register_ran_function(flexric_ag, &rrc_stats_style, 1);
+  */
+
+  const rrc_conf_report_style_t rrc_conf_style[2] = {
+    { .type = RRC_CONF_REPORT_STYLE_TYPE_MINIMAL },
+    { .type = RRC_CONF_REPORT_STYLE_TYPE_COMPLETE }
+  };
+  sm_rrc_conf_register_ran_function(flexric_ag, fill_rrc_conf_msg, rrc_conf_style, 2);
+
+  pthread_t t_agent;
+  int rc = pthread_create(&t_agent, NULL, start_agent, flexric_ag);
+  assert(rc == 0);
+}
+
+void flexric_stop_nsa(void)
+{
+  e2ap_free_agent(flexric_ag);
+}
diff --git a/openair2/GNB_APP/gnb_config.c b/openair2/GNB_APP/gnb_config.c
index e578e98c5e..da1cb6efb3 100644
--- a/openair2/GNB_APP/gnb_config.c
+++ b/openair2/GNB_APP/gnb_config.c
@@ -939,6 +939,7 @@ void RCconfig_NRRRC(MessageDef *msg_p, uint32_t i, gNB_RRC_INST *rrc) {
         char gnbpath[MAX_OPTNAME_SIZE + 8];
         sprintf(gnbpath,"%s.[%i]",GNB_CONFIG_STRING_GNB_LIST,k);
 
+        rrc->node_name = strdup(*(GNBParamList.paramarray[0][GNB_GNB_NAME_IDX].strptr));
 	
         paramdef_t PLMNParams[] = GNBPLMNPARAMS_DESC;
 
diff --git a/openair2/LAYER2/MAC/eNB_scheduler_dlsch.c b/openair2/LAYER2/MAC/eNB_scheduler_dlsch.c
index 596d978a98..9db1b2559c 100644
--- a/openair2/LAYER2/MAC/eNB_scheduler_dlsch.c
+++ b/openair2/LAYER2/MAC/eNB_scheduler_dlsch.c
@@ -561,23 +561,25 @@ schedule_ue_spec(module_id_t module_idP,
     if (cc[CC_id].vrb_map[i] != 0)
       total_nb_available_rb--;
 
-  // store the global enb stats:
-  eNB->eNB_stats[CC_id].num_dlactive_UEs = UE_info->num_UEs;
-  eNB->eNB_stats[CC_id].available_prbs = total_nb_available_rb;
-  eNB->eNB_stats[CC_id].total_available_prbs += total_nb_available_rb;
-  eNB->eNB_stats[CC_id].dlsch_bytes_tx = 0;
-  eNB->eNB_stats[CC_id].dlsch_pdus_tx = 0;
-
   // CALLING Pre_Processor for downlink scheduling
   // (Returns estimation of RBs required by each UE and the allocation on sub-band)
   VCD_SIGNAL_DUMPER_DUMP_FUNCTION_BY_NAME(VCD_SIGNAL_DUMPER_FUNCTIONS_DLSCH_PREPROCESSOR,
                                           VCD_FUNCTION_IN);
   start_meas(&eNB->schedule_dlsch_preprocessor);
+  pthread_mutex_lock(&eNB->pp_dl_mutex);
   eNB->pre_processor_dl.dl(module_idP, CC_id, frameP, subframeP);
+  pthread_mutex_unlock(&eNB->pp_dl_mutex);
   stop_meas(&eNB->schedule_dlsch_preprocessor);
   VCD_SIGNAL_DUMPER_DUMP_FUNCTION_BY_NAME(VCD_SIGNAL_DUMPER_FUNCTIONS_DLSCH_PREPROCESSOR,
                                           VCD_FUNCTION_OUT);
 
+  // store the global enb stats:
+  eNB->eNB_stats[CC_id].num_dlactive_UEs = UE_info->num_UEs;
+  eNB->eNB_stats[CC_id].available_prbs = total_nb_available_rb;
+  eNB->eNB_stats[CC_id].total_available_prbs += total_nb_available_rb;
+  eNB->eNB_stats[CC_id].dlsch_bytes_tx = 0;
+  eNB->eNB_stats[CC_id].dlsch_pdus_tx = 0;
+
   for (int UE_id = UE_info->list.head; UE_id >= 0; UE_id = UE_info->list.next[UE_id]) {
     LOG_D(MAC, "doing schedule_ue_spec for CC_id %d UE %d\n",
           CC_id,
@@ -586,6 +588,8 @@ schedule_ue_spec(module_id_t module_idP,
     UE_TEMPLATE *ue_template = &UE_info->UE_template[CC_id][UE_id];
     eNB_UE_STATS *eNB_UE_stats = &UE_info->eNB_UE_stats[CC_id][UE_id];
     eNB_UE_stats->TBS = 0;
+    eNB_UE_stats->overhead_bytes = 0;
+    eNB_UE_stats->rbs_used = 0;
     const rnti_t rnti = ue_template->rnti;
 
     // If TDD
diff --git a/openair2/LAYER2/MAC/mac.h b/openair2/LAYER2/MAC/mac.h
index 062f613526..40777073c8 100644
--- a/openair2/LAYER2/MAC/mac.h
+++ b/openair2/LAYER2/MAC/mac.h
@@ -1448,6 +1448,7 @@ typedef struct eNB_MAC_INST_s {
   /// are called by ULSCH/DLSCH, respectively. Pro-processor implementation can
   /// encapsulate slicing.
   pp_impl_param_t pre_processor_dl;
+  pthread_mutex_t pp_dl_mutex;
   pp_impl_param_t pre_processor_ul;
 
   int32_t puSch10xSnr;
@@ -1724,6 +1725,7 @@ typedef struct {
   /// after the reception of NFAPI_UL_CONFIG_ULSCH_PDU_TYPE.
   uint8_t first_ULSCH_Tx;
   uint8_t SI_Decoded;
+  uint8_t SIB_Decoded;
   int ra_frame;   // This variable keeps the frame in which the RA started for the specific UE. It is used in order
   // to make sure that different UEs RA starts within a number of frames difference.
 
diff --git a/openair2/LAYER2/MAC/slicing/slicing.c b/openair2/LAYER2/MAC/slicing/slicing.c
index 48dd99afeb..ec0685d4c0 100644
--- a/openair2/LAYER2/MAC/slicing/slicing.c
+++ b/openair2/LAYER2/MAC/slicing/slicing.c
@@ -40,6 +40,9 @@
 #include "common/ran_context.h"
 extern RAN_CONTEXT_t RC;
 
+/* SCN19 needs get_TBS_DL() */
+#include "PHY/LTE_TRANSPORT/transport_common_proto.h"
+
 #define RET_FAIL(ret, x...) do { LOG_E(MAC, x); return ret; } while (0)
 
 int slicing_get_UE_slice_idx(slice_info_t *si, int UE_id) {
@@ -583,7 +586,8 @@ pp_impl_param_t static_ul_init(module_id_t mod_id, int CC_id) {
   ulp->posHigh = to_prb(RC.mac[mod_id]->common_channels[CC_id].ul_Bandwidth) - 1;
   default_sched_ul_algo_t *algo = &RC.mac[mod_id]->pre_processor_ul.ul_algo;
   algo->data = NULL;
-  DevAssert(0 == addmod_static_slice_ul(si, 0, strdup("default"), algo, ulp));
+  const int rc = addmod_static_slice_ul(si, 0, strdup("default"), algo, ulp);
+  DevAssert(0 == rc);
   const UE_list_t *UE_list = &RC.mac[mod_id]->UE_info.list;
   for (int UE_id = UE_list->head; UE_id >= 0; UE_id = UE_list->next[UE_id])
     slicing_add_UE(si, UE_id);
@@ -603,3 +607,904 @@ pp_impl_param_t static_ul_init(module_id_t mod_id, int CC_id) {
 
   return sttc;
 }
+
+/************************* NVS Slicing Implementation **************************/
+
+typedef struct {
+  float exp; // exponential weight. mov. avg for weight calc
+  int   rb;  // number of RBs this slice has been scheduled in last round
+  float eff; // effective rate for rate slices
+  float beta_eff; // averaging coeff so we average over roughly one second
+  int   active;   // activity state for rate slices
+} _nvs_int_t;
+
+int _nvs_admission_control(const slice_info_t *si,
+                           const nvs_slice_param_t *p,
+                           int idx) {
+  if (p->type != NVS_RATE && p->type != NVS_RES)
+    RET_FAIL(-1, "%s(): invalid slice type %d\n", __func__, p->type);
+  if (p->type == NVS_RATE && p->Mbps_reserved > p->Mbps_reference)
+    RET_FAIL(-1,
+             "%s(): a rate slice cannot reserve more than the reference rate\n",
+             __func__);
+  if (p->type == NVS_RES && p->pct_reserved > 1.0f)
+    RET_FAIL(-1, "%s(): cannot reserve more than 1.0\n", __func__);
+  float sum_req = 0.0f;
+  for (int i = 0; i < si->num; ++i) {
+    const nvs_slice_param_t *sp = i == idx ? p : si->s[i]->algo_data;
+    if (sp->type == NVS_RATE)
+      sum_req += sp->Mbps_reserved / sp->Mbps_reference;
+    else
+      sum_req += sp->pct_reserved;
+  }
+  if (idx < 0) { /* not an existing slice */
+    if (p->type == NVS_RATE)
+      sum_req += p->Mbps_reserved / p->Mbps_reference;
+    else
+      sum_req += p->pct_reserved;
+  }
+  if (sum_req > 1.0)
+    RET_FAIL(-3,
+             "%s(): admission control failed: sum of resources is %f > 1.0\n",
+             __func__, sum_req);
+  return 0;
+}
+
+int addmod_nvs_slice_dl(slice_info_t *si,
+                        int id,
+                        char *label,
+                        void *algo,
+                        void *slice_params_dl) {
+  nvs_slice_param_t *dl = slice_params_dl;
+  int index = _exists_slice(si->num, si->s, id);
+  if (index < 0 && si->num >= MAX_NVS_SLICES)
+    RET_FAIL(-2, "%s(): cannot handle more than %d slices\n", __func__, MAX_NVS_SLICES);
+
+  if (index < 0 && !dl)
+    RET_FAIL(-100, "%s(): no parameters for new slice %d, aborting\n", __func__, id);
+
+  if (dl) {
+    int rc = _nvs_admission_control(si, dl, index);
+    if (rc < 0)
+      return rc;
+  }
+
+  slice_t *s = NULL;
+  if (index >= 0) {
+    s = si->s[index];
+    if (label) {
+      if (s->label) free(s->label);
+      s->label = label;
+    }
+    if (algo) {
+      s->dl_algo.unset(&s->dl_algo.data);
+      s->dl_algo = *(default_sched_dl_algo_t *) algo;
+      if (!s->dl_algo.data)
+        s->dl_algo.data = s->dl_algo.setup();
+    }
+    if (dl) {
+      free(s->algo_data);
+      s->algo_data = dl;
+    } else { /* we have no parameters: we are done */
+      return index;
+    }
+  } else {
+    if (!algo)
+      RET_FAIL(-14, "%s(): no scheduler algorithm provided\n", __func__);
+
+    s = _add_slice(&si->num, si->s);
+    if (!s)
+      RET_FAIL(-4, "%s(): cannot allocate memory for slice\n", __func__);
+    s->int_data = malloc(sizeof(_nvs_int_t));
+    if (!s->int_data)
+      RET_FAIL(-5, "%s(): cannot allocate memory for slice internal data\n", __func__);
+
+    s->id = id;
+    s->label = label;
+    s->dl_algo = *(default_sched_dl_algo_t *) algo;
+    if (!s->dl_algo.data)
+      s->dl_algo.data = s->dl_algo.setup();
+    s->algo_data = dl;
+  }
+
+  _nvs_int_t *nvs_p = s->int_data;
+  /* reset all slice-internal parameters */
+  nvs_p->rb = 0;
+  nvs_p->active = 0;
+  if (dl->type == NVS_RATE) {
+    nvs_p->exp = dl->Mbps_reserved / dl->Mbps_reference;
+    nvs_p->eff = dl->Mbps_reference;
+  } else {
+    nvs_p->exp = dl->pct_reserved;
+    nvs_p->eff = 0; // not used
+  }
+  // scale beta so we (roughly) average the eff rate over 1s
+  nvs_p->beta_eff = BETA / nvs_p->exp;
+
+  return index < 0 ? si->num - 1 : index;
+}
+
+//int addmod_nvs_slice_ul(slice_info_t *si,
+//                        int id,
+//                        char *label,
+//                        void *slice_params_ul) {
+//  nvs_slice_param_t *sp = slice_params_ul;
+//  int index = _exists_slice(si->num, si->s, id);
+//  if (index < 0 && si->num >= MAX_NVS_SLICES)
+//    RET_FAIL(-2, "%s(): cannot handle more than %d slices\n", __func__, MAX_NVS_SLICES);
+//
+//  int rc = _nvs_admission_control(si->num, si->s, sp, index);
+//  if (rc < 0)
+//    return rc;
+//
+//  slice_t *ns = NULL;
+//  if (index < 0) {
+//    ns = _add_slice(&si->num, si->s);
+//    if (!ns)
+//      RET_FAIL(-4, "%s(): cannot allocate memory for slice\n", __func__);
+//    ns->id = id;
+//    ns->int_data = malloc(sizeof(_nvs_int_t));
+//    if (!ns->int_data)
+//      RET_FAIL(-5, "%s(): cannot allocate memory for slice internal data\n",
+//               __func__);
+//  } else {
+//    ns = si->s[index];
+//    free(ns->algo_data);
+//  }
+//  if (label) {
+//    if (ns->label)
+//      free(ns->label);
+//    ns->label = label;
+//  }
+//  ns->algo_data = sp;
+//  _nvs_int_t *nvs_p = ns->int_data;
+//  nvs_p->rb = 0;
+//  nvs_p->active = 0;
+//  if (sp->type == NVS_RATE) {
+//    nvs_p->exp = sp->Mbps_reserved;
+//    nvs_p->eff = sp->Mbps_reference;
+//  } else {
+//    nvs_p->exp = sp->pct_reserved;
+//    nvs_p->eff = 0; // not used
+//  }
+//
+//  return si->num - 1;
+//}
+
+int remove_nvs_slice_dl(slice_info_t *si, uint8_t slice_idx) {
+  if (slice_idx == 0)
+    return 0;
+  slice_t *sr = _remove_slice(&si->num, si->s, si->UE_assoc_slice, slice_idx);
+  if (!sr)
+    return 0;
+  free(sr->algo_data);
+  free(sr->int_data);
+  sr->dl_algo.unset(&sr->dl_algo.data);
+  free(sr);
+  return 1;
+}
+
+//int remove_nvs_slice_ul(slice_info_t *si, uint8_t slice_idx) {
+//  if (slice_idx == 0)
+//    return 0;
+//  slice_t *sr = _remove_slice(&si->num, si->s, si->UE_assoc_slice, slice_idx);
+//  if (!sr)
+//    return 0;
+//  free(sr->algo_data);
+//  free(sr->int_data);
+//  free(sr);
+//  return 1;
+//}
+
+void nvs_dl(module_id_t mod_id,
+               int CC_id,
+               frame_t frame,
+               sub_frame_t subframe) {
+  UE_info_t *UE_info = &RC.mac[mod_id]->UE_info;
+
+  store_dlsch_buffer(mod_id, CC_id, frame, subframe);
+
+  slice_info_t *si = RC.mac[mod_id]->pre_processor_dl.slices;
+  const COMMON_channels_t *cc = &RC.mac[mod_id]->common_channels[CC_id];
+  const uint8_t harq_pid = frame_subframe2_dl_harq_pid(cc->tdd_Config, frame, subframe);
+  for (int UE_id = UE_info->list.head; UE_id >= 0; UE_id = UE_info->list.next[UE_id]) {
+    UE_sched_ctrl_t *ue_sched_ctrl = &UE_info->UE_sched_ctrl[UE_id];
+
+    /* initialize per-UE scheduling information */
+    ue_sched_ctrl->pre_nb_available_rbs[CC_id] = 0;
+    ue_sched_ctrl->dl_pow_off[CC_id] = 2;
+    memset(ue_sched_ctrl->rballoc_sub_UE[CC_id], 0, sizeof(ue_sched_ctrl->rballoc_sub_UE[CC_id]));
+    ue_sched_ctrl->pre_dci_dl_pdu_idx = -1;
+
+    const int idx = si->UE_assoc_slice[UE_id];
+    DevAssert(idx >= 0);
+    const UE_TEMPLATE *UE_template = &UE_info->UE_template[CC_id][UE_id];
+    const uint8_t round = UE_info->UE_sched_ctrl[UE_id].round[CC_id][harq_pid];
+    /* if UE has data or retransmission, mark respective slice as active */
+    const bool active = UE_template->dl_buffer_total > 0 || round != 8;
+    ((_nvs_int_t *)si->s[idx]->int_data)->active |= active;
+  }
+
+  const int N_RBG = to_rbg(RC.mac[mod_id]->common_channels[CC_id].mib->message.dl_Bandwidth);
+  const int RBGsize = get_min_rb_unit(mod_id, CC_id);
+  const int N_RB_DL = to_prb(RC.mac[mod_id]->common_channels[CC_id].mib->message.dl_Bandwidth);
+  uint8_t *vrb_map = RC.mac[mod_id]->common_channels[CC_id].vrb_map;
+  uint8_t rbgalloc_mask[N_RBG_MAX];
+  int n_rbg_sched = 0;
+  for (int i = 0; i < N_RBG; i++) {
+    // calculate mask: init to one + "AND" with vrb_map:
+    // if any RB in vrb_map is blocked (1), the current RBG will be 0
+    rbgalloc_mask[i] = 1;
+    for (int j = 0; j < RBGsize && RBGsize * i + j < N_RB_DL; j++)
+      rbgalloc_mask[i] &= !vrb_map[RBGsize * i + j];
+    n_rbg_sched += rbgalloc_mask[i];
+  }
+
+  /* todo: schedule retransmission first */
+
+  float maxw = 0.0f;
+  int maxidx = -1;
+  for (int i = 0; i < si->num; ++i) {
+    slice_t *s = si->s[i];
+    nvs_slice_param_t *p = s->algo_data;
+    _nvs_int_t *ip = s->int_data;
+    /* if this slice has been marked as inactive, disable to prevent that
+     * it's exp rate is uselessly driven down */
+    if (!ip->active)
+      continue;
+
+    float w = 0.0f;
+    if (p->type == NVS_RATE) {
+      float inst = 0.0f;
+      if (ip->rb > 0) { /* it was scheduled last round */
+        /* inst rate: B in last round * 8(bit) / 1000000 (Mbps) * 1000 (1ms) */
+        inst = (float) RC.mac[mod_id]->eNB_stats[CC_id].dlsch_bytes_tx * 8 / 1000;
+        ip->eff = (1.0f - ip->beta_eff) * ip->eff + ip->beta_eff * inst;
+        //LOG_W(MAC, "i %d slice %d ip->rb %d inst %f ip->eff %f\n", i, s->id, ip->rb, inst, ip->eff);
+        ip->rb = 0;
+      }
+      ip->exp = (1 - BETA) * ip->exp + BETA * inst;
+      const float rsv = p->Mbps_reserved * min(1.0f, ip->eff / p->Mbps_reference);
+      w = rsv / ip->exp;
+    } else {
+      float inst = (float)ip->rb / N_RB_DL;
+      ip->exp = (1.0f - BETA) * ip->exp + BETA * inst;
+      w = p->pct_reserved / ip->exp;
+    }
+    //LOG_I(MAC, "i %d slice %d type %d ip->exp %f w %f\n", i, s->id, p->type, ip->exp, w);
+    ip->rb = 0;
+    if (w > maxw + 0.001f) {
+      maxw = w;
+      maxidx = i;
+    }
+  }
+
+  if (maxidx < 0)
+    return;
+
+  int nb_rb = n_rbg_sched * RBGsize;
+  if (rbgalloc_mask[N_RBG - 1]
+      && (N_RB_DL == 15 || N_RB_DL == 25 || N_RB_DL == 50 || N_RB_DL == 75))
+    nb_rb -= 1;
+  ((_nvs_int_t *)si->s[maxidx]->int_data)->rb = nb_rb;
+
+  int rbg_rem = n_rbg_sched;
+  if (si->s[maxidx]->UEs.head >= 0) {
+    rbg_rem = si->s[maxidx]->dl_algo.run(mod_id,
+                                         CC_id,
+                                         frame,
+                                         subframe,
+                                         &si->s[maxidx]->UEs,
+                                         4, // max_num_ue
+                                         n_rbg_sched,
+                                         rbgalloc_mask,
+                                         si->s[maxidx]->dl_algo.data);
+  }
+  if (rbg_rem == n_rbg_sched) // if no RBGs have been used mark as inactive
+    ((_nvs_int_t *)si->s[maxidx]->int_data)->active = 0;
+
+  // the following block is meant for validation of the pre-processor to check
+  // whether all UE allocations are non-overlapping and is not necessary for
+  // scheduling functionality
+  char t[26] = "_________________________";
+  t[N_RBG] = 0;
+  for (int i = 0; i < N_RBG; i++)
+    for (int j = 0; j < RBGsize; j++)
+      if (vrb_map[RBGsize*i+j] != 0)
+        t[i] = 'x';
+  int print = 0;
+  for (int UE_id = UE_info->list.head; UE_id >= 0; UE_id = UE_info->list.next[UE_id]) {
+    const UE_sched_ctrl_t *ue_sched_ctrl = &UE_info->UE_sched_ctrl[UE_id];
+
+    if (ue_sched_ctrl->pre_nb_available_rbs[CC_id] == 0)
+      continue;
+
+    LOG_D(MAC,
+          "%4d.%d UE%d %d RBs allocated, pre MCS %d\n",
+          frame,
+          subframe,
+          UE_id,
+          ue_sched_ctrl->pre_nb_available_rbs[CC_id],
+          UE_info->eNB_UE_stats[CC_id][UE_id].dlsch_mcs1);
+
+    print = 1;
+
+    for (int i = 0; i < N_RBG; i++) {
+      if (!ue_sched_ctrl->rballoc_sub_UE[CC_id][i])
+        continue;
+      for (int j = 0; j < RBGsize; j++) {
+        if (vrb_map[RBGsize*i+j] != 0) {
+          LOG_I(MAC, "%4d.%d DL scheduler allocation list: %s\n", frame, subframe, t);
+          LOG_E(MAC, "%4d.%d: UE %d allocated at locked RB %d/RBG %d\n", frame,
+                subframe, UE_id, RBGsize * i + j, i);
+        }
+        vrb_map[RBGsize*i+j] = 1;
+      }
+      t[i] = '0' + UE_id;
+    }
+  }
+  if (print)
+    LOG_D(MAC, "%4d.%d DL scheduler allocation list: %s\n", frame, subframe, t);
+}
+
+void nvs_ul(module_id_t mod_id,
+               int CC_id,
+               frame_t frame,
+               sub_frame_t subframe,
+               frame_t sched_frame,
+               sub_frame_t sched_subframe) {
+  ulsch_scheduler_pre_processor(mod_id, CC_id, frame, subframe, sched_frame, sched_subframe);
+}
+
+void nvs_destroy(slice_info_t **si) {
+  const int n_dl = (*si)->num;
+  (*si)->num = 0;
+  for (int i = 0; i < n_dl; ++i) {
+    slice_t *s = (*si)->s[i];
+    if (s->label)
+      free(s->label);
+    free(s->algo_data);
+    free(s->int_data);
+    free(s);
+  }
+  free((*si)->s);
+}
+
+pp_impl_param_t nvs_dl_init(module_id_t mod_id, int CC_id) {
+  slice_info_t *si = calloc(1, sizeof(slice_info_t));
+  DevAssert(si);
+
+  si->num = 0;
+  si->s = calloc(MAX_NVS_SLICES, sizeof(slice_t));
+  DevAssert(si->s);
+  for (int i = 0; i < MAX_MOBILES_PER_ENB; ++i)
+    si->UE_assoc_slice[i] = -1;
+
+  /* insert default slice, all resources */
+  nvs_slice_param_t *dlp = malloc(sizeof(nvs_slice_param_t));
+  DevAssert(dlp);
+  dlp->type = NVS_RES;
+  dlp->pct_reserved = 1.0f;
+  default_sched_dl_algo_t *algo = &RC.mac[mod_id]->pre_processor_dl.dl_algo;
+  algo->data = NULL;
+  const int rc = addmod_nvs_slice_dl(si, 0, strdup("default"), algo, dlp);
+  DevAssert(0 == rc);
+  const UE_list_t *UE_list = &RC.mac[mod_id]->UE_info.list;
+  for (int UE_id = UE_list->head; UE_id >= 0; UE_id = UE_list->next[UE_id])
+    slicing_add_UE(si, UE_id);
+
+  pp_impl_param_t nvs;
+  nvs.algorithm = NVS_SLICING;
+  nvs.add_UE = slicing_add_UE;
+  nvs.remove_UE = slicing_remove_UE;
+  nvs.move_UE = slicing_move_UE;
+  nvs.addmod_slice = addmod_nvs_slice_dl;
+  nvs.remove_slice = remove_nvs_slice_dl;
+  nvs.dl = nvs_dl;
+  // current DL algo becomes default scheduler
+  nvs.dl_algo = *algo;
+  nvs.destroy = nvs_destroy;
+  nvs.slices = si;
+
+  return nvs;
+}
+
+
+/************* Schmidt, Chang, Nikaein 2019 Slicing Implementation *************/
+
+typedef struct {
+  float exp; // exponential weight. mov. avg for weight calc
+  union {    // which struct is given implicitly through slice type
+    struct {
+      int   rb;  // number of RBs this slice has been scheduled in last round
+      float eff; // effective rate for rate slices
+      int   active; // activity state for rate slices
+    } dyn;
+    struct {
+      int   rb;
+      float t;   // moving average of used resources of
+      int   data_req; // how much data this slice might schedule
+    } ond;
+  };
+} _scn19_int_t;
+
+int _scn19_res_slice_used(module_id_t mod_id, int CC_id, UE_list_t *UEs) {
+  int B = 0;
+  for (int UE_id = UEs->head; UE_id >= 0; UE_id = UEs->next[UE_id]) {
+    const eNB_UE_STATS *ue = &RC.mac[mod_id]->UE_info.eNB_UE_stats[CC_id][UE_id];
+    B += ue->TBS - ue->overhead_bytes; // count SDU bytes, if PDU, delete OH_B
+  }
+  return B;
+}
+
+int _scn19_admission_control(const slice_info_t *si,
+                             scn19_slice_param_t *p,
+                             int idx,
+                             int N_RBG) {
+  if (p->type != SCN19_DYN && p->type != SCN19_FIX && p->type != SCN19_OND)
+    RET_FAIL(-1, "%s(): invalid slice type %d\n", __func__, p->type);
+  if (p->type == SCN19_DYN && p->Mbps_reserved > p->Mbps_reference)
+    RET_FAIL(-1,
+             "%s(): a dynamic slice cannot reserve more than the reference rate\n",
+             __func__);
+  if (p->type == SCN19_FIX && p->posLow > p->posHigh)
+    RET_FAIL(-1,
+             "%s(): lower position of fixed slice cannot be above upper position\n",
+             __func__);
+  float sum_req = 0.0f;
+  uint8_t rbgMap[111] = { 0 }; // cover up to all LTE RBs
+  for (int i = 0; i < si->num; ++i) {
+    scn19_slice_param_t *sp = i == idx ? p : si->s[i]->algo_data;
+    switch (sp->type) {
+      case SCN19_DYN:
+        sum_req += (float) sp->Mbps_reserved / sp->Mbps_reference;
+        break;
+      case SCN19_FIX:
+        for (int i = sp->posLow; i <= sp->posHigh; ++i) {
+          if (rbgMap[i])
+            RET_FAIL(-33, "%s(): fixed slices are overlapping\n", __func__);
+          rbgMap[i] = 1;
+        }
+        sum_req += (float) (sp->posHigh + 1 - sp->posLow) / N_RBG;
+        break;
+      case SCN19_OND:
+        sum_req += sp->pct_reserved;
+        break;
+    }
+  }
+  if (idx < 0) { /* not an existing slice */
+    switch (p->type) {
+      case SCN19_DYN:
+        sum_req += (float) p->Mbps_reserved / p->Mbps_reference;
+        break;
+      case SCN19_FIX:
+        for (int i = p->posLow; i <= p->posHigh; ++i) {
+          if (rbgMap[i])
+            RET_FAIL(-33, "%s(): fixed slices are overlapping\n", __func__);
+          rbgMap[i] = 1;
+        }
+        sum_req += (float) (p->posHigh + 1 - p->posLow) / N_RBG;
+        break;
+      case SCN19_OND:
+        sum_req += p->pct_reserved;
+        break;
+    }
+  }
+  if (sum_req > 1.0f)
+    RET_FAIL(-3,
+             "%s(): admission control failed: sum of resources %f > 1.0\n",
+             __func__, sum_req);
+  return 0;
+}
+
+int addmod_scn19_slice_dl(slice_info_t *si,
+                        int id,
+                        char *label,
+                        void *algo,
+                        void *slice_params_dl) {
+  scn19_slice_param_t *dl = slice_params_dl;
+  int index = _exists_slice(si->num, si->s, id);
+  if (index < 0 && si->num >= MAX_SCN19_SLICES)
+    RET_FAIL(-2, "%s(): cannot handle more than %d slices\n", __func__, MAX_SCN19_SLICES);
+
+  /* TODO: mod_id, CC_id as parameters! */
+  const module_id_t mod_id = 0;
+  const int CC_id = 0;
+  const int N_RBG = to_rbg(RC.mac[mod_id]->common_channels[CC_id].mib->message.dl_Bandwidth);
+  int rc = _scn19_admission_control(si, dl, index, N_RBG);
+  if (rc < 0)
+    return rc;
+
+  slice_t *ns = NULL;
+  if (index >= 0) {
+    ns = si->s[index];
+    if (label) {
+      if (ns->label) free(ns->label);
+      ns->label = label;
+    }
+    if (algo) {
+      ns->dl_algo.unset(&ns->dl_algo.data);
+      ns->dl_algo = *(default_sched_dl_algo_t *) algo;
+      if (!ns->dl_algo.data)
+        ns->dl_algo.data = ns->dl_algo.setup();
+    }
+    if (dl) {
+      free(ns->algo_data);
+      ns->algo_data = dl;
+    } else { /* we have no parameters: we are done */
+      return index;
+    }
+  } else {
+    if (!algo)
+      RET_FAIL(-14, "%s(): no scheduler algorithm provided\n", __func__);
+
+    ns = _add_slice(&si->num, si->s);
+    if (!ns)
+      RET_FAIL(-4, "%s(): cannot allocate memory for slice\n", __func__);
+    ns->int_data = malloc(sizeof(_scn19_int_t));
+    if (!ns->int_data)
+      RET_FAIL(-5, "%s(): cannot allocate memory for slice internal data\n",
+               __func__);
+
+    ns->id = id;
+    ns->label = label;
+    ns->dl_algo = *(default_sched_dl_algo_t *) algo;
+    if (!ns->dl_algo.data)
+      ns->dl_algo.data = ns->dl_algo.setup();
+    ns->algo_data = dl;
+  }
+
+  _scn19_int_t *scn19_p = ns->int_data;
+  /* reset all slice-internal parameters */
+  if (dl->type == SCN19_DYN) {
+    scn19_p->exp = dl->Mbps_reserved / dl->Mbps_reference;
+    scn19_p->dyn.rb = 0;
+    scn19_p->dyn.eff = dl->Mbps_reference;
+    scn19_p->dyn.active = 0;
+  } if (dl->type == SCN19_OND) {
+    scn19_p->exp = dl->pct_reserved; // * 5000; // artificial rate
+    scn19_p->ond.rb = 0;
+    scn19_p->ond.t = 0;
+    scn19_p->ond.data_req = 0;
+  }
+  return index < 0 ? si->num - 1 : index;
+}
+
+//int addmod_scn19_slice_ul(slice_info_t *si,
+//                        int id,
+//                        char *label,
+//                        void *slice_params_ul) {
+//  scn19_slice_param_t *ul = slice_params_ul;
+//  int index = _exists_slice(si->num, si->s, id);
+//  if (index < 0 && si->num >= MAX_SCN19_SLICES)
+//    RET_FAIL(-2, "%s(): cannot handle more than %d slices\n", __func__, MAX_SCN19_SLICES);
+//
+//  const module_id_t mod_id = 0;
+//  const int CC_id = 0;
+//  const int N_RB_UL = to_prb(RC.mac[mod_id]->common_channels[CC_id].ul_Bandwidth);
+//  int rc = _scn19_admission_control(si->num, si->s, ul, index, N_RB_UL);
+//  if (rc < 0)
+//    return rc;
+//
+//  slice_t *ns = NULL;
+//  if (index < 0) {
+//    ns = _add_slice(&si->num, si->s);
+//    if (!ns)
+//      RET_FAIL(-4, "%s(): cannot allocate memory for slice\n", __func__);
+//    ns->id = id;
+//    ns->int_data = malloc(sizeof(_scn19_int_t));
+//    if (!ns->int_data)
+//      RET_FAIL(-5, "%s(): cannot allocate memory for slice internal data\n",
+//               __func__);
+//  } else {
+//    ns = si->s[index];
+//    free(ns->algo_data);
+//  }
+//  if (label) {
+//    if (ns->label)
+//      free(ns->label);
+//    ns->label = label;
+//  }
+//  ns->algo_data = ul;
+//  _scn19_int_t *scn19_p = ns->int_data;
+//  if (ul->type == SCN19_DYN) {
+//    scn19_p->exp = ul->Mbps_reserved;
+//    scn19_p->dyn.rb = 0;
+//    scn19_p->dyn.active = 0;
+//    scn19_p->dyn.eff = ul->Mbps_reference;
+//  } if (ul->type == SCN19_OND) {
+//    scn19_p->exp = ul->pct_reserved * 5000; // artificial rate
+//    scn19_p->ond.rb = 0;
+//    scn19_p->ond.t = 0;
+//    scn19_p->ond.data_req = 0;
+//  }
+//  return si->num - 1;
+//}
+
+void scn19_dl(module_id_t mod_id,
+               int CC_id,
+               frame_t frame,
+               sub_frame_t subframe) {
+  UE_info_t *UE_info = &RC.mac[mod_id]->UE_info;
+
+  store_dlsch_buffer(mod_id, CC_id, frame, subframe);
+
+  slice_info_t *si = RC.mac[mod_id]->pre_processor_dl.slices;
+  const COMMON_channels_t *cc = &RC.mac[mod_id]->common_channels[CC_id];
+  const uint8_t harq_pid = frame_subframe2_dl_harq_pid(cc->tdd_Config, frame, subframe);
+  for (int UE_id = UE_info->list.head; UE_id >= 0; UE_id = UE_info->list.next[UE_id]) {
+    UE_sched_ctrl_t *ue_sched_ctrl = &UE_info->UE_sched_ctrl[UE_id];
+
+    /* initialize per-UE scheduling information */
+    ue_sched_ctrl->pre_nb_available_rbs[CC_id] = 0;
+    ue_sched_ctrl->dl_pow_off[CC_id] = 2;
+    memset(ue_sched_ctrl->rballoc_sub_UE[CC_id], 0, sizeof(ue_sched_ctrl->rballoc_sub_UE[CC_id]));
+    ue_sched_ctrl->pre_dci_dl_pdu_idx = -1;
+
+    const UE_TEMPLATE *UE_template = &UE_info->UE_template[CC_id][UE_id];
+    const uint8_t round = UE_info->UE_sched_ctrl[UE_id].round[CC_id][harq_pid];
+    int B = UE_template->dl_buffer_total;
+    if (round != 8) {
+      /* we should account for the amount of data to be retransmitted if there
+       * is retransmission */
+      const int nb_rb = UE_template->nb_rb[harq_pid];
+      B += get_TBS_DL(UE_template->oldmcs1[harq_pid], nb_rb);
+    }
+    if (B > 0) {
+      /* mark this slice as active */
+      const int idx = si->UE_assoc_slice[UE_id];
+      const enum scn19_type type = ((scn19_slice_param_t *)si->s[idx]->algo_data)->type;
+      _scn19_int_t *i = (_scn19_int_t *)si->s[idx]->int_data;
+      if (type == SCN19_DYN)
+        i->dyn.active = 1;
+      if (type == SCN19_OND)
+        i->ond.data_req += B;
+    }
+  }
+
+  const int N_RBG = to_rbg(RC.mac[mod_id]->common_channels[CC_id].mib->message.dl_Bandwidth);
+  const int N_RB_DL = to_prb(RC.mac[mod_id]->common_channels[CC_id].mib->message.dl_Bandwidth);
+  const int RBGsize = get_min_rb_unit(mod_id, CC_id);
+  uint8_t *vrb_map = RC.mac[mod_id]->common_channels[CC_id].vrb_map;
+  uint8_t rbgalloc_mask[N_RBG_MAX];
+  int n_rbg_sched = 0;
+  for (int i = 0; i < N_RBG; i++) {
+    // calculate mask: init to one + "AND" with vrb_map:
+    // if any RB in vrb_map is blocked (1), the current RBG will be 0
+    rbgalloc_mask[i] = 1;
+    for (int j = 0; j < RBGsize && RBGsize * i + j < N_RB_DL; j++)
+      rbgalloc_mask[i] &= !vrb_map[RBGsize * i + j];
+    n_rbg_sched += rbgalloc_mask[i];
+  }
+
+  /* todo: schedule retransmission first */
+
+  float maxw_dyn = 0.0f;
+  int maxidx_dyn = -1;
+  float w_ond[MAX_SCN19_SLICES]; // weights for on-demand slices
+  int rbg_ond[MAX_SCN19_SLICES]; // number of RBGs this on-demand slice is allowed to use
+  struct {
+    int head;
+    int next[MAX_SCN19_SLICES];
+  } ond_list;
+  ond_list.head = -1;
+  for (int i = 0; i < si->num; ++i) {
+    w_ond[i] = 0.0f;
+    slice_t *s = si->s[i];
+    scn19_slice_param_t *p = s->algo_data;
+    _scn19_int_t *ip = s->int_data;
+    switch (p->type) {
+      case SCN19_DYN: {
+          /* if this slice has been marked as inactive, disable to prevent that
+           * it's effective rate is uselessly driven down */
+          if (!ip->dyn.active)
+            continue;
+          float inst = 0.0f;
+          if (ip->dyn.rb > 0) { /* it was scheduled last round */
+            /* inst rate: B in last round * 8(bit) / 1000 (kbps) */
+            inst = (float) _scn19_res_slice_used(mod_id, CC_id, &s->UEs) * 8 / 1000 / ip->dyn.rb;
+            /* TODO introduce beta_eff */
+            ip->dyn.eff = (1.0f - BETA) * ip->dyn.eff + BETA * inst * N_RB_DL;
+            ip->dyn.rb = 0;
+          }
+          ip->exp = (1 - BETA) * ip->exp + BETA * inst;
+          const float rsv = p->Mbps_reserved * min(1.0f, ip->dyn.eff / p->Mbps_reference);
+          float w = rsv / ip->exp;
+          if (w > maxw_dyn + 0.001f) {
+            maxw_dyn = w;
+            maxidx_dyn = i;
+          }
+        }
+        break;
+      case SCN19_FIX: {
+          uint8_t rbgalloc_slice_mask[N_RBG_MAX];
+          memset(rbgalloc_slice_mask, 0, sizeof(rbgalloc_slice_mask));
+          int n_rbg_sched_fix = 0;
+          for (int rbg = p->posLow; rbg <= p->posHigh && rbg <= N_RBG; ++rbg) {
+            rbgalloc_slice_mask[rbg] = rbgalloc_mask[rbg];
+            n_rbg_sched_fix += rbgalloc_mask[rbg];
+            rbgalloc_mask[rbg] = 0; // lock for other slices
+          }
+          n_rbg_sched -= n_rbg_sched_fix;
+          if (si->s[i]->UEs.head < 0)
+            continue;
+          si->s[i]->dl_algo.run(mod_id,
+                                CC_id,
+                                frame,
+                                subframe,
+                                &si->s[i]->UEs,
+                                1, // max_num_ue, might be adapted to size of allocation
+                                n_rbg_sched_fix,
+                                rbgalloc_slice_mask,
+                                si->s[i]->dl_algo.data);
+        }
+        break;
+      case SCN19_OND: {
+          float inst = 0.0f;
+          if (ip->ond.rb > 0) { /* it was scheduled last round */
+            /* inst rate: B in last round * 8(bit) /1000 (kbps) * 1000 (1ms) */
+            inst = _scn19_res_slice_used(mod_id, CC_id, &s->UEs);
+          }
+          ip->exp = (1.0f - BETA) * ip->exp + BETA * inst;
+          float w = p->log_delta * ip->ond.data_req / ip->exp;
+          ip->ond.data_req = 0;
+          const float lw = (float) ip->ond.rb / N_RB_DL;
+          ip->ond.t = (1.0f - 1.0f / p->tau) * ip->ond.t + lw / p->tau;
+          DevAssert(ip->ond.t > -0.001f && ip->ond.t < 1.001f);
+          const float tmax = min(1.0f, p->tau * p->pct_reserved + (1.0f - p->tau) * ip->ond.t);
+          const int rbg_max = tmax * N_RBG;
+          if (w > 0.01f && rbg_max > 0) {
+            w_ond[i] = w;
+            rbg_ond[i] = rbg_max;
+
+            /* insertion sort: insert the current slice such that the resulting
+             * list is sorted by descending weight */
+            int *l = &ond_list.head;
+            while (*l >= 0 && w_ond[*l] > w)
+              l = &ond_list.next[*l];
+            int temp = *l;
+            *l = i;
+            ond_list.next[i] = temp;
+          }
+          ip->ond.rb = 0;
+        }
+        break;
+    }
+  }
+
+  for (int idx_ond = ond_list.head; idx_ond >= 0; idx_ond = ond_list.next[idx_ond]) {
+    slice_t *s = si->s[idx_ond];
+    if (s->UEs.head < 0)
+      continue;
+    const int r = min(n_rbg_sched, rbg_ond[idx_ond]);
+    //LOG_W(MAC, "%3d.%d Schedule ondemand index %d/ID %d weight %f\n",
+    //      frame, subframe, idx_ond, s->id, w_ond[idx_ond]);
+    int rbg_rem = s->dl_algo.run(mod_id,
+                                 CC_id,
+                                 frame,
+                                 subframe,
+                                 &s->UEs,
+                                 1, // max_num_ue
+                                 r,
+                                 rbgalloc_mask,
+                                 s->dl_algo.data);
+    int used = r - rbg_rem;
+    ((_scn19_int_t *)s->int_data)->ond.rb = used * RBGsize;
+    n_rbg_sched -= used;
+    if (n_rbg_sched == 0)
+      break;
+  }
+
+  if (n_rbg_sched > 0 && maxidx_dyn >= 0) {
+    int nb_rb = n_rbg_sched * RBGsize;
+    if (rbgalloc_mask[N_RBG - 1]
+        && (N_RB_DL == 15 || N_RB_DL == 25 || N_RB_DL == 50 || N_RB_DL == 75))
+      nb_rb -= 1;
+    ((_scn19_int_t *)si->s[maxidx_dyn]->int_data)->dyn.rb = nb_rb;
+    int rbg_rem = n_rbg_sched;
+    if (si->s[maxidx_dyn]->UEs.head >= 0)
+      rbg_rem = si->s[maxidx_dyn]->dl_algo.run(mod_id,
+                                               CC_id,
+                                               frame,
+                                               subframe,
+                                               &si->s[maxidx_dyn]->UEs,
+                                               4, // max_num_ue
+                                               n_rbg_sched,
+                                               rbgalloc_mask,
+                                               si->s[maxidx_dyn]->dl_algo.data);
+    if (rbg_rem == n_rbg_sched) // if no RBGs have been used mark as inactive
+      ((_scn19_int_t *)si->s[maxidx_dyn]->int_data)->dyn.active = 0;
+  }
+
+  // the following block is meant for validation of the pre-processor to check
+  // whether all UE allocations are non-overlapping and is not necessary for
+  // scheduling functionality
+  char t[26] = "_________________________";
+  t[N_RBG] = 0;
+  for (int i = 0; i < N_RBG; i++)
+    for (int j = 0; j < RBGsize; j++)
+      if (vrb_map[RBGsize*i+j] != 0)
+        t[i] = 'x';
+  int print = 0;
+  for (int UE_id = UE_info->list.head; UE_id >= 0; UE_id = UE_info->list.next[UE_id]) {
+    const UE_sched_ctrl_t *ue_sched_ctrl = &UE_info->UE_sched_ctrl[UE_id];
+
+    if (ue_sched_ctrl->pre_nb_available_rbs[CC_id] == 0)
+      continue;
+
+    LOG_D(MAC,
+          "%4d.%d UE%d %d RBs allocated, pre MCS %d\n",
+          frame,
+          subframe,
+          UE_id,
+          ue_sched_ctrl->pre_nb_available_rbs[CC_id],
+          UE_info->eNB_UE_stats[CC_id][UE_id].dlsch_mcs1);
+
+    print = 1;
+
+    for (int i = 0; i < N_RBG; i++) {
+      if (!ue_sched_ctrl->rballoc_sub_UE[CC_id][i])
+        continue;
+      for (int j = 0; j < RBGsize; j++) {
+        if (vrb_map[RBGsize*i+j] != 0) {
+          LOG_I(MAC, "%4d.%d DL scheduler allocation list: %s\n", frame, subframe, t);
+          LOG_E(MAC, "%4d.%d: UE %d allocated at locked RB %d/RBG %d\n", frame,
+                subframe, UE_id, RBGsize * i + j, i);
+        }
+        vrb_map[RBGsize*i+j] = 1;
+      }
+      t[i] = '0' + UE_id;
+    }
+  }
+  if (print)
+    LOG_D(MAC, "%4d.%d DL scheduler allocation list: %s\n", frame, subframe, t);
+}
+
+//void scn19_ul(module_id_t mod_id,
+//               int CC_id,
+//               frame_t frame,
+//               sub_frame_t subframe,
+//               frame_t sched_frame,
+//               sub_frame_t sched_subframe) {
+//  ulsch_scheduler_pre_processor(mod_id, CC_id, frame, subframe, sched_frame, sched_subframe);
+//}
+
+pp_impl_param_t scn19_dl_init(module_id_t mod_id, int CC_id) {
+  slice_info_t *si = calloc(1, sizeof(slice_info_t));
+  DevAssert(si);
+
+  si->num = 0;
+  si->s = calloc(MAX_SCN19_SLICES, sizeof(slice_t));
+  DevAssert(si->s);
+  for (int i = 0; i < MAX_MOBILES_PER_ENB; ++i)
+    si->UE_assoc_slice[i] = -1;
+
+  /* insert default slice, all resources */
+  scn19_slice_param_t *dlp = malloc(sizeof(scn19_slice_param_t));
+  DevAssert(dlp);
+  dlp->type = SCN19_FIX;
+  dlp->posLow = 0;
+  dlp->posHigh = to_rbg(RC.mac[mod_id]->common_channels[CC_id].mib->message.dl_Bandwidth) - 1;
+  default_sched_dl_algo_t *algo = &RC.mac[mod_id]->pre_processor_dl.dl_algo;
+  algo->data = NULL;
+  const int rc = addmod_scn19_slice_dl(si, 0, strdup("default"), algo, dlp);
+  DevAssert(0 == rc);
+  const UE_list_t *UE_list = &RC.mac[mod_id]->UE_info.list;
+  for (int UE_id = UE_list->head; UE_id >= 0; UE_id = UE_list->next[UE_id])
+    slicing_add_UE(si, UE_id);
+
+  pp_impl_param_t scn19;
+  scn19.algorithm = SCN19_SLICING;
+  scn19.add_UE = slicing_add_UE;
+  scn19.remove_UE = slicing_remove_UE;
+  scn19.move_UE = slicing_move_UE;
+  scn19.addmod_slice = addmod_scn19_slice_dl;
+  scn19.remove_slice = remove_nvs_slice_dl; // removing SCN19 slice as in NVS
+  scn19.dl = scn19_dl;
+  // current DL algo becomes default scheduler
+  scn19.dl_algo = *algo;
+  scn19.destroy = nvs_destroy;
+  scn19.slices = si;
+
+  return scn19;
+}
diff --git a/openair2/LAYER2/MAC/slicing/slicing.h b/openair2/LAYER2/MAC/slicing/slicing.h
index 1099b50ea0..3e77798421 100644
--- a/openair2/LAYER2/MAC/slicing/slicing.h
+++ b/openair2/LAYER2/MAC/slicing/slicing.h
@@ -71,4 +71,33 @@ pp_impl_param_t static_dl_init(module_id_t mod_id, int CC_id);
 pp_impl_param_t static_ul_init(module_id_t mod_id, int CC_id);
 
 
+#define NVS_SLICING 20
+/* arbitrary upper limit, increase if you want to instantiate more slices */
+#define MAX_NVS_SLICES 10
+/* window for slice weight averaging -> 1s for fine granularity */
+#define BETA 0.001f
+typedef struct {
+  enum nvs_type {NVS_RATE, NVS_RES} type;
+  union {
+    struct { float Mbps_reserved; float Mbps_reference; };
+    struct { float pct_reserved; };
+  };
+} nvs_slice_param_t;
+pp_impl_param_t nvs_dl_init(module_id_t mod_id, int CC_id);
+
+
+#define SCN19_SLICING 30
+/* arbitrary upper limit, increase if you want to instantiate more slices */
+#define MAX_SCN19_SLICES 10
+#define BETA 0.001f
+typedef struct {
+  enum scn19_type {SCN19_DYN, SCN19_FIX, SCN19_OND } type;
+  union {
+    struct { float Mbps_reserved; float Mbps_reference; };
+    struct { uint16_t posLow; uint16_t posHigh; };
+    struct { float pct_reserved; uint16_t tau; float log_delta; };
+  };
+} scn19_slice_param_t;
+pp_impl_param_t scn19_dl_init(module_id_t mod_id, int CC_id);
+
 #endif /* __SLICING_H__ */
diff --git a/openair2/LAYER2/MAC/ue_procedures.c b/openair2/LAYER2/MAC/ue_procedures.c
index 9ae8f82a00..5a5948c0f8 100644
--- a/openair2/LAYER2/MAC/ue_procedures.c
+++ b/openair2/LAYER2/MAC/ue_procedures.c
@@ -158,9 +158,10 @@ void ue_init_mac(module_id_t module_idP) {
 
   if(NFAPI_MODE==NFAPI_UE_STUB_PNF) {
     pthread_mutex_init(&UE_mac_inst[module_idP].UL_INFO_mutex,NULL);
-    UE_mac_inst[module_idP].UE_mode[0] = NOT_SYNCHED; //PRACH;
+    UE_mac_inst[module_idP].UE_mode[0] = PRACH_INACTIVE;
     UE_mac_inst[module_idP].first_ULSCH_Tx =0;
     UE_mac_inst[module_idP].SI_Decoded = 0;
+    UE_mac_inst[module_idP].SIB_Decoded = 0;
     next_ra_frame = 0;
     next_Mod_id = 0;
     tx_request_pdu_list = NULL;
diff --git a/openair2/LAYER2/NR_MAC_gNB/config.c b/openair2/LAYER2/NR_MAC_gNB/config.c
index 98e9ce4351..87f73b0382 100644
--- a/openair2/LAYER2/NR_MAC_gNB/config.c
+++ b/openair2/LAYER2/NR_MAC_gNB/config.c
@@ -421,7 +421,7 @@ int rrc_mac_config_req_gNB(module_id_t Mod_idP,
     }
 
     if (get_softmodem_params()->phy_test) {
-      RC.nrmac[Mod_idP]->pre_processor_dl = nr_preprocessor_phytest;
+      RC.nrmac[Mod_idP]->pre_processor_dl.dl = nr_preprocessor_phytest;
       RC.nrmac[Mod_idP]->pre_processor_ul = nr_ul_preprocessor_phytest;
     } else {
       RC.nrmac[Mod_idP]->pre_processor_dl = nr_init_fr1_dlsch_preprocessor(Mod_idP, 0);
diff --git a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler.c b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler.c
index 36f687b5cd..8496128d9d 100644
--- a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler.c
+++ b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler.c
@@ -55,15 +55,131 @@
 #include "nfapi/oai_integration/vendor_ext.h"
 #include "executables/nr-softmodem.h"
 
+#include "LAYER2/nr_pdcp/nr_pdcp_entity.h"
+#include "LAYER2/nr_rlc/nr_rlc_entity.h"
+
 uint16_t nr_pdcch_order_table[6] = { 31, 31, 511, 2047, 2047, 8191 };
 
 void clear_mac_stats(gNB_MAC_INST *gNB) {
   memset((void*)gNB->UE_info.mac_stats,0,MAX_MOBILES_PER_GNB*sizeof(NR_mac_stats_t));
 }
 
+void dump_rlc_stats(int rnti, int is_srb, int rb_id, nr_rlc_statistics_t *stats)
+{
+  LOG_I(MAC, "rnti %d %s %d RLC stats:\n"
+        "    mode %s\n"
+        "    PDU TX:\n"
+        "      txpdu_pkts         %d\n"
+        "      txpdu_bytes        %"PRIu64"\n"
+        "      txpdu_dd_pkts      %d\n"
+        "      txpdu_dd_bytes     %"PRIu64"\n"
+        "      txpdu_retx_pkts    %d\n"
+        "      txpdu_retx_bytes   %"PRIu64"\n"
+        "      txpdu_segmented    %d\n"
+        "      txpdu_status_pkts  %d\n"
+        "      txpdu_status_bytes %"PRIu64"\n"
+        "    PDU RX:\n"
+        "      rxpdu_pkts         %d\n"
+        "      rxpdu_bytes        %"PRIu64"\n"
+        "      rxpdu_dup_pkts     %d\n"
+        "      rxpdu_dup_bytes    %"PRIu64"\n"
+        "      rxpdu_dd_pkts      %d\n"
+        "      rxpdu_dd_bytes     %"PRIu64"\n"
+        "      rxpdu_ow_pkts      %d\n"
+        "      rxpdu_ow_bytes     %"PRIu64"\n"
+        "      rxpdu_status_pkts  %d\n"
+        "      rxpdu_status_bytes %"PRIu64"\n"
+        "    SDU TX:\n"
+        "      txsdu_pkts         %d\n"
+        "      txsdu_bytes        %"PRIu64"\n"
+        "    SDU RX:\n"
+        "      rxsdu_pkts         %d\n"
+        "      rxsdu_bytes        %"PRIu64"\n"
+        "      rxsdu_dd_pkts      %d\n"
+        "      rxsdu_dd_bytes     %"PRIu64"\n",
+        rnti, is_srb ? "SRB" : "DRB", rb_id,
+        stats->mode == 0 ? "AM" : stats->mode == 1 ? "UM" : "TM",
+        stats->txpdu_pkts,
+        stats->txpdu_bytes,
+        stats->txpdu_dd_pkts,
+        stats->txpdu_dd_bytes,
+        stats->txpdu_retx_pkts,
+        stats->txpdu_retx_bytes,
+        stats->txpdu_segmented,
+        stats->txpdu_status_pkts,
+        stats->txpdu_status_bytes,
+        stats->rxpdu_pkts,
+        stats->rxpdu_bytes,
+        stats->rxpdu_dup_pkts,
+        stats->rxpdu_dup_bytes,
+        stats->rxpdu_dd_pkts,
+        stats->rxpdu_dd_bytes,
+        stats->rxpdu_ow_pkts,
+        stats->rxpdu_ow_bytes,
+        stats->rxpdu_status_pkts,
+        stats->rxpdu_status_bytes,
+        stats->txsdu_pkts,
+        stats->txsdu_bytes,
+        stats->rxsdu_pkts,
+        stats->rxsdu_bytes,
+        stats->rxsdu_dd_pkts,
+        stats->rxsdu_dd_bytes);
+}
+
+void dump_pdcp_stats(int rnti, int is_srb, int rb_id, nr_pdcp_statistics_t *stats)
+{
+  LOG_I(MAC, "rnti %d %s %d PDCP stats:\n"
+        "    mode %s\n"
+        "    PDU TX:\n"
+        "      txpdu_pkts     %d\n"
+        "      txpdu_bytes    %"PRIu64"\n"
+        "      txpdu_sn       %d\n"
+        "    PDU RX:\n"
+        "      rxpdu_pkts     %d\n"
+        "      rxpdu_bytes    %"PRIu64"\n"
+        "      rxpdu_sn       %d\n"
+        "      rxpdu_dd_pkts  %d\n"
+        "      rxpdu_dd_bytes %"PRIu64"\n"
+        "    SDU TX:\n"
+        "      txsdu_pkts     %d\n"
+        "      txsdu_bytes    %"PRIu64"\n"
+        "    SDU RX:\n"
+        "      rxsdu_pkts     %d\n"
+        "      rxsdu_bytes    %"PRIu64"\n",
+        rnti, is_srb ? "SRB" : "DRB", rb_id,
+        stats->mode == NR_PDCP_DRB_AM ? "DRB AM" : stats->mode == NR_PDCP_DRB_UM ? "DRB UM" : "SRB",
+        stats->txpdu_pkts,
+        stats->txpdu_bytes,
+        stats->txpdu_sn,
+        stats->rxpdu_pkts,
+        stats->rxpdu_bytes,
+        stats->rxpdu_sn,
+        stats->rxpdu_dd_pkts,
+        stats->rxpdu_dd_bytes,
+        stats->txsdu_pkts,
+        stats->txsdu_bytes,
+        stats->rxsdu_pkts,
+        stats->rxsdu_bytes);
+}
+
 void dump_mac_stats(gNB_MAC_INST *gNB)
 {
   NR_UE_info_t *UE_info = &gNB->UE_info;
+  nr_pdcp_statistics_t pdcp;
+  nr_rlc_statistics_t  rlc;
+
+  /* TODO: put these in some .h file(s) */
+  int nr_pdcp_get_statistics(
+    int rnti,
+    int srb_flag,
+    int rb_id,
+    nr_pdcp_statistics_t *out);
+  int nr_rlc_get_statistics(
+    int rnti,
+    int srb_flag,
+    int rb_id,
+    nr_rlc_statistics_t *out);
+
   int num = 1;
   for (int UE_id = UE_info->list.head; UE_id >= 0; UE_id = UE_info->list.next[UE_id]) {
     LOG_I(MAC, "UE ID %d RNTI %04x (%d/%d) PH %d dB PCMAX %d dBm\n",
@@ -102,6 +218,22 @@ void dump_mac_stats(gNB_MAC_INST *gNB)
       if (stats->lc_bytes_rx[lc_id] > 0)
         LOG_I(MAC, "UE %d: LCID %d: %d bytes RX\n", UE_id, lc_id, stats->lc_bytes_rx[lc_id]);
     }
+
+    /* RLC stats for SRB 1&2 and DRB 1 */
+    //if (nr_rlc_get_statistics(UE_info->rnti[UE_id], 1, 1, &rlc))
+    //  dump_rlc_stats(UE_info->rnti[UE_id], 1, 1, &rlc);
+    //if (nr_rlc_get_statistics(UE_info->rnti[UE_id], 1, 2, &rlc))
+    //  dump_rlc_stats(UE_info->rnti[UE_id], 1, 2, &rlc);
+    //if (nr_rlc_get_statistics(UE_info->rnti[UE_id], 0, 1, &rlc))
+    //  dump_rlc_stats(UE_info->rnti[UE_id], 0, 1, &rlc);
+
+    ///* PDCP stats for SRB 1&2 and DRB 1 */
+    //if (nr_pdcp_get_statistics(UE_info->rnti[UE_id], 1, 1, &pdcp))
+    //  dump_pdcp_stats(UE_info->rnti[UE_id], 1, 1, &pdcp);
+    //if (nr_pdcp_get_statistics(UE_info->rnti[UE_id], 1, 2, &pdcp))
+    //  dump_pdcp_stats(UE_info->rnti[UE_id], 1, 2, &pdcp);
+    //if (nr_pdcp_get_statistics(UE_info->rnti[UE_id], 0, 1, &pdcp))
+    //  dump_pdcp_stats(UE_info->rnti[UE_id], 0, 1, &pdcp);
   }
   print_meas(&gNB->eNB_scheduler, "DL & UL scheduling timing stats", NULL, NULL);
 }
@@ -342,6 +474,9 @@ void gNB_dlsch_ulsch_scheduler(module_id_t module_idP,
       gNB->tdd_beam_association[i] = -1;
   }
 
+  gNB->frame = frame;
+  gNB->slot = slot;
+
   start_meas(&RC.nrmac[module_idP]->eNB_scheduler);
   VCD_SIGNAL_DUMPER_DUMP_FUNCTION_BY_NAME(VCD_SIGNAL_DUMPER_FUNCTIONS_gNB_DLSCH_ULSCH_SCHEDULER,VCD_FUNCTION_IN);
 
diff --git a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_dlsch.c b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_dlsch.c
index cb1a73edae..a255630435 100644
--- a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_dlsch.c
+++ b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_dlsch.c
@@ -522,18 +522,34 @@ bool allocate_dl_retransmission(module_id_t module_id,
   return true;
 }
 
-float thr_ue[MAX_MOBILES_PER_GNB];
 uint32_t pf_tbs[3][28]; // pre-computed, approximate TBS values for PF coefficient
-
-void pf_dl(module_id_t module_id,
-           frame_t frame,
-           sub_frame_t slot,
-           NR_list_t *UE_list,
-           int max_num_ue,
-           int n_rb_sched,
-           uint8_t *rballoc_mask) {
+void *nr_pf_dl_setup(void)
+{
+  void *data = malloc(MAX_MOBILES_PER_GNB * sizeof(float));
+  AssertFatal(data, "%s(): could not allocate data\n", __func__);
+  for (int i = 0; i < MAX_MOBILES_PER_ENB; i++)
+    *(float *) data = 0.0f;
+  return data;
+}
+void nr_pf_dl_unset(void **data)
+{
+  DevAssert(data);
+  if (*data)
+    free(*data);
+  *data = NULL;
+}
+void nr_pf_dl(module_id_t module_id,
+              frame_t frame,
+              sub_frame_t slot,
+              NR_list_t *UE_list,
+              int max_num_ue,
+              int n_rb_sched,
+              uint8_t *rballoc_mask,
+              void *data)
+{
   const NR_ServingCellConfigCommon_t *scc = RC.nrmac[module_id]->common_channels->ServingCellConfigCommon;
   NR_UE_info_t *UE_info = &RC.nrmac[module_id]->UE_info;
+  float *thr_ue = data;
   float coeff_ue[MAX_MOBILES_PER_GNB];
   // UEs that could be scheduled
   int ue_array[MAX_MOBILES_PER_GNB];
@@ -673,10 +689,18 @@ void pf_dl(module_id_t module_id,
       rballoc_mask[rb + sched_pdsch->rbStart] = 0;
   }
 }
+nr_dl_sched_algo_t nr_proportional_fair_wbcqi_dl = {
+  .name  = "nr_proportional_fair_wbcqi_dl",
+  .setup = nr_pf_dl_setup,
+  .unset = nr_pf_dl_unset,
+  .run   = nr_pf_dl,
+  .data  = NULL
+};
 
 void nr_fr1_dlsch_preprocessor(module_id_t module_id, frame_t frame, sub_frame_t slot)
 {
-  NR_UE_info_t *UE_info = &RC.nrmac[module_id]->UE_info;
+  gNB_MAC_INST *nrmac = RC.nrmac[module_id];
+  NR_UE_info_t *UE_info = &nrmac->UE_info;
 
   if (UE_info->num_UEs == 0)
     return;
@@ -708,16 +732,17 @@ void nr_fr1_dlsch_preprocessor(module_id_t module_id, frame_t frame, sub_frame_t
   nr_store_dlsch_buffer(module_id, frame, slot);
 
   /* proportional fair scheduling algorithm */
-  pf_dl(module_id,
-        frame,
-        slot,
-        &UE_info->list,
-        2,
-        n_rb_sched,
-        rballoc_mask);
+  nrmac->pre_processor_dl.dl_algo.run(module_id,
+                                      frame,
+                                      slot,
+                                      &UE_info->list,
+                                      2,
+                                      n_rb_sched,
+                                      rballoc_mask,
+                                      nrmac->pre_processor_dl.dl_algo.data);
 }
 
-nr_pp_impl_dl nr_init_fr1_dlsch_preprocessor(module_id_t module_id, int CC_id)
+nr_pp_impl_param_dl_t nr_init_fr1_dlsch_preprocessor(module_id_t module_id, int CC_id)
 {
   /* in the PF algorithm, we have to use the TBsize to compute the coefficient.
    * This would include the number of DMRS symbols, which in turn depends on
@@ -742,7 +767,12 @@ nr_pp_impl_dl nr_init_fr1_dlsch_preprocessor(module_id_t module_id, int CC_id)
     }
   }
 
-  return nr_fr1_dlsch_preprocessor;
+  nr_pp_impl_param_dl_t impl;
+  memset(&impl, 0, sizeof(impl));
+  impl.dl = nr_fr1_dlsch_preprocessor;
+  impl.dl_algo = nr_proportional_fair_wbcqi_dl;
+  impl.dl_algo.data = impl.dl_algo.setup();
+  return impl;
 }
 
 void nr_schedule_ue_spec(module_id_t module_id,
@@ -753,7 +783,9 @@ void nr_schedule_ue_spec(module_id_t module_id,
     return;
 
   /* PREPROCESSOR */
-  gNB_mac->pre_processor_dl(module_id, frame, slot);
+  pthread_mutex_lock(&gNB_mac->pp_mutex);
+  gNB_mac->pre_processor_dl.dl(module_id, frame, slot);
+  pthread_mutex_unlock(&gNB_mac->pp_mutex);
 
   const int CC_id = 0;
   NR_ServingCellConfigCommon_t *scc = gNB_mac->common_channels[CC_id].ServingCellConfigCommon;
@@ -810,10 +842,17 @@ void nr_schedule_ue_spec(module_id_t module_id,
       else
         remove_nr_list(&sched_ctrl->retrans_dl_harq, current_harq_pid);
     }
+
+    DevAssert(sched_pdsch->pucch_allocation == 0);
+    NR_sched_pucch_t *pucch = &sched_ctrl->sched_pucch[sched_pdsch->pucch_allocation];
+    if (sched_pdsch->pucch_allocation == 1 && pucch->frame == 0 && pucch->ul_slot == 0) {
+      LOG_W(MAC, "pucch_allocation %d pucch %4d.%2d\n", sched_pdsch->pucch_allocation, pucch->frame, pucch->ul_slot);
+      continue;
+    }
+
     NR_UE_harq_t *harq = &sched_ctrl->harq_processes[current_harq_pid];
     DevAssert(!harq->is_waiting);
     add_tail_nr_list(&sched_ctrl->feedback_dl_harq, current_harq_pid);
-    NR_sched_pucch_t *pucch = &sched_ctrl->sched_pucch[sched_pdsch->pucch_allocation];
     harq->feedback_frame = pucch->frame;
     harq->feedback_slot = pucch->ul_slot;
     harq->is_waiting = true;
@@ -1028,6 +1067,8 @@ void nr_schedule_ue_spec(module_id_t module_id,
                   "UE %d mismatch between scheduled TBS and buffered TB for HARQ PID %d\n",
                   UE_id,
                   current_harq_pid);
+      NR_mac_stats_t *mac_stats = &UE_info->mac_stats[UE_id];
+      mac_stats->dlsch_total_rbs_retx += sched_pdsch->rbSize;
     } else { /* initial transmission */
 
       LOG_D(MAC, "[%s] Initial HARQ transmission in %d.%d\n", __FUNCTION__, frame, slot);
@@ -1048,6 +1089,7 @@ void nr_schedule_ue_spec(module_id_t module_id,
 
       const int lcid = DL_SCH_LCID_DTCH;
       int dlsch_total_bytes = 0;
+      int sdus = 0;
       if (sched_ctrl->num_total_bytes > 0) {
         tbs_size_t len = 0;
         while (size > 3) {
@@ -1093,6 +1135,7 @@ void nr_schedule_ue_spec(module_id_t module_id,
           size -= len;
           buf += len;
           dlsch_total_bytes += len;
+          sdus += 1;
         }
         if (len == 0) {
           /* RLC did not have data anymore, mark buffer as unused */
@@ -1119,6 +1162,7 @@ void nr_schedule_ue_spec(module_id_t module_id,
         size -= size;
         buf += size;
         dlsch_total_bytes += size;
+        sdus += 1;
       }
 
       // Add padding header and zero rest out if there is space left
@@ -1135,9 +1179,12 @@ void nr_schedule_ue_spec(module_id_t module_id,
         }
       }
 
-      UE_info->mac_stats[UE_id].dlsch_total_bytes += TBS;
-      UE_info->mac_stats[UE_id].dlsch_current_bytes = TBS;
-      UE_info->mac_stats[UE_id].lc_bytes_tx[lcid] += dlsch_total_bytes;
+      NR_mac_stats_t *mac_stats = &UE_info->mac_stats[UE_id];
+      mac_stats->dlsch_total_bytes += TBS;
+      mac_stats->dlsch_current_bytes = TBS;
+      mac_stats->lc_bytes_tx[lcid] += dlsch_total_bytes;
+      mac_stats->dlsch_total_rbs += sched_pdsch->rbSize;
+      mac_stats->dlsch_num_mac_sdu += sdus;
 
       /* save retransmission information */
       harq->sched_pdsch = *sched_pdsch;
diff --git a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_primitives.c b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_primitives.c
index b3d2ecb0b2..8da42aefdf 100644
--- a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_primitives.c
+++ b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_primitives.c
@@ -1768,6 +1768,9 @@ int add_new_nr_ue(module_id_t mod_idP, rnti_t rntiP, NR_CellGroupConfig_t *secon
     UE_info->secondaryCellGroup[UE_id] = secondaryCellGroup;
     add_nr_list(&UE_info->list, UE_id);
     memset(&UE_info->mac_stats[UE_id], 0, sizeof(NR_mac_stats_t));
+    nr_pp_impl_param_dl_t* dl = &RC.nrmac[mod_idP]->pre_processor_dl;
+    if (dl->slices)
+      dl->add_UE(dl->slices, UE_id);
     set_Y(UE_info->Y[UE_id], rntiP);
     compute_csi_bitlen (secondaryCellGroup->spCellConfig->spCellConfigDedicated->csi_MeasConfig->choice.setup, UE_info, UE_id, mod_idP);
     NR_UE_sched_ctrl_t *sched_ctrl = &UE_info->UE_sched_ctrl[UE_id];
@@ -1861,6 +1864,9 @@ void mac_remove_nr_ue(module_id_t mod_id, rnti_t rnti)
     UE_info->num_UEs--;
     UE_info->active[UE_id] = FALSE;
     UE_info->rnti[UE_id] = 0;
+    nr_pp_impl_param_dl_t* dl = &RC.nrmac[mod_id]->pre_processor_dl;
+    if (dl->slices)
+      dl->remove_UE(dl->slices, UE_id);
     remove_nr_list(&UE_info->list, UE_id);
     NR_UE_sched_ctrl_t *sched_ctrl = &UE_info->UE_sched_ctrl[UE_id];
     destroy_nr_list(&sched_ctrl->available_dl_harq);
diff --git a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_uci.c b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_uci.c
index f53f79ba49..0a882791a8 100644
--- a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_uci.c
+++ b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_uci.c
@@ -1257,11 +1257,6 @@ int nr_acknack_scheduling(int mod_id,
     }
   }
 
-  pucch->timing_indicator = i; // index in the list of timing indicators
-
-  pucch->dai_c++;
-  pucch->resource_indicator = 0; // each UE has dedicated PUCCH resources
-
   /* verify that at that slot and symbol, resources are free. We only do this
    * for initialCyclicShift 0 (we assume it always has that one), so other
    * initialCyclicShifts can overlap with ICS 0!*/
@@ -1271,10 +1266,17 @@ int nr_acknack_scheduling(int mod_id,
   if (resource->format.choice.format0->initialCyclicShift == 0) {
     uint16_t *vrb_map_UL = &RC.nrmac[mod_id]->common_channels[CC_id].vrb_map_UL[pucch->ul_slot * MAX_BWP_SIZE];
     const uint16_t symb = 1 << resource->format.choice.format0->startingSymbolIndex;
-    if ((vrb_map_UL[resource->startingPRB] & symb) != 0)
+    if ((vrb_map_UL[resource->startingPRB] & symb) != 0) {
       LOG_W(MAC, "symbol 0x%x is not free for PUCCH alloc in vrb_map_UL at RB %ld and slot %d.%d\n", symb, resource->startingPRB, pucch->frame, pucch->ul_slot);
+      return -1; // we cannot allocate?!
+    }
     vrb_map_UL[resource->startingPRB] |= symb;
   }
+
+  pucch->timing_indicator = i; // index in the list of timing indicators
+
+  pucch->dai_c++;
+  pucch->resource_indicator = 0; // each UE has dedicated PUCCH resources
   return 0;
 }
 
diff --git a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_ulsch.c b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_ulsch.c
index 323baa48a7..5239e4c6f9 100644
--- a/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_ulsch.c
+++ b/openair2/LAYER2/NR_MAC_gNB/gNB_scheduler_ulsch.c
@@ -187,6 +187,7 @@ void nr_process_mac_pdu(module_id_t module_idP,
     uint8_t *pdu_ptr = pduP, rx_lcid, done = 0;
     int pdu_len = mac_pdu_len;
     uint16_t mac_ce_len, mac_subheader_len, mac_sdu_len;
+    int sdus = 0;
 
 
     NR_UE_info_t *UE_info = &RC.nrmac[module_idP]->UE_info;
@@ -444,10 +445,10 @@ void nr_process_mac_pdu(module_id_t module_idP,
           else
             sched_ctrl->estimated_ul_buffer = 0;
           break;
+          sdus += 1;
 
         default:
           LOG_E(MAC, "Received unknown MAC header (LCID = 0x%02x)\n", rx_lcid);
-          return;
           break;
         }
         pdu_ptr += ( mac_subheader_len + mac_ce_len + mac_sdu_len );
@@ -459,9 +460,11 @@ void nr_process_mac_pdu(module_id_t module_idP,
           for (int i = 0; i < 20; i++) // Only printf 1st - 20nd bytes
             printf("%02x ", pdu_ptr[i]);
           printf("\n");
-          return;
+          break;
         }
     }
+  NR_mac_stats_t *mac_stats = &UE_info->mac_stats[UE_id];
+  mac_stats->ulsch_num_mac_sdu += sdus;
 }
 
 void abort_nr_ul_harq(module_id_t mod_id, int UE_id, int8_t harq_pid)
@@ -1286,9 +1289,10 @@ void nr_schedule_ulsch(module_id_t module_id, frame_t frame, sub_frame_t slot)
     NR_pusch_semi_static_t *ps = &sched_ctrl->pusch_semi_static;
 
     /* Statistics */
-    UE_info->mac_stats[UE_id].ulsch_rounds[cur_harq->round]++;
+    NR_mac_stats_t* mac_stats = &UE_info->mac_stats[UE_id];
+    mac_stats->ulsch_rounds[cur_harq->round]++;
     if (cur_harq->round == 0) {
-      UE_info->mac_stats[UE_id].ulsch_total_bytes_scheduled += sched_pusch->tb_size;
+      mac_stats->ulsch_total_bytes_scheduled += sched_pusch->tb_size;
       /* Save information on MCS, TBS etc for the current initial transmission
        * so we have access to it when retransmitting */
       cur_harq->sched_pusch = *sched_pusch;
@@ -1296,6 +1300,7 @@ void nr_schedule_ulsch(module_id_t module_id, frame_t frame, sub_frame_t slot)
        * retransmissions */
       cur_harq->sched_pusch.time_domain_allocation = ps->time_domain_allocation;
       sched_ctrl->sched_ul_bytes += sched_pusch->tb_size;
+      mac_stats->ulsch_total_rbs += sched_pusch->rbSize;
     } else {
       LOG_D(MAC,
             "%d.%2d UL retransmission RNTI %04x sched %d.%2d HARQ PID %d round %d NDI %d\n",
@@ -1307,6 +1312,7 @@ void nr_schedule_ulsch(module_id_t module_id, frame_t frame, sub_frame_t slot)
             harq_id,
             cur_harq->round,
             cur_harq->ndi);
+      mac_stats->ulsch_total_rbs_retx += sched_pusch->rbSize;
     }
     UE_info->mac_stats[UE_id].ulsch_current_bytes = sched_pusch->tb_size;
     sched_ctrl->last_ul_frame = sched_pusch->frame;
diff --git a/openair2/LAYER2/NR_MAC_gNB/mac_proto.h b/openair2/LAYER2/NR_MAC_gNB/mac_proto.h
index 1010ebafda..06fc6da455 100644
--- a/openair2/LAYER2/NR_MAC_gNB/mac_proto.h
+++ b/openair2/LAYER2/NR_MAC_gNB/mac_proto.h
@@ -75,7 +75,7 @@ void nr_schedule_ue_spec(module_id_t module_id,
                          sub_frame_t slot);
 
 /* \brief default FR1 DL preprocessor init routine, returns preprocessor to call */
-nr_pp_impl_dl nr_init_fr1_dlsch_preprocessor(module_id_t module_id, int CC_id);
+nr_pp_impl_param_dl_t nr_init_fr1_dlsch_preprocessor(module_id_t module_id, int CC_id);
 
 void schedule_control_sib1(module_id_t module_id,
                            int CC_id,
diff --git a/openair2/LAYER2/NR_MAC_gNB/main.c b/openair2/LAYER2/NR_MAC_gNB/main.c
index 60b0cac215..3c591eb44f 100644
--- a/openair2/LAYER2/NR_MAC_gNB/main.c
+++ b/openair2/LAYER2/NR_MAC_gNB/main.c
@@ -82,12 +82,13 @@ void mac_top_init_gNB(void)
       RC.nrmac[i]->ul_handle = 0;
 
       if (get_softmodem_params()->phy_test) {
-        RC.nrmac[i]->pre_processor_dl = nr_preprocessor_phytest;
+        RC.nrmac[i]->pre_processor_dl.dl = nr_preprocessor_phytest;
         RC.nrmac[i]->pre_processor_ul = nr_ul_preprocessor_phytest;
       } else {
         RC.nrmac[i]->pre_processor_dl = nr_init_fr1_dlsch_preprocessor(i, 0);
         RC.nrmac[i]->pre_processor_ul = nr_init_fr1_ulsch_preprocessor(i, 0);
       }
+      pthread_mutex_init(&RC.nrmac[i]->pp_mutex, NULL);
 
     }//END for (i = 0; i < RC.nb_nr_macrlc_inst; i++)
 
diff --git a/openair2/LAYER2/NR_MAC_gNB/nr_mac_gNB.h b/openair2/LAYER2/NR_MAC_gNB/nr_mac_gNB.h
index c1ec27580f..a94a56782e 100644
--- a/openair2/LAYER2/NR_MAC_gNB/nr_mac_gNB.h
+++ b/openair2/LAYER2/NR_MAC_gNB/nr_mac_gNB.h
@@ -600,11 +600,17 @@ typedef struct {
   int dlsch_errors;
   int dlsch_total_bytes;
   int dlsch_current_bytes;
+  int dlsch_total_rbs;
+  int dlsch_total_rbs_retx;
+  int dlsch_num_mac_sdu;
   int ulsch_rounds[8];
   int ulsch_errors;
   int ulsch_total_bytes_scheduled;
   int ulsch_total_bytes_rx;
   int ulsch_current_bytes;
+  int ulsch_total_rbs;
+  int ulsch_total_rbs_retx;
+  int ulsch_num_mac_sdu;
   int cumul_rsrp;
   uint8_t num_rsrp_meas;
 } NR_mac_stats_t;
@@ -631,6 +637,19 @@ typedef struct {
   uint8_t UE_beam_index[MAX_MOBILES_PER_GNB];
 } NR_UE_info_t;
 
+/**
+ * definition of a scheduling algorithm implementation used in the
+ * default DL scheduler
+ */
+typedef struct {
+  char *name;
+  void *(*setup)(void);
+  void (*unset)(void **);
+  void (*run)(
+      module_id_t, frame_t, sub_frame_t, NR_list_t *, int, int, uint8_t *, void *);
+  void *data;
+} nr_dl_sched_algo_t;
+
 typedef void (*nr_pp_impl_dl)(module_id_t mod_id,
                               frame_t frame,
                               sub_frame_t slot);
@@ -638,6 +657,38 @@ typedef bool (*nr_pp_impl_ul)(module_id_t mod_id,
                               frame_t frame,
                               sub_frame_t slot);
 
+struct nr_slice_info_s;
+typedef struct {
+  int algorithm;
+
+  /// inform the slice algorithm about a new UE
+  void (*add_UE)(struct nr_slice_info_s *s, int UE_id);
+  /// inform the slice algorithm about a UE that disconnected
+  void (*remove_UE)(struct nr_slice_info_s *s, int UE_id);
+  /// move a UE to a slice in DL/UL, -1 means don't move (no-op).
+  void (*move_UE)(struct nr_slice_info_s *s, int UE_id, int idx);
+
+  /// Adds a new slice through admission control. slice_params are
+  /// algorithm-specific parameters. sched is either a default_sched_ul_algo_t
+  /// or default_sched_dl_algo_t, depending on whether this implementation
+  /// handles UL/DL. If slice at index exists, updates existing
+  /// slice. Returns index of new slice or -1 on failure.
+  int (*addmod_slice)(struct nr_slice_info_s *s,
+                      int id,
+                      char *label,
+                      void *sched,
+                      void *slice_params);
+  /// Returns slice through slice_idx. 1 if successful, 0 if not.
+  int (*remove_slice)(struct nr_slice_info_s *s, uint8_t slice_idx);
+
+  nr_pp_impl_dl dl;
+  nr_dl_sched_algo_t dl_algo;
+
+  void (*destroy)(struct nr_slice_info_s **s);
+
+  struct nr_slice_info_s *slices;
+} nr_pp_impl_param_dl_t;
+
 /*! \brief top level eNB MAC structure */
 typedef struct gNB_MAC_INST_s {
   /// Ethernet parameters for northbound midhaul interface
@@ -728,7 +779,8 @@ typedef struct gNB_MAC_INST_s {
   uint32_t ulsch_max_slots_inactivity;
 
   /// DL preprocessor for differentiated scheduling
-  nr_pp_impl_dl pre_processor_dl;
+  nr_pp_impl_param_dl_t pre_processor_dl;
+  pthread_mutex_t pp_mutex;
   /// UL preprocessor for differentiated scheduling
   nr_pp_impl_ul pre_processor_ul;
 
@@ -736,6 +788,9 @@ typedef struct gNB_MAC_INST_s {
   NR_CellGroupConfig_t *secondaryCellGroupCommon;
   NR_Type0_PDCCH_CSS_config_t type0_PDCCH_CSS_config[64];
 
+  int16_t frame;
+  int16_t slot;
+
 } gNB_MAC_INST;
 
 #endif /*__LAYER2_NR_MAC_GNB_H__ */
diff --git a/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.c b/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.c
new file mode 100644
index 0000000000..b7d5c121ce
--- /dev/null
+++ b/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.c
@@ -0,0 +1,483 @@
+/*
+ * Licensed to the OpenAirInterface (OAI) Software Alliance under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The OpenAirInterface Software Alliance licenses this file to You under
+ * the OAI Public License, Version 1.1  (the "License"); you may not use this file
+ * except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.openairinterface.org/?page_id=698
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *-------------------------------------------------------------------------------
+ * For more information about the OpenAirInterface (OAI) Software Alliance:
+ *      contact@openairinterface.org
+ */
+
+/*!
+ * \file   nr_slicing.c
+ * \brief  Generic NR Slicing helper functions and Static Slicing Implementation
+ * \author Robert Schmidt
+ * \date   2021
+ * \email  robert.schmidt@eurecom.fr
+ */
+
+#define _GNU_SOURCE
+#include <stdlib.h>
+#include <dlfcn.h>
+
+#include "assertions.h"
+#include "common/utils/LOG/log.h"
+
+#include "openair2/LAYER2/NR_MAC_gNB/mac_proto.h"
+
+#include "nr_slicing.h"
+#include "nr_slicing_internal.h"
+
+#include "common/ran_context.h"
+extern RAN_CONTEXT_t RC;
+
+#define RET_FAIL(ret, x...) do { LOG_E(MAC, x); return ret; } while (0)
+
+int nr_slicing_get_UE_slice_idx(nr_slice_info_t *si, int UE_id) {
+  return si->UE_assoc_slice[UE_id];
+}
+
+void nr_slicing_add_UE(nr_slice_info_t *si, int UE_id) {
+  add_tail_nr_list(&si->s[0]->UEs, UE_id);
+  si->UE_assoc_slice[UE_id] = 0;
+}
+
+void _nr_remove_UE(nr_slice_t **s, uint8_t *assoc, int UE_id) {
+  const uint8_t i = assoc[UE_id];
+  remove_nr_list(&s[i]->UEs, UE_id);
+  assoc[UE_id] = -1;
+}
+
+void nr_slicing_remove_UE(nr_slice_info_t *si, int UE_id) {
+  _nr_remove_UE(si->s, si->UE_assoc_slice, UE_id);
+}
+
+void _nr_move_UE(nr_slice_t **s, uint8_t *assoc, int UE_id, int to) {
+  const uint8_t i = assoc[UE_id];
+  remove_nr_list(&s[i]->UEs, UE_id);
+  add_tail_nr_list(&s[to]->UEs, UE_id);
+  assoc[UE_id] = to;
+}
+
+void nr_slicing_move_UE(nr_slice_info_t *si, int UE_id, int idx) {
+  DevAssert(idx >= -1 && idx < si->num);
+  if (idx >= 0)
+    _nr_move_UE(si->s, si->UE_assoc_slice, UE_id, idx);
+}
+
+int _nr_exists_slice(uint8_t n, nr_slice_t **s, int id) {
+  for (int i = 0; i < n; ++i)
+    if (s[i]->id == id)
+      return i;
+  return -1;
+}
+
+nr_slice_t *_nr_add_slice(uint8_t *n, nr_slice_t **s) {
+  s[*n] = calloc(1, sizeof(nr_slice_t));
+  if (!s[*n])
+    return NULL;
+  create_nr_list(&s[*n]->UEs, MAX_MOBILES_PER_GNB);
+  *n += 1;
+  return s[*n - 1];
+}
+
+nr_slice_t *_nr_remove_slice(uint8_t *n, nr_slice_t **s, uint8_t *assoc, int idx) {
+  if (idx >= *n)
+    return NULL;
+
+  nr_slice_t *sr = s[idx];
+  while (sr->UEs.head >= 0)
+    _nr_move_UE(s, assoc, sr->UEs.head, 0);
+
+  for (int i = idx + 1; i < *n; ++i)
+    s[i - 1] = s[i];
+  *n -= 1;
+  s[*n] = NULL;
+
+  for (int i = 0; i < MAX_MOBILES_PER_GNB; ++i)
+    if (assoc[i] > idx)
+      assoc[i] -= 1;
+
+  if (sr->label)
+    free(sr->label);
+
+  return sr;
+}
+
+
+/************************* NVS Slicing Implementation **************************/
+
+typedef struct {
+  float exp; // exponential weight. mov. avg for weight calc
+  int   rb;  // number of RBs this slice has been scheduled in last round
+  float eff; // effective rate for rate slices
+  float beta_eff; // averaging coeff so we average over roughly one second
+  int   active;   // activity state for rate slices
+} _nvs_int_t;
+
+int _nvs_nr_admission_control(const nr_slice_info_t *si,
+                              const nvs_nr_slice_param_t *p,
+                              int idx)
+{
+  if (p->type != NVS_RATE && p->type != NVS_RES)
+    RET_FAIL(-1, "%s(): invalid slice type %d\n", __func__, p->type);
+  if (p->type == NVS_RATE && p->Mbps_reserved > p->Mbps_reference)
+    RET_FAIL(-1,
+             "%s(): a rate slice cannot reserve more than the reference rate\n",
+             __func__);
+  if (p->type == NVS_RES && p->pct_reserved > 1.0f)
+    RET_FAIL(-1, "%s(): cannot reserve more than 1.0\n", __func__);
+  float sum_req = 0.0f;
+  for (int i = 0; i < si->num; ++i) {
+    const nvs_nr_slice_param_t *sp = i == idx ? p : si->s[i]->algo_data;
+    if (sp->type == NVS_RATE)
+      sum_req += sp->Mbps_reserved / sp->Mbps_reference;
+    else
+      sum_req += sp->pct_reserved;
+  }
+  if (idx < 0) { /* not an existing slice */
+    if (p->type == NVS_RATE)
+      sum_req += p->Mbps_reserved / p->Mbps_reference;
+    else
+      sum_req += p->pct_reserved;
+  }
+  if (sum_req > 1.0)
+    RET_FAIL(-3,
+             "%s(): admission control failed: sum of resources is %f > 1.0\n",
+             __func__, sum_req);
+  return 0;
+}
+
+int addmod_nvs_nr_slice_dl(nr_slice_info_t *si,
+                           int id,
+                           char *label,
+                           void *algo,
+                           void *slice_params_dl)
+{
+  nvs_nr_slice_param_t *dl = slice_params_dl;
+  int index = _nr_exists_slice(si->num, si->s, id);
+  if (index < 0 && si->num >= MAX_NVS_SLICES)
+    RET_FAIL(-2, "%s(): cannot handle more than %d slices\n", __func__, MAX_NVS_SLICES);
+
+  if (index < 0 && !dl)
+    RET_FAIL(-100, "%s(): no parameters for new slice %d, aborting\n", __func__, id);
+
+  if (dl) {
+    int rc = _nvs_nr_admission_control(si, dl, index);
+    if (rc < 0)
+      return rc;
+  }
+
+  nr_slice_t *s = NULL;
+  if (index >= 0) {
+    s = si->s[index];
+    if (label) {
+      if (s->label) free(s->label);
+      s->label = label;
+    }
+    if (algo && s->dl_algo.run != ((nr_dl_sched_algo_t*)algo)->run) {
+      s->dl_algo.unset(&s->dl_algo.data);
+      s->dl_algo = *(nr_dl_sched_algo_t*) algo;
+      if (!s->dl_algo.data)
+        s->dl_algo.data = s->dl_algo.setup();
+    }
+    if (dl) {
+      free(s->algo_data);
+      s->algo_data = dl;
+    } else { /* we have no parameters: we are done */
+      return index;
+    }
+  } else {
+    if (!algo)
+      RET_FAIL(-14, "%s(): no scheduler algorithm provided\n", __func__);
+
+    s = _nr_add_slice(&si->num, si->s);
+    if (!s)
+      RET_FAIL(-4, "%s(): cannot allocate memory for slice\n", __func__);
+    s->int_data = malloc(sizeof(_nvs_int_t));
+    if (!s->int_data)
+      RET_FAIL(-5, "%s(): cannot allocate memory for slice internal data\n", __func__);
+
+    s->id = id;
+    s->label = label;
+    s->dl_algo = *(nr_dl_sched_algo_t*) algo;
+    if (!s->dl_algo.data)
+      s->dl_algo.data = s->dl_algo.setup();
+    s->algo_data = dl;
+  }
+
+  _nvs_int_t *nvs_p = s->int_data;
+  /* reset all slice-internal parameters */
+  nvs_p->rb = 0;
+  nvs_p->active = 0;
+  if (dl->type == NVS_RATE) {
+    nvs_p->exp = dl->Mbps_reserved / dl->Mbps_reference;
+    nvs_p->eff = dl->Mbps_reference;
+  } else {
+    nvs_p->exp = dl->pct_reserved;
+    nvs_p->eff = 0; // not used
+  }
+  // scale beta so we (roughly) average the eff rate over 1s
+  nvs_p->beta_eff = BETA / nvs_p->exp;
+
+  return index < 0 ? si->num - 1 : index;
+}
+
+//int addmod_nvs_slice_ul(nr_slice_info_t *si,
+//                        int id,
+//                        char *label,
+//                        void *slice_params_ul) {
+//  nvs_nr_slice_param_t *sp = slice_params_ul;
+//  int index = _nr_exists_slice(si->num, si->s, id);
+//  if (index < 0 && si->num >= MAX_NVS_SLICES)
+//    RET_FAIL(-2, "%s(): cannot handle more than %d slices\n", __func__, MAX_NVS_SLICES);
+//
+//  int rc = _nvs_admission_control(si->num, si->s, sp, index);
+//  if (rc < 0)
+//    return rc;
+//
+//  nr_slice_t *ns = NULL;
+//  if (index < 0) {
+//    ns = _add_slice(&si->num, si->s);
+//    if (!ns)
+//      RET_FAIL(-4, "%s(): cannot allocate memory for slice\n", __func__);
+//    ns->id = id;
+//    ns->int_data = malloc(sizeof(_nvs_int_t));
+//    if (!ns->int_data)
+//      RET_FAIL(-5, "%s(): cannot allocate memory for slice internal data\n",
+//               __func__);
+//  } else {
+//    ns = si->s[index];
+//    free(ns->algo_data);
+//  }
+//  if (label) {
+//    if (ns->label)
+//      free(ns->label);
+//    ns->label = label;
+//  }
+//  ns->algo_data = sp;
+//  _nvs_int_t *nvs_p = ns->int_data;
+//  nvs_p->rb = 0;
+//  nvs_p->active = 0;
+//  if (sp->type == NVS_RATE) {
+//    nvs_p->exp = sp->Mbps_reserved;
+//    nvs_p->eff = sp->Mbps_reference;
+//  } else {
+//    nvs_p->exp = sp->pct_reserved;
+//    nvs_p->eff = 0; // not used
+//  }
+//
+//  return si->num - 1;
+//}
+
+int remove_nvs_nr_slice_dl(nr_slice_info_t *si, uint8_t slice_idx)
+{
+  if (slice_idx == 0)
+    return 0;
+  nr_slice_t *sr = _nr_remove_slice(&si->num, si->s, si->UE_assoc_slice, slice_idx);
+  if (!sr)
+    return 0;
+  free(sr->algo_data);
+  free(sr->int_data);
+  sr->dl_algo.unset(&sr->dl_algo.data);
+  free(sr);
+  return 1;
+}
+
+//int remove_nvs_slice_ul(nr_slice_info_t *si, uint8_t slice_idx) {
+//  if (slice_idx == 0)
+//    return 0;
+//  nr_slice_t *sr = _remove_slice(&si->num, si->s, si->UE_assoc_slice, slice_idx);
+//  if (!sr)
+//    return 0;
+//  free(sr->algo_data);
+//  free(sr->int_data);
+//  free(sr);
+//  return 1;
+//}
+
+extern void nr_store_dlsch_buffer(module_id_t, frame_t, sub_frame_t);
+
+void nvs_nr_dl(module_id_t mod_id,
+               frame_t frame,
+               sub_frame_t slot)
+{
+  gNB_MAC_INST *nrmac = RC.nrmac[mod_id];
+  NR_UE_info_t *UE_info = &nrmac->UE_info;
+  if (UE_info->num_UEs == 0) /* no UEs at all -> don't bother */
+    return;
+
+  /* check if we are supposed to schedule something */
+  NR_BWP_Downlink_t *active_bwp = UE_info->UE_sched_ctrl[UE_info->list.head].active_bwp;
+  const int tda = nrmac->preferred_dl_tda[active_bwp->bwp_Id][slot];
+  if (tda < 0)
+    return;
+  const uint16_t bwpSize = NRRIV2BW(active_bwp->bwp_Common->genericParameters.locationAndBandwidth, MAX_BWP_SIZE);
+
+  /* Retrieve amount of data to send */
+  nr_store_dlsch_buffer(mod_id, frame, slot);
+
+  nr_slice_info_t *si = RC.nrmac[mod_id]->pre_processor_dl.slices;
+  int bytes_last_round = 0;
+  for (int UE_id = UE_info->list.head; UE_id >= 0; UE_id = UE_info->list.next[UE_id]) {
+    const NR_UE_sched_ctrl_t *sched_ctrl = &UE_info->UE_sched_ctrl[UE_id];
+
+    bytes_last_round += UE_info->mac_stats[UE_id].dlsch_current_bytes;
+
+    const int idx = si->UE_assoc_slice[UE_id];
+    DevAssert(idx >= 0);
+
+    /* if UE has data or retransmission, mark respective slice as active */
+    const int retx_pid = sched_ctrl->retrans_dl_harq.head;
+    const bool active = sched_ctrl->num_total_bytes > 0 || retx_pid >= 0;
+    ((_nvs_int_t *)si->s[idx]->int_data)->active |= active;
+  }
+
+  const int CC_id = 0;
+  uint16_t *vrb_map = nrmac->common_channels[CC_id].vrb_map;
+  uint8_t rballoc_mask[bwpSize];
+  int n_rb_sched = 0;
+  for (int i = 0; i < bwpSize; i++) {
+    // calculate mask: init with "NOT" vrb_map:
+    // if any RB in vrb_map is blocked (1), the current RBG will be 0
+    rballoc_mask[i] = !vrb_map[i];
+    n_rb_sched += rballoc_mask[i];
+  }
+
+  float maxw = 0.0f;
+  int maxidx = -1;
+  for (int i = 0; i < si->num; ++i) {
+    nr_slice_t *s = si->s[i];
+    nvs_nr_slice_param_t *p = s->algo_data;
+    _nvs_int_t *ip = s->int_data;
+
+    float w = 0.0f;
+    if (p->type == NVS_RATE) {
+      /* if this slice has been marked as inactive, disable to prevent that
+       * it's exp rate is uselessly driven down */
+      if (!ip->active)
+        continue;
+      float inst = 0.0f;
+      if (ip->rb > 0) { /* it was scheduled last round */
+        /* inst rate: B in last round * 8(bit) / 1000000 (Mbps) * 1000 (1ms) */
+        inst = (float) bytes_last_round * 8 / 1000;
+        ip->eff = (1.0f - ip->beta_eff) * ip->eff + ip->beta_eff * inst;
+        //LOG_W(nrMAC, "i %d slice %d ip->rb %d inst %f ip->eff %f\n", i, s->id, ip->rb, inst, ip->eff);
+        ip->rb = 0;
+      }
+      ip->exp = (1 - BETA) * ip->exp + BETA * inst;
+      const float rsv = p->Mbps_reserved * min(1.0f, ip->eff / p->Mbps_reference);
+      w = rsv / ip->exp;
+    } else {
+      float inst = (float)ip->rb / bwpSize;
+      ip->exp = (1.0f - BETA) * ip->exp + BETA * inst;
+      w = p->pct_reserved / ip->exp;
+    }
+    //LOG_I(MAC, "i %d slice %d type %d ip->exp %f w %f\n", i, s->id, p->type, ip->exp, w);
+    ip->rb = 0;
+    if (w > maxw + 0.001f) {
+      maxw = w;
+      maxidx = i;
+    }
+  }
+
+  if (maxidx < 0)
+    return;
+
+  ((_nvs_int_t *)si->s[maxidx]->int_data)->rb = n_rb_sched;
+
+  //int rbg_rem = n_rb_sched;
+  if (si->s[maxidx]->UEs.head >= 0) {
+    /*rbg_rem = */
+    //LOG_I(MAC, "%4d.%2d scheduling slice idx %d ID %d (first UE %d)\n", frame, slot, maxidx, si->s[maxidx]->id, si->s[maxidx]->UEs.head);
+    si->s[maxidx]->dl_algo.run(mod_id,
+                               frame,
+                               slot,
+                               &si->s[maxidx]->UEs,
+                               2, // max_num_ue
+                               n_rb_sched,
+                               rballoc_mask,
+                               si->s[maxidx]->dl_algo.data);
+  } else {
+    //LOG_I(MAC, "%4d.%2d not scheduling slice idx %d ID %d (no UEs)\n", frame, slot, maxidx, si->s[maxidx]->id);
+  }
+  // TODO
+  //if (rbg_rem == n_rbg_sched) // if no RBGs have been used mark as inactive
+  //  ((_nvs_int_t *)si->s[maxidx]->int_data)->active = 0;
+}
+
+/*
+void nvs_ul(module_id_t mod_id,
+               int CC_id,
+               frame_t frame,
+               sub_frame_t subframe,
+               frame_t sched_frame,
+               sub_frame_t sched_subframe) {
+  ulsch_scheduler_pre_processor(mod_id, CC_id, frame, subframe, sched_frame, sched_subframe);
+}
+*/
+
+void nvs_nr_destroy(nr_slice_info_t **si) {
+  const int n_dl = (*si)->num;
+  (*si)->num = 0;
+  for (int i = 0; i < n_dl; ++i) {
+    nr_slice_t *s = (*si)->s[i];
+    if (s->label)
+      free(s->label);
+    free(s->algo_data);
+    free(s->int_data);
+    free(s);
+  }
+  free((*si)->s);
+}
+
+nr_pp_impl_param_dl_t nvs_nr_dl_init(module_id_t mod_id, int CC_id)
+{
+  nr_slice_info_t *si = calloc(1, sizeof(nr_slice_info_t));
+  DevAssert(si);
+
+  si->num = 0;
+  si->s = calloc(MAX_NVS_SLICES, sizeof(nr_slice_t));
+  DevAssert(si->s);
+  for (int i = 0; i < MAX_MOBILES_PER_GNB; ++i)
+    si->UE_assoc_slice[i] = -1;
+
+  /* insert default slice, all resources */
+  nvs_nr_slice_param_t *dlp = malloc(sizeof(nvs_nr_slice_param_t));
+  DevAssert(dlp);
+  dlp->type = NVS_RES;
+  dlp->pct_reserved = 1.0f;
+  nr_dl_sched_algo_t *algo = &RC.nrmac[mod_id]->pre_processor_dl.dl_algo;
+  algo->data = NULL;
+  const int rc = addmod_nvs_nr_slice_dl(si, 0, strdup("default"), algo, dlp);
+  DevAssert(0 == rc);
+  const NR_list_t *UE_list = &RC.nrmac[mod_id]->UE_info.list;
+  for (int UE_id = UE_list->head; UE_id >= 0; UE_id = UE_list->next[UE_id])
+    nr_slicing_add_UE(si, UE_id);
+
+  nr_pp_impl_param_dl_t nvs;
+  nvs.algorithm = NVS_SLICING;
+  nvs.add_UE = nr_slicing_add_UE;
+  nvs.remove_UE = nr_slicing_remove_UE;
+  nvs.move_UE = nr_slicing_move_UE;
+  nvs.addmod_slice = addmod_nvs_nr_slice_dl;
+  nvs.remove_slice = remove_nvs_nr_slice_dl;
+  nvs.dl = nvs_nr_dl;
+  // current DL algo becomes default scheduler
+  nvs.dl_algo = *algo;
+  nvs.destroy = nvs_nr_destroy;
+  nvs.slices = si;
+
+  return nvs;
+}
diff --git a/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.h b/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.h
new file mode 100644
index 0000000000..f7f3defc97
--- /dev/null
+++ b/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing.h
@@ -0,0 +1,74 @@
+/*
+ * Licensed to the OpenAirInterface (OAI) Software Alliance under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The OpenAirInterface Software Alliance licenses this file to You under
+ * the OAI Public License, Version 1.1  (the "License"); you may not use this file
+ * except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.openairinterface.org/?page_id=698
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *-------------------------------------------------------------------------------
+ * For more information about the OpenAirInterface (OAI) Software Alliance:
+ *      contact@openairinterface.org
+ */
+
+/*!
+ * \file   nr_slicing.h
+ * \brief  General NR slice definition and helper parameters
+ * \author Robert Schmidt
+ * \date   2021
+ * \email  robert.schmidt@eurecom.fr
+ */
+
+#ifndef NR_SLICING_H__
+#define NR_SLICING_H__
+
+#include "openair2/LAYER2/NR_MAC_gNB/nr_mac_gNB.h"
+
+typedef struct nr_slice_s {
+  /// Arbitrary ID
+  slice_id_t id;
+  /// Arbitrary label
+  char *label;
+
+  nr_dl_sched_algo_t dl_algo;
+
+  /// A specific algorithm's implementation parameters
+  void *algo_data;
+  /// Internal data that might be kept alongside a slice's params
+  void *int_data;
+
+  // list of users in this slice
+  NR_list_t UEs;
+} nr_slice_t;
+
+typedef struct nr_slice_info_s {
+  uint8_t num;
+  nr_slice_t **s;
+  uint8_t UE_assoc_slice[MAX_MOBILES_PER_ENB];
+} nr_slice_info_t;
+
+int nr_slicing_get_UE_slice_idx(nr_slice_info_t *si, int UE_id);
+
+#define NVS_SLICING 20
+/* arbitrary upper limit, increase if you want to instantiate more slices */
+#define MAX_NVS_SLICES 10
+/* window for slice weight averaging -> 1s for fine granularity */
+#define BETA 0.001f
+typedef struct {
+  enum nvs_type {NVS_RATE, NVS_RES} type;
+  union {
+    struct { float Mbps_reserved; float Mbps_reference; };
+    struct { float pct_reserved; };
+  };
+} nvs_nr_slice_param_t;
+nr_pp_impl_param_dl_t nvs_nr_dl_init(module_id_t mod_id, int CC_id);
+
+#endif /* NR_SLICING_H__ */
diff --git a/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing_internal.h b/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing_internal.h
new file mode 100644
index 0000000000..9ecc8da1b8
--- /dev/null
+++ b/openair2/LAYER2/NR_MAC_gNB/slicing/nr_slicing_internal.h
@@ -0,0 +1,46 @@
+/*
+ * Licensed to the OpenAirInterface (OAI) Software Alliance under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The OpenAirInterface Software Alliance licenses this file to You under
+ * the OAI Public License, Version 1.1  (the "License"); you may not use this file
+ * except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.openairinterface.org/?page_id=698
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *-------------------------------------------------------------------------------
+ * For more information about the OpenAirInterface (OAI) Software Alliance:
+ *      contact@openairinterface.org
+ */
+
+/*!
+ * \file   nr_slicing_internal.h
+ * \brief  Internal NR slice helper functions
+ * \author Robert Schmidt
+ * \date   2021
+ * \email  robert.schmidt@eurecom.fr
+ */
+
+#ifndef NR_SLICING_INTERNAL_H__
+#define NR_SLICING_INTERNAL_H__
+
+#include "nr_slicing.h"
+
+void nr_slicing_add_UE(nr_slice_info_t *si, int UE_id);
+
+void _nr_remove_UE(nr_slice_t **s, uint8_t *assoc, int UE_id);
+void nr_slicing_remove_UE(nr_slice_info_t *si, int UE_id);
+
+void _nr_move_UE(nr_slice_t **s, uint8_t *assoc, int UE_id, int to);
+void nr_slicing_move_UE(nr_slice_info_t *si, int UE_id, int idx);
+
+nr_slice_t *_nr_add_slice(uint8_t *n, nr_slice_t **s);
+nr_slice_t *_nr_remove_slice(uint8_t *n, nr_slice_t **s, uint8_t *assoc, int idx);
+
+#endif /* NR_SLICING_INTERNAL_H__ */
diff --git a/openair2/LAYER2/PDCP_v10.1.0/pdcp.c b/openair2/LAYER2/PDCP_v10.1.0/pdcp.c
index 51d3cfc8f3..f725db5c63 100644
--- a/openair2/LAYER2/PDCP_v10.1.0/pdcp.c
+++ b/openair2/LAYER2/PDCP_v10.1.0/pdcp.c
@@ -554,6 +554,7 @@ boolean_t pdcp_data_req(
   }
 
   LOG_D(PDCP,"ueid %d lcid %d tx seq num %d\n", pdcp_uid, (int)(rb_idP+rb_offset), current_sn);
+  pdcp_enb[ctxt_pP->module_id].uid_tx[pdcp_uid]=1;
   Pdcp_stats_tx[ctxt_pP->module_id][pdcp_uid][rb_idP+rb_offset]++;
   Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_idP+rb_offset]++;
   Pdcp_stats_tx_bytes[ctxt_pP->module_id][pdcp_uid][rb_idP+rb_offset]+=sdu_buffer_sizeP;
@@ -1116,6 +1117,7 @@ pdcp_data_ind(
     }
   }
 
+  pdcp_enb[ctxt_pP->module_id].uid_rx[pdcp_uid]=1;
   Pdcp_stats_rx[ctxt_pP->module_id][pdcp_uid][rb_idP+rb_offset]++;
   Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_idP+rb_offset]++;
   Pdcp_stats_rx_bytes[ctxt_pP->module_id][pdcp_uid][rb_idP+rb_offset]+=(sdu_buffer_sizeP  - payload_offset);
@@ -1140,48 +1142,61 @@ pdcp_data_ind(
 void pdcp_update_stats(const protocol_ctxt_t *const  ctxt_pP) {
   uint16_t           pdcp_uid = 0;
   uint8_t            rb_id     = 0;
-
-  // these stats are measured for both eNB and UE on per seond basis
-  for (rb_id =0; rb_id < NB_RB_MAX; rb_id ++) {
-    for (pdcp_uid=0; pdcp_uid< MAX_MOBILES_PER_ENB; pdcp_uid++) {
-      //printf("frame %d and subframe %d \n", pdcp_enb[ctxt_pP->module_id].frame, pdcp_enb[ctxt_pP->module_id].subframe);
-      // tx stats
-      if (Pdcp_stats_tx_window_ms[ctxt_pP->module_id][pdcp_uid] > 0 &&
-          pdcp_enb[ctxt_pP->module_id].sfn % Pdcp_stats_tx_window_ms[ctxt_pP->module_id][pdcp_uid] == 0) {
-        // unit: bit/s
-        Pdcp_stats_tx_throughput_w[ctxt_pP->module_id][pdcp_uid][rb_id]=Pdcp_stats_tx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]*8;
-        Pdcp_stats_tx_w[ctxt_pP->module_id][pdcp_uid][rb_id]= Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id];
-        Pdcp_stats_tx_bytes_w[ctxt_pP->module_id][pdcp_uid][rb_id]= Pdcp_stats_tx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id];
-
-        if (Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id] > 0) {
-          Pdcp_stats_tx_aiat_w[ctxt_pP->module_id][pdcp_uid][rb_id]=(Pdcp_stats_tx_aiat_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]/Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]);
-        } else {
-          Pdcp_stats_tx_aiat_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
-        }
-
-        // reset the tmp vars
-        Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
-        Pdcp_stats_tx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
-        Pdcp_stats_tx_aiat_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
+  
+  // these stats are measured for both eNB and UE on per seond basis 
+  for (pdcp_uid=0; pdcp_uid< pdcp_enb[ctxt_pP->module_id].num_ues; pdcp_uid++) {
+    if (pdcp_enb[ctxt_pP->module_id].rnti[pdcp_uid] <= 0) 
+      continue;
+    
+    for (rb_id =0; rb_id < NB_RB_MAX; rb_id ++) {
+      if (pdcp_enb[ctxt_pP->module_id].rb_id[pdcp_uid][rb_id] <= 0) 
+	continue;
+      
+      
+      if (pdcp_enb[ctxt_pP->module_id].uid_tx[pdcp_uid] &&
+	  Pdcp_stats_tx_window_ms[ctxt_pP->module_id][pdcp_uid] > 0 &&
+	  pdcp_enb[ctxt_pP->module_id].sfn % Pdcp_stats_tx_window_ms[ctxt_pP->module_id][pdcp_uid] == 0) {
+
+	pdcp_enb[ctxt_pP->module_id].uid_tx[pdcp_uid]=0;
+	
+	// tx stats unit: bit/s
+	Pdcp_stats_tx_throughput_w[ctxt_pP->module_id][pdcp_uid][rb_id]=Pdcp_stats_tx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]*8;
+	Pdcp_stats_tx_w[ctxt_pP->module_id][pdcp_uid][rb_id]= Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id];
+	Pdcp_stats_tx_bytes_w[ctxt_pP->module_id][pdcp_uid][rb_id]= Pdcp_stats_tx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id];
+	
+	if (Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id] > 0) {
+	  Pdcp_stats_tx_aiat_w[ctxt_pP->module_id][pdcp_uid][rb_id]=(Pdcp_stats_tx_aiat_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]/Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]);
+	} else {
+	  Pdcp_stats_tx_aiat_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
+	}
+	
+	// reset the tmp vars
+	Pdcp_stats_tx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
+	Pdcp_stats_tx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
+	Pdcp_stats_tx_aiat_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
       }
-
-      if (Pdcp_stats_rx_window_ms[ctxt_pP->module_id][pdcp_uid] > 0 &&
-          pdcp_enb[ctxt_pP->module_id].sfn % Pdcp_stats_rx_window_ms[ctxt_pP->module_id][pdcp_uid] == 0) {
-        // rx stats
-        Pdcp_stats_rx_goodput_w[ctxt_pP->module_id][pdcp_uid][rb_id]=Pdcp_stats_rx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]*8;
-        Pdcp_stats_rx_w[ctxt_pP->module_id][pdcp_uid][rb_id]=   Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id];
-        Pdcp_stats_rx_bytes_w[ctxt_pP->module_id][pdcp_uid][rb_id]= Pdcp_stats_rx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id];
-
-        if(Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id] > 0) {
-          Pdcp_stats_rx_aiat_w[ctxt_pP->module_id][pdcp_uid][rb_id]= (Pdcp_stats_rx_aiat_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]/Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]);
-        } else {
-          Pdcp_stats_rx_aiat_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
-        }
-
-        // reset the tmp vars
-        Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
-        Pdcp_stats_rx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
-        Pdcp_stats_rx_aiat_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
+      
+      if (pdcp_enb[ctxt_pP->module_id].uid_rx[pdcp_uid]   &&
+	  Pdcp_stats_rx_window_ms[ctxt_pP->module_id][pdcp_uid] > 0 &&
+	  pdcp_enb[ctxt_pP->module_id].sfn % Pdcp_stats_rx_window_ms[ctxt_pP->module_id][pdcp_uid] == 0) {
+
+	pdcp_enb[ctxt_pP->module_id].uid_rx[pdcp_uid]=0;
+	
+	// rx stats
+	Pdcp_stats_rx_goodput_w[ctxt_pP->module_id][pdcp_uid][rb_id]=Pdcp_stats_rx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]*8;
+	Pdcp_stats_rx_w[ctxt_pP->module_id][pdcp_uid][rb_id]=   Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id];
+	Pdcp_stats_rx_bytes_w[ctxt_pP->module_id][pdcp_uid][rb_id]= Pdcp_stats_rx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id];
+	
+	if(Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id] > 0) {
+	  Pdcp_stats_rx_aiat_w[ctxt_pP->module_id][pdcp_uid][rb_id]= (Pdcp_stats_rx_aiat_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]/Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]);
+	} else {
+	  Pdcp_stats_rx_aiat_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
+	}
+	
+	// reset the tmp vars
+	Pdcp_stats_rx_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
+	Pdcp_stats_rx_bytes_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
+	Pdcp_stats_rx_aiat_tmp_w[ctxt_pP->module_id][pdcp_uid][rb_id]=0;
       }
     }
   }
@@ -1200,11 +1215,13 @@ pdcp_run (
   } else {
     start_meas(&UE_pdcp_stats[ctxt_pP->module_id].pdcp_run);
   }
-
-  pdcp_enb[ctxt_pP->module_id].sfn++; // range: 0 to 18,446,744,073,709,551,615
-  pdcp_enb[ctxt_pP->module_id].frame=ctxt_pP->frame; // 1023
-  pdcp_enb[ctxt_pP->module_id].subframe= ctxt_pP->subframe;
-  pdcp_update_stats(ctxt_pP);
+  
+  if (ctxt_pP->enb_flag) {
+    pdcp_enb[ctxt_pP->module_id].sfn++; // range: 0 to 18,446,744,073,709,551,615
+    pdcp_enb[ctxt_pP->module_id].frame=ctxt_pP->frame; // 1023
+    pdcp_enb[ctxt_pP->module_id].subframe= ctxt_pP->subframe;
+    pdcp_update_stats(ctxt_pP);
+  }
   VCD_SIGNAL_DUMPER_DUMP_FUNCTION_BY_NAME(VCD_SIGNAL_DUMPER_FUNCTIONS_PDCP_RUN, VCD_FUNCTION_IN);
   MessageDef   *msg_p;
   int           result;
@@ -1469,7 +1486,7 @@ void pdcp_init_stats_UE(module_id_t mod, uint16_t uid) {
   }
 }
 
-void pdcp_add_UE(const protocol_ctxt_t *const  ctxt_pP) {
+void pdcp_add_UE(const protocol_ctxt_t *const  ctxt_pP,  const rb_id_t rb_idP) {
   int i, ue_flag=1; //, ret=-1; to be decied later
 
   for (i=0; i < MAX_MOBILES_PER_ENB; i++) {
@@ -1478,12 +1495,13 @@ void pdcp_add_UE(const protocol_ctxt_t *const  ctxt_pP) {
       break;
     }
   }
-
+  // need to add rb_id
   if (ue_flag == 1 ) {
     for (i=0; i < MAX_MOBILES_PER_ENB ; i++) {
       if (pdcp_enb[ctxt_pP->module_id].rnti[i] == 0 ) {
         pdcp_enb[ctxt_pP->module_id].rnti[i]=ctxt_pP->rnti;
         pdcp_enb[ctxt_pP->module_id].uid[i]=i;
+	pdcp_enb[ctxt_pP->module_id].rb_id[i][rb_idP]=1; // this RB is active
         pdcp_enb[ctxt_pP->module_id].num_ues++;
         printf("add new uid is %d %x\n\n", i, ctxt_pP->rnti);
         pdcp_init_stats_UE(ctxt_pP->module_id, i);
@@ -1855,6 +1873,7 @@ rrc_pdcp_config_asn1_req (
         kRRCenc_pP,
         kRRCint_pP,
         kUPenc_pP);
+      
       h_rc = hashtable_remove(pdcp_coll_p, key);
 
       if ((defaultDRB != NULL) && (*defaultDRB == drb_id)) {
@@ -1964,7 +1983,7 @@ pdcp_config_req_asn1 (
 
       if (ctxt_pP->enb_flag == ENB_FLAG_YES) {
         pdcp_pP->is_ue = FALSE;
-        pdcp_add_UE(ctxt_pP);
+        pdcp_add_UE(ctxt_pP, rb_idP);
 
         //pdcp_eNB_UE_instance_to_rnti[ctxtP->module_id] = ctxt_pP->rnti;
         //      pdcp_eNB_UE_instance_to_rnti[pdcp_eNB_UE_instance_to_rnti_index] = ctxt_pP->rnti;
diff --git a/openair2/LAYER2/PDCP_v10.1.0/pdcp.h b/openair2/LAYER2/PDCP_v10.1.0/pdcp.h
index 0c3dd2f04f..4e9e75c825 100644
--- a/openair2/LAYER2/PDCP_v10.1.0/pdcp.h
+++ b/openair2/LAYER2/PDCP_v10.1.0/pdcp.h
@@ -129,7 +129,15 @@ void pdcp_update_perioidical_stats(const protocol_ctxt_t *const  ctxt_pP);
 typedef struct pdcp_enb_s {
   // used for eNB stats generation
   uint16_t uid[MAX_MOBILES_PER_ENB];
+  // flag indicating if UE sends packets 
+  uint16_t uid_tx[MAX_MOBILES_PER_ENB];
+  // flag indicating if UE receives packets
+  uint16_t uid_rx[MAX_MOBILES_PER_ENB];
+  // UE RNTI 
   rnti_t rnti[MAX_MOBILES_PER_ENB];
+  // UE active RABs
+  rb_id_t  rb_id[MAX_MOBILES_PER_ENB][NB_RB_MAX];
+  
   uint16_t num_ues;
 
   uint64_t sfn;
@@ -363,7 +371,7 @@ boolean_t pdcp_config_req_asn1 (
 * \param[in]  ctxt_pP           Running context.
 * \return     A status about the processing, OK or error code.
 */
-void pdcp_add_UE(const protocol_ctxt_t *const  ctxt_pP);
+void pdcp_add_UE(const protocol_ctxt_t *const  ctxt_pP, const rb_id_t rb_idP);
 
 /*! \fn boolean_t pdcp_remove_UE(const protocol_ctxt_t* const  ctxt_pP)
 * \brief  Function for RRC to remove UE from PDCP module hashtable
diff --git a/openair2/LAYER2/nr_pdcp/nr_pdcp_entity.c b/openair2/LAYER2/nr_pdcp/nr_pdcp_entity.c
index 1822239171..3d6fb94ea0 100644
--- a/openair2/LAYER2/nr_pdcp/nr_pdcp_entity.c
+++ b/openair2/LAYER2/nr_pdcp/nr_pdcp_entity.c
@@ -54,6 +54,9 @@ static void nr_pdcp_entity_recv_pdu(nr_pdcp_entity_t *entity,
     exit(1);
   }
 
+  entity->stats.rxpdu_pkts++;
+  entity->stats.rxpdu_bytes += size;
+
   if (entity->sn_size == 12) {
     rcvd_sn = ((buffer[0] & 0xf) <<  8) |
                 buffer[1];
@@ -65,6 +68,8 @@ static void nr_pdcp_entity_recv_pdu(nr_pdcp_entity_t *entity,
     header_size = 3;
   }
 
+  entity->stats.rxpdu_sn = rcvd_sn;
+
   if (entity->has_integrity) {
     integrity_size = 4;
   } else {
@@ -73,6 +78,10 @@ static void nr_pdcp_entity_recv_pdu(nr_pdcp_entity_t *entity,
 
   if (size < header_size + integrity_size + 1) {
     LOG_E(PDCP, "bad PDU received (size = %d)\n", size);
+
+    entity->stats.rxpdu_dd_pkts++;
+    entity->stats.rxpdu_dd_bytes += size;
+
     return;
   }
 
@@ -101,6 +110,10 @@ static void nr_pdcp_entity_recv_pdu(nr_pdcp_entity_t *entity,
                       entity->rb_id, rcvd_count, entity->is_gnb ? 0 : 1);
     if (memcmp(integrity, buffer, 4) != 0) {
       LOG_E(PDCP, "discard NR PDU, integrity failed\n");
+
+      entity->stats.rxpdu_dd_pkts++;
+      entity->stats.rxpdu_dd_bytes += size;
+
       return;
     }
   }
@@ -108,6 +121,10 @@ static void nr_pdcp_entity_recv_pdu(nr_pdcp_entity_t *entity,
   if (rcvd_count < entity->rx_deliv
       || nr_pdcp_sdu_in_list(entity->rx_list, rcvd_count)) {
     LOG_D(PDCP, "discard NR PDU rcvd_count=%d\n", rcvd_count);
+
+    entity->stats.rxpdu_dd_pkts++;
+    entity->stats.rxpdu_dd_bytes += size;
+
     return;
   }
 
@@ -132,8 +149,13 @@ static void nr_pdcp_entity_recv_pdu(nr_pdcp_entity_t *entity,
                           cur->buffer, cur->size);
       entity->rx_list = cur->next;
       entity->rx_size -= cur->size;
+
+      entity->stats.txsdu_pkts++;
+      entity->stats.txsdu_bytes += cur->size;
+
       nr_pdcp_free_sdu(cur);
       count++;
+
     }
     entity->rx_deliv = count;
   }
@@ -159,6 +181,9 @@ static void nr_pdcp_entity_recv_sdu(nr_pdcp_entity_t *entity,
   char     buf[size + 3 + 4];
   int      dc_bit;
 
+  entity->stats.rxsdu_pkts++;
+  entity->stats.rxsdu_bytes += size;
+
   count = entity->tx_next;
   sn = entity->tx_next & entity->sn_max;
 
@@ -203,6 +228,10 @@ static void nr_pdcp_entity_recv_sdu(nr_pdcp_entity_t *entity,
 
   entity->deliver_pdu(entity->deliver_pdu_data, entity, buf,
                       header_size + size + integrity_size, sdu_id);
+
+  entity->stats.txpdu_pkts++;
+  entity->stats.txpdu_bytes += header_size + size + integrity_size;
+  entity->stats.txpdu_sn = sn;
 }
 
 static void nr_pdcp_entity_set_integrity_key(nr_pdcp_entity_t *entity,
@@ -276,6 +305,12 @@ void nr_pdcp_entity_delete(nr_pdcp_entity_t *entity)
   free(entity);
 }
 
+static void nr_pdcp_entity_get_stats(nr_pdcp_entity_t *entity,
+                                     nr_pdcp_statistics_t *out)
+{
+  *out = entity->stats;
+}
+
 nr_pdcp_entity_t *new_nr_pdcp_entity(
     nr_pdcp_entity_type_t type,
     int is_gnb, int rb_id,
@@ -310,6 +345,8 @@ nr_pdcp_entity_t *new_nr_pdcp_entity(
 
   ret->delete = nr_pdcp_entity_delete;
 
+  ret->get_stats = nr_pdcp_entity_get_stats;
+
   ret->deliver_sdu = deliver_sdu;
   ret->deliver_sdu_data = deliver_sdu_data;
 
diff --git a/openair2/LAYER2/nr_pdcp/nr_pdcp_entity.h b/openair2/LAYER2/nr_pdcp/nr_pdcp_entity.h
index 4ae7a45abb..40e9c9098a 100644
--- a/openair2/LAYER2/nr_pdcp/nr_pdcp_entity.h
+++ b/openair2/LAYER2/nr_pdcp/nr_pdcp_entity.h
@@ -32,6 +32,35 @@ typedef enum {
   NR_PDCP_SRB
 } nr_pdcp_entity_type_t;
 
+typedef struct {
+  nr_pdcp_entity_type_t mode;
+
+  /* PDU stats */
+  /* TX */
+  int      txpdu_pkts;     /* aggregated number of tx packets */
+  uint64_t txpdu_bytes;    /* aggregated bytes of tx packets */
+  int      txpdu_sn;       /* current sequence number of last tx packet (or TX_NEXT) */
+
+  /* RX */
+  int      rxpdu_pkts;     /* aggregated number of rx packets */
+  uint64_t rxpdu_bytes;    /* aggregated bytes of rx packets */
+  int      rxpdu_sn;       /* current sequence number of last rx packet (or  RX_NEXT) */
+  /* TODO? */ int rxpdu_oo_pkts;       /* aggregated number of out-of-order rx pkts  (or RX_REORD) */
+  /* TODO? */ uint64_t rxpdu_oo_bytes; /* aggregated amount of out-of-order rx bytes */
+  int      rxpdu_dd_pkts;  /* aggregated number of duplicated discarded packets (or dropped packets because of other reasons such as integrity failure) (or RX_DELIV) */
+  uint64_t rxpdu_dd_bytes; /* aggregated amount of discarded packets' bytes */
+  /* TODO? */ int      rxpdu_ro_count; /* this state variable indicates the COUNT value following the COUNT value associated with the PDCP Data PDU which triggered t-Reordering. (RX_REORD) */
+
+  /* SDU stats */
+  /* TX */
+  int      txsdu_pkts;     /* number of SDUs delivered */
+  uint64_t txsdu_bytes;    /* number of bytes of SDUs delivered */
+
+  /* RX */
+  int      rxsdu_pkts;     /* number of SDUs received */
+  uint64_t rxsdu_bytes;    /* number of bytes of SDUs received */
+} nr_pdcp_statistics_t;
+
 typedef struct nr_pdcp_entity_t {
   nr_pdcp_entity_type_t type;
 
@@ -40,6 +69,7 @@ typedef struct nr_pdcp_entity_t {
   void (*recv_sdu)(struct nr_pdcp_entity_t *entity, char *buffer, int size,
                    int sdu_id);
   void (*delete)(struct nr_pdcp_entity_t *entity);
+  void (*get_stats)(struct nr_pdcp_entity_t *entity, nr_pdcp_statistics_t *out);
   void (*set_integrity_key)(struct nr_pdcp_entity_t *entity, char *key);
   void (*set_time)(struct nr_pdcp_entity_t *entity, uint64_t now);
 
@@ -100,6 +130,8 @@ typedef struct nr_pdcp_entity_t {
   nr_pdcp_sdu_t *rx_list;
   int           rx_size;
   int           rx_maxsize;
+
+  nr_pdcp_statistics_t stats;
 } nr_pdcp_entity_t;
 
 nr_pdcp_entity_t *new_nr_pdcp_entity(
diff --git a/openair2/LAYER2/nr_pdcp/nr_pdcp_oai_api.c b/openair2/LAYER2/nr_pdcp/nr_pdcp_oai_api.c
index 39b770508e..b1e70ddd4d 100644
--- a/openair2/LAYER2/nr_pdcp/nr_pdcp_oai_api.c
+++ b/openair2/LAYER2/nr_pdcp/nr_pdcp_oai_api.c
@@ -998,3 +998,41 @@ void nr_pdcp_tick(int frame, int subframe)
     nr_pdcp_wakeup_timer_thread(nr_pdcp_current_time);
   }
 }
+
+/* returns 0 in case of error, 1 if everything ok */
+int nr_pdcp_get_statistics(
+  int rnti,
+  int srb_flag,
+  int rb_id,
+  nr_pdcp_statistics_t *out)
+{
+  nr_pdcp_ue_t     *ue;
+  nr_pdcp_entity_t *rb;
+  int              ret;
+
+  nr_pdcp_manager_lock(nr_pdcp_ue_manager);
+  ue = nr_pdcp_manager_get_ue(nr_pdcp_ue_manager, rnti);
+
+  if (srb_flag == 1) {
+    if (rb_id < 1 || rb_id > 2)
+      rb = NULL;
+    else
+      rb = ue->srb[rb_id - 1];
+  } else {
+    if (rb_id < 1 || rb_id > 5)
+      rb = NULL;
+    else
+      rb = ue->drb[rb_id - 1];
+  }
+
+  if (rb != NULL) {
+    rb->get_stats(rb, out);
+    ret = 1;
+  } else {
+    ret = 0;
+  }
+
+  nr_pdcp_manager_unlock(nr_pdcp_ue_manager);
+
+  return ret;
+}
diff --git a/openair2/LAYER2/nr_rlc/nr_rlc_entity.c b/openair2/LAYER2/nr_rlc/nr_rlc_entity.c
index fefe2fc77d..d9d435fec3 100644
--- a/openair2/LAYER2/nr_rlc/nr_rlc_entity.c
+++ b/openair2/LAYER2/nr_rlc/nr_rlc_entity.c
@@ -29,6 +29,13 @@
 
 #include "LOG/log.h"
 
+static void nr_rlc_entity_get_stats(
+    nr_rlc_entity_t *entity,
+    nr_rlc_statistics_t *out)
+{
+  *out = entity->stats;
+}
+
 nr_rlc_entity_t *new_nr_rlc_entity_am(
     int rx_maxsize,
     int tx_maxsize,
@@ -85,6 +92,7 @@ nr_rlc_entity_t *new_nr_rlc_entity_am(
   ret->common.discard_sdu     = nr_rlc_entity_am_discard_sdu;
   ret->common.reestablishment = nr_rlc_entity_am_reestablishment;
   ret->common.delete          = nr_rlc_entity_am_delete;
+  ret->common.get_stats       = nr_rlc_entity_get_stats;
 
   ret->common.deliver_sdu                  = deliver_sdu;
   ret->common.deliver_sdu_data             = deliver_sdu_data;
@@ -93,6 +101,8 @@ nr_rlc_entity_t *new_nr_rlc_entity_am(
   ret->common.max_retx_reached             = max_retx_reached;
   ret->common.max_retx_reached_data        = max_retx_reached_data;
 
+  ret->common.stats.mode = 0;  /* 0 for AM */
+
   return (nr_rlc_entity_t *)ret;
 }
 
@@ -135,10 +145,13 @@ nr_rlc_entity_t *new_nr_rlc_entity_um(
   ret->common.discard_sdu     = nr_rlc_entity_um_discard_sdu;
   ret->common.reestablishment = nr_rlc_entity_um_reestablishment;
   ret->common.delete          = nr_rlc_entity_um_delete;
+  ret->common.get_stats       = nr_rlc_entity_get_stats;
 
   ret->common.deliver_sdu                  = deliver_sdu;
   ret->common.deliver_sdu_data             = deliver_sdu_data;
 
+  ret->common.stats.mode = 1;  /* 1 for UM */
+
   return (nr_rlc_entity_t *)ret;
 }
 
@@ -166,9 +179,12 @@ nr_rlc_entity_t *new_nr_rlc_entity_tm(
   ret->common.discard_sdu     = nr_rlc_entity_tm_discard_sdu;
   ret->common.reestablishment = nr_rlc_entity_tm_reestablishment;
   ret->common.delete          = nr_rlc_entity_tm_delete;
+  ret->common.get_stats       = nr_rlc_entity_get_stats;
 
   ret->common.deliver_sdu                  = deliver_sdu;
   ret->common.deliver_sdu_data             = deliver_sdu_data;
 
+  ret->common.stats.mode = 2;  /* 2 for TM */
+
   return (nr_rlc_entity_t *)ret;
 }
diff --git a/openair2/LAYER2/nr_rlc/nr_rlc_entity.h b/openair2/LAYER2/nr_rlc/nr_rlc_entity.h
index 5b12a90cfd..f6feb49b57 100644
--- a/openair2/LAYER2/nr_rlc/nr_rlc_entity.h
+++ b/openair2/LAYER2/nr_rlc/nr_rlc_entity.h
@@ -26,6 +26,54 @@
 
 #define NR_SDU_MAX 16000   /* max NR PDCP SDU size is 9000, let's take more */
 
+typedef struct {
+  int      mode;               /* 0: RLC AM, 1: RLC UM, 2: RLC TM */
+
+  /* PDU stats */
+  /* TX */
+  int      txpdu_pkts;         /* aggregated number of transmitted RLC PDUs */
+  uint64_t txpdu_bytes;        /* aggregated amount of transmitted bytes in RLC PDUs */
+  /* TODO? */ uint64_t txpdu_wt_ms;      /* aggregated head-of-line tx packet waiting time to be transmitted (i.e. send to the MAC layer) */
+  int      txpdu_dd_pkts;      /* aggregated number of dropped or discarded tx packets by RLC */
+  uint64_t txpdu_dd_bytes;     /* aggregated amount of bytes dropped or discarded tx packets by RLC */
+  int      txpdu_retx_pkts;    /* aggregated number of tx pdus/pkts to be re-transmitted (only applicable to RLC AM) */
+  uint64_t txpdu_retx_bytes;   /* aggregated amount of bytes to be re-transmitted (only applicable to RLC AM) */
+  int      txpdu_segmented;    /* aggregated number of segmentations */
+  int      txpdu_status_pkts;  /* aggregated number of tx status pdus/pkts (only applicable to RLC AM) */
+  uint64_t txpdu_status_bytes; /* aggregated amount of tx status bytes  (only applicable to RLC AM) */
+  /* TODO? */ int      txbuf_occ_bytes;    /* current tx buffer occupancy in terms of amount of bytes (average: NOT IMPLEMENTED) */
+  /* TODO? */ int      txbuf_occ_pkts;     /* current tx buffer occupancy in terms of number of packets (average: NOT IMPLEMENTED) */
+  /* txbuf_wd_ms: the time window for which the txbuf  occupancy value is obtained - NOT IMPLEMENTED */
+
+  /* RX */
+  int      rxpdu_pkts;         /* aggregated number of received RLC PDUs */
+  uint64_t rxpdu_bytes;        /* amount of bytes received by the RLC */
+  int      rxpdu_dup_pkts;     /* aggregated number of duplicate packets */
+  uint64_t rxpdu_dup_bytes;    /* aggregated amount of duplicated bytes */
+  int      rxpdu_dd_pkts;      /* aggregated number of rx packets dropped or discarded by RLC */
+  uint64_t rxpdu_dd_bytes;     /* aggregated amount of rx bytes dropped or discarded by RLC */
+  int      rxpdu_ow_pkts;      /* aggregated number of out of window received RLC pdu */
+  uint64_t rxpdu_ow_bytes;     /* aggregated number of out of window bytes received RLC pdu */
+  int      rxpdu_status_pkts;  /* aggregated number of rx status pdus/pkts (only applicable to RLC AM) */
+  uint64_t rxpdu_status_bytes; /* aggregated amount of rx status bytes  (only applicable to RLC AM) */
+  /* rxpdu_rotout_ms: flag indicating rx reordering  timeout in ms - NOT IMPLEMENTED */
+  /* rxpdu_potout_ms: flag indicating the poll retransmit time out in ms - NOT IMPLEMENTED */
+  /* rxpdu_sptout_ms: flag indicating status prohibit timeout in ms - NOT IMPLEMENTED */
+  /* TODO? */ uint64_t rxbuf_occ_bytes;    /* current rx buffer occupancy in terms of amount of bytes (average: NOT IMPLEMENTED) */
+  /* TODO? */ int      rxbuf_occ_pkts;     /* current rx buffer occupancy in terms of number of packets (average: NOT IMPLEMENTED) */
+
+  /* SDU stats */
+  /* TX */
+  int      txsdu_pkts;         /* number of SDUs delivered */
+  uint64_t txsdu_bytes;        /* number of bytes of SDUs delivered */
+
+  /* RX */
+  int      rxsdu_pkts;         /* number of SDUs received */
+  uint64_t rxsdu_bytes;        /* number of bytes of SDUs received */
+  int      rxsdu_dd_pkts;      /* number of dropped or discarded SDUs */
+  uint64_t rxsdu_dd_bytes;     /* number of bytes of SDUs dropped or discarded */
+} nr_rlc_statistics_t;
+
 typedef struct {
   int status_size;
   int tx_size;
@@ -50,6 +98,8 @@ typedef struct nr_rlc_entity_t {
 
   void (*delete)(struct nr_rlc_entity_t *entity);
 
+  void (*get_stats)(struct nr_rlc_entity_t *entity, nr_rlc_statistics_t *out);
+
   /* callbacks provided to the RLC module */
   void (*deliver_sdu)(void *deliver_sdu_data, struct nr_rlc_entity_t *entity,
                       char *buf, int size);
@@ -63,6 +113,9 @@ typedef struct nr_rlc_entity_t {
   void (*max_retx_reached)(void *max_retx_reached_data,
                            struct nr_rlc_entity_t *entity);
   void *max_retx_reached_data;
+
+  /* statistics */
+  nr_rlc_statistics_t stats;
 } nr_rlc_entity_t;
 
 nr_rlc_entity_t *new_nr_rlc_entity_am(
diff --git a/openair2/LAYER2/nr_rlc/nr_rlc_entity_am.c b/openair2/LAYER2/nr_rlc/nr_rlc_entity_am.c
index 000c764e8f..a8f22dc6f3 100644
--- a/openair2/LAYER2/nr_rlc/nr_rlc_entity_am.c
+++ b/openair2/LAYER2/nr_rlc/nr_rlc_entity_am.c
@@ -234,6 +234,9 @@ static void reassemble_and_deliver(nr_rlc_entity_am_t *entity, int sn)
   entity->common.deliver_sdu(entity->common.deliver_sdu_data,
                              (nr_rlc_entity_t *)entity,
                              sdu, so);
+
+  entity->common.stats.txsdu_pkts++;
+  entity->common.stats.txsdu_bytes += so;
 }
 
 static void reception_actions(nr_rlc_entity_am_t *entity, nr_rlc_pdu_t *pdu)
@@ -545,6 +548,9 @@ void nr_rlc_entity_am_recv_pdu(nr_rlc_entity_t *_entity,
   int control_e3;
   unsigned char sn_set[32768];  /* used to dec retx_count only once per sdu */
 
+  entity->common.stats.rxpdu_pkts++;
+  entity->common.stats.rxpdu_bytes += size;
+
   nr_rlc_pdu_decoder_init(&decoder, buffer, size);
   dc = nr_rlc_pdu_decoder_get_bits(&decoder, 1); R(decoder);
   if (dc == 0) goto control;
@@ -592,6 +598,10 @@ void nr_rlc_entity_am_recv_pdu(nr_rlc_entity_t *_entity,
     LOG_D(RLC, "%s:%d:%s: warning: discard PDU, sn out of window (sn %d rx_next %d)\n",
           __FILE__, __LINE__, __FUNCTION__,
            sn, entity->rx_next);
+
+    entity->common.stats.rxpdu_ow_pkts++;
+    entity->common.stats.rxpdu_ow_bytes += size;
+
     goto discard;
   }
 
@@ -599,6 +609,10 @@ void nr_rlc_entity_am_recv_pdu(nr_rlc_entity_t *_entity,
   if (segment_already_received(entity, sn, so, data_size)) {
     LOG_D(RLC, "%s:%d:%s: warning: discard PDU, already received\n",
           __FILE__, __LINE__, __FUNCTION__);
+
+    entity->common.stats.rxpdu_dup_pkts++;
+    entity->common.stats.rxpdu_dup_bytes += size;
+
     goto discard;
   }
 
@@ -631,6 +645,9 @@ void nr_rlc_entity_am_recv_pdu(nr_rlc_entity_t *_entity,
   return;
 
 control:
+  entity->common.stats.rxpdu_status_pkts++;
+  entity->common.stats.rxpdu_status_bytes += size;
+
   cpt = nr_rlc_pdu_decoder_get_bits(&decoder, 3); R(decoder);
   if (cpt != 0) {
     LOG_D(RLC, "%s:%d:%s: warning: discard PDU, CPT not 0 (%d)\n",
@@ -750,6 +767,9 @@ discard:
   if (p)
     entity->status_triggered = 1;
 
+  entity->common.stats.rxpdu_dd_pkts++;
+  entity->common.stats.rxpdu_dd_bytes += size;
+
 #undef R
 }
 
@@ -1274,6 +1294,11 @@ static int generate_status(nr_rlc_entity_am_t *entity, char *buffer, int size)
   /* start t_status_prohibit */
   entity->t_status_prohibit_start = entity->t_current;
 
+  entity->common.stats.txpdu_pkts++;
+  entity->common.stats.txpdu_bytes += encoder.byte;
+  entity->common.stats.txpdu_status_pkts++;
+  entity->common.stats.txpdu_status_bytes += encoder.byte;
+
   return encoder.byte;
 }
 
@@ -1411,6 +1436,7 @@ static int generate_retx_pdu(nr_rlc_entity_am_t *entity, char *buffer,
   int pdu_header_size;
   int pdu_size;
   int p;
+  int ret_size;
 
   sdu = entity->retransmit_list;
 
@@ -1436,6 +1462,8 @@ static int generate_retx_pdu(nr_rlc_entity_am_t *entity, char *buffer,
     entity->retransmit_list = next_sdu;
     if (entity->retransmit_end == NULL)
       entity->retransmit_end = entity->retransmit_list;
+
+    entity->common.stats.txpdu_segmented++;
   }
 
   /* put SDU/SDU segment in the wait list */
@@ -1448,7 +1476,14 @@ static int generate_retx_pdu(nr_rlc_entity_am_t *entity, char *buffer,
     entity->force_poll = 0;
   }
 
-  return serialize_sdu(entity, sdu, buffer, size, p);
+  ret_size = serialize_sdu(entity, sdu, buffer, size, p);
+
+  entity->common.stats.txpdu_pkts++;
+  entity->common.stats.txpdu_bytes += ret_size;
+  entity->common.stats.txpdu_retx_pkts++;
+  entity->common.stats.txpdu_retx_bytes += ret_size;
+
+  return ret_size;
 }
 
 static int generate_tx_pdu(nr_rlc_entity_am_t *entity, char *buffer, int size)
@@ -1457,6 +1492,7 @@ static int generate_tx_pdu(nr_rlc_entity_am_t *entity, char *buffer, int size)
   int pdu_header_size;
   int pdu_size;
   int p;
+  int ret_size;
 
   /* sn out of window (that is: we have window stalling)? do nothing */
   if (is_window_stalling(entity))
@@ -1492,6 +1528,8 @@ static int generate_tx_pdu(nr_rlc_entity_am_t *entity, char *buffer, int size)
     entity->tx_list = next_sdu;
     if (entity->tx_end == NULL)
       entity->tx_end = entity->tx_list;
+
+    entity->common.stats.txpdu_segmented++;
   }
 
   /* update tx_next if the SDU segment is the last */
@@ -1517,7 +1555,12 @@ static int generate_tx_pdu(nr_rlc_entity_am_t *entity, char *buffer, int size)
     entity->force_poll = 0;
   }
 
-  return serialize_sdu(entity, sdu, buffer, size, p);
+  ret_size = serialize_sdu(entity, sdu, buffer, size, p);
+
+  entity->common.stats.txpdu_pkts++;
+  entity->common.stats.txpdu_bytes += ret_size;
+
+  return ret_size;
 }
 
 /* Pretend to serialize all the SDUs in a list and return the size
@@ -1587,6 +1630,9 @@ void nr_rlc_entity_am_recv_sdu(nr_rlc_entity_t *_entity,
   nr_rlc_entity_am_t *entity = (nr_rlc_entity_am_t *)_entity;
   nr_rlc_sdu_segment_t *sdu;
 
+  entity->common.stats.rxsdu_pkts++;
+  entity->common.stats.rxsdu_bytes += size;
+
   if (size > NR_SDU_MAX) {
     LOG_E(RLC, "%s:%d:%s: fatal: SDU size too big (%d bytes)\n",
           __FILE__, __LINE__, __FUNCTION__, size);
@@ -1596,6 +1642,10 @@ void nr_rlc_entity_am_recv_sdu(nr_rlc_entity_t *_entity,
   if (entity->tx_size + size > entity->tx_maxsize) {
     LOG_E(RLC, "%s:%d:%s: warning: SDU rejected, SDU buffer full\n",
           __FILE__, __LINE__, __FUNCTION__);
+
+    entity->common.stats.rxsdu_dd_pkts++;
+    entity->common.stats.rxsdu_dd_bytes += size;
+
     return;
   }
 
diff --git a/openair2/LAYER2/nr_rlc/nr_rlc_entity_tm.c b/openair2/LAYER2/nr_rlc/nr_rlc_entity_tm.c
index 86a0697624..2bc6b2a66c 100644
--- a/openair2/LAYER2/nr_rlc/nr_rlc_entity_tm.c
+++ b/openair2/LAYER2/nr_rlc/nr_rlc_entity_tm.c
@@ -36,9 +36,16 @@ void nr_rlc_entity_tm_recv_pdu(nr_rlc_entity_t *_entity,
                                char *buffer, int size)
 {
   nr_rlc_entity_tm_t *entity = (nr_rlc_entity_tm_t *)_entity;
+
+  entity->common.stats.rxpdu_pkts++;
+  entity->common.stats.rxpdu_bytes += size;
+
   entity->common.deliver_sdu(entity->common.deliver_sdu_data,
                              (nr_rlc_entity_t *)entity,
                              buffer, size);
+
+  entity->common.stats.txsdu_pkts++;
+  entity->common.stats.txsdu_bytes += size;
 }
 
 /*************************************************************************/
@@ -70,6 +77,9 @@ static int generate_tx_pdu(nr_rlc_entity_tm_t *entity, char *buffer, int size)
   entity->tx_size -= sdu->size;
   nr_rlc_free_sdu_segment(sdu);
 
+  entity->common.stats.txpdu_pkts++;
+  entity->common.stats.txpdu_bytes += size;
+
   return ret;
 }
 
@@ -119,6 +129,9 @@ void nr_rlc_entity_tm_recv_sdu(nr_rlc_entity_t *_entity,
   nr_rlc_entity_tm_t *entity = (nr_rlc_entity_tm_t *)_entity;
   nr_rlc_sdu_segment_t *sdu;
 
+  entity->common.stats.rxsdu_pkts++;
+  entity->common.stats.rxsdu_bytes += size;
+
   if (size > NR_SDU_MAX) {
     LOG_E(RLC, "%s:%d:%s: fatal: SDU size too big (%d bytes)\n",
           __FILE__, __LINE__, __FUNCTION__, size);
@@ -128,6 +141,10 @@ void nr_rlc_entity_tm_recv_sdu(nr_rlc_entity_t *_entity,
   if (entity->tx_size + size > entity->tx_maxsize) {
     LOG_D(RLC, "%s:%d:%s: warning: SDU rejected, SDU buffer full\n",
           __FILE__, __LINE__, __FUNCTION__);
+
+    entity->common.stats.rxsdu_dd_pkts++;
+    entity->common.stats.rxsdu_dd_bytes += size;
+
     return;
   }
 
diff --git a/openair2/LAYER2/nr_rlc/nr_rlc_entity_um.c b/openair2/LAYER2/nr_rlc/nr_rlc_entity_um.c
index 4ef952667d..7d7368a34a 100644
--- a/openair2/LAYER2/nr_rlc/nr_rlc_entity_um.c
+++ b/openair2/LAYER2/nr_rlc/nr_rlc_entity_um.c
@@ -165,6 +165,9 @@ static void reassemble_and_deliver(nr_rlc_entity_um_t *entity, int sn)
   entity->common.deliver_sdu(entity->common.deliver_sdu_data,
                              (nr_rlc_entity_t *)entity,
                              sdu, so);
+
+  entity->common.stats.txsdu_pkts++;
+  entity->common.stats.txsdu_bytes += so;
 }
 
 static void reception_actions(nr_rlc_entity_um_t *entity, nr_rlc_pdu_t *pdu)
@@ -194,6 +197,15 @@ static void reception_actions(nr_rlc_entity_um_t *entity, nr_rlc_pdu_t *pdu)
         nr_rlc_pdu_t *p = entity->rx_list;
         entity->rx_size -= p->size;
         entity->rx_list = p->next;
+
+        entity->common.stats.rxpdu_dd_pkts++;
+        /* we don't count PDU header bytes here, so be it */
+        entity->common.stats.rxpdu_dd_bytes += p->size;
+
+        entity->common.stats.rxpdu_ow_pkts++;
+        /* we don't count PDU header bytes here, so be it */
+        entity->common.stats.rxpdu_ow_bytes += p->size;
+
         nr_rlc_free_pdu(p);
       }
 
@@ -258,6 +270,9 @@ void nr_rlc_entity_um_recv_pdu(nr_rlc_entity_t *_entity,
   int is_first;
   int is_last;
 
+  entity->common.stats.rxpdu_pkts++;
+  entity->common.stats.rxpdu_bytes += size;
+
   nr_rlc_pdu_decoder_init(&decoder, buffer, size);
 
   si = nr_rlc_pdu_decoder_get_bits(&decoder, 2); R(decoder);
@@ -276,6 +291,10 @@ void nr_rlc_entity_um_recv_pdu(nr_rlc_entity_t *_entity,
     entity->common.deliver_sdu(entity->common.deliver_sdu_data,
                                (nr_rlc_entity_t *)entity,
                                buffer + 1, size - 1);
+
+    entity->common.stats.txsdu_pkts++;
+    entity->common.stats.txsdu_bytes += size - 1;
+
     return;
   }
 
@@ -336,6 +355,9 @@ err:
   goto discard;
 
 discard:
+  entity->common.stats.rxpdu_dd_pkts++;
+  entity->common.stats.rxpdu_dd_bytes += size;
+
   return;
 
 #undef R
@@ -434,6 +456,8 @@ static nr_rlc_sdu_segment_t *resegment(nr_rlc_sdu_segment_t *sdu,
   next->so = sdu->so + sdu->size;
   next->is_first = 0;
 
+  entity->common.stats.txpdu_segmented++;
+
   return next;
 }
 
@@ -474,6 +498,8 @@ static int generate_tx_pdu(nr_rlc_entity_um_t *entity, char *buffer, int size)
     entity->tx_list = next_sdu;
     if (entity->tx_end == NULL)
       entity->tx_end = entity->tx_list;
+
+    entity->common.stats.txpdu_segmented++;
   }
 
   /* update tx_next if the SDU is an SDU segment and is the last */
@@ -485,6 +511,9 @@ static int generate_tx_pdu(nr_rlc_entity_um_t *entity, char *buffer, int size)
   entity->tx_size -= sdu->size;
   nr_rlc_free_sdu_segment(sdu);
 
+  entity->common.stats.txpdu_pkts++;
+  entity->common.stats.txpdu_bytes += size;
+
   return ret;
 }
 
@@ -538,6 +567,9 @@ void nr_rlc_entity_um_recv_sdu(nr_rlc_entity_t *_entity,
   nr_rlc_entity_um_t *entity = (nr_rlc_entity_um_t *)_entity;
   nr_rlc_sdu_segment_t *sdu;
 
+  entity->common.stats.rxsdu_pkts++;
+  entity->common.stats.rxsdu_bytes += size;
+
   if (size > NR_SDU_MAX) {
     LOG_E(RLC, "%s:%d:%s: fatal: SDU size too big (%d bytes)\n",
           __FILE__, __LINE__, __FUNCTION__, size);
@@ -547,6 +579,10 @@ void nr_rlc_entity_um_recv_sdu(nr_rlc_entity_t *_entity,
   if (entity->tx_size + size > entity->tx_maxsize) {
     LOG_D(RLC, "%s:%d:%s: warning: SDU rejected, SDU buffer full\n",
           __FILE__, __LINE__, __FUNCTION__);
+
+    entity->common.stats.rxsdu_dd_pkts++;
+    entity->common.stats.rxsdu_dd_bytes += size;
+
     return;
   }
 
@@ -591,6 +627,11 @@ static void check_t_reassembly(nr_rlc_entity_um_t *entity)
     nr_rlc_pdu_t *p = cur;
     cur = cur->next;
     entity->rx_list = cur;
+
+    entity->common.stats.rxpdu_dd_pkts++;
+    /* we don't count PDU header bytes here, so be it */
+    entity->common.stats.rxpdu_dd_bytes += p->size;
+
     nr_rlc_free_pdu(p);
   }
 
diff --git a/openair2/LAYER2/nr_rlc/nr_rlc_oai_api.c b/openair2/LAYER2/nr_rlc/nr_rlc_oai_api.c
index 66553e813b..2569d617c3 100644
--- a/openair2/LAYER2/nr_rlc/nr_rlc_oai_api.c
+++ b/openair2/LAYER2/nr_rlc/nr_rlc_oai_api.c
@@ -1002,3 +1002,39 @@ void rlc_tick(int a, int b)
         __FILE__, __LINE__, __FUNCTION__);
   exit(1);
 }
+
+/* returns 0 in case of error, 1 if everything ok */
+int nr_rlc_get_statistics(
+  int rnti,
+  int srb_flag,
+  int rb_id,
+  nr_rlc_statistics_t *out)
+{
+  nr_rlc_ue_t     *ue;
+  nr_rlc_entity_t *rb;
+  int             ret;
+
+  nr_rlc_manager_lock(nr_rlc_ue_manager);
+  ue = nr_rlc_manager_get_ue(nr_rlc_ue_manager, rnti);
+
+  rb = NULL;
+
+  if (srb_flag) {
+    if (rb_id >= 1 && rb_id <= 2)
+      rb = ue->srb[rb_id - 1];
+  } else {
+    if (rb_id >= 1 && rb_id <= 5)
+      rb = ue->drb[rb_id - 1];
+  }
+
+  if (rb != NULL) {
+    rb->get_stats(rb, out);
+    ret = 1;
+  } else {
+    ret = 0;
+  }
+
+  nr_rlc_manager_unlock(nr_rlc_ue_manager);
+
+  return ret;
+}
diff --git a/openair2/PHY_INTERFACE/phy_stub_UE.c b/openair2/PHY_INTERFACE/phy_stub_UE.c
index c212075934..52a30c4d08 100644
--- a/openair2/PHY_INTERFACE/phy_stub_UE.c
+++ b/openair2/PHY_INTERFACE/phy_stub_UE.c
@@ -48,6 +48,14 @@ nfapi_dl_config_request_t* dl_config_req = NULL;
 nfapi_ul_config_request_t* ul_config_req = NULL;
 nfapi_hi_dci0_request_t* hi_dci0_req = NULL;
 
+int cqi[MAX_MOBILES_PER_ENB] = { [0 ... MAX_MOBILES_PER_ENB-1] = 15};
+int get_ue_cqi(int mod_id) {
+  if (cqi[mod_id] >= 0 && cqi[mod_id] <= 15)
+    return cqi[mod_id];
+  else
+    return 6 + rand() % 10;
+}
+
 extern nfapi_tx_request_pdu_t* tx_request_pdu[1023][10][10];
 //extern int timer_subframe;
 //extern int timer_frame;
@@ -259,7 +267,7 @@ void fill_ulsch_cqi_indication_UE_MAC(int Mod_id,
   pdu->ul_cqi_information.channel = 1; // PUSCH
 
   // eNB_scheduler_primitives.c:4839: the upper four bits seem to be the CQI
-  const int cqi = 15;
+  const int cqi = get_ue_cqi(Mod_id);
   raw_pdu->pdu[0] = cqi << 4;
 
   UL_INFO->cqi_ind.cqi_indication_body.number_of_cqis++;
@@ -736,7 +744,7 @@ void dl_config_req_UE_MAC_dci(int sfn,
   } else if (rnti_type == 2) {
     if (rnti == 0xFFFF) { /* SI-RNTI */
       for (int ue_id = 0; ue_id < num_ue; ue_id++) {
-        if (UE_mac_inst[ue_id].UE_mode[0] == NOT_SYNCHED)
+        if (UE_mac_inst[ue_id].UE_mode[0] == NOT_SYNCHED || UE_mac_inst[ue_id].UE_mode[0] == PRACH_INACTIVE)
           continue;
 
         ue_decode_si(ue_id, 0, sfn, 0,
diff --git a/openair2/RRC/LTE/L2_interface_ue.c b/openair2/RRC/LTE/L2_interface_ue.c
index 5c1800cdd4..b7464b28dc 100644
--- a/openair2/RRC/LTE/L2_interface_ue.c
+++ b/openair2/RRC/LTE/L2_interface_ue.c
@@ -116,7 +116,7 @@ mac_rrc_data_req_ue(
 
   return(0);
 }
-
+extern UE_MAC_INST *UE_mac_inst;
 //------------------------------------------------------------------------------
 int8_t
 mac_rrc_data_ind_ue(
@@ -168,29 +168,34 @@ mac_rrc_data_ind_ue(
     }
   }
 
-  if(srb_idP == BCCH) {
+  if(srb_idP == BCCH
+      && (!UE_mac_inst[ctxt.instance].SI_Decoded
+          || !UE_mac_inst[ctxt.instance].SIB_Decoded)) {
     LOG_D(RRC,"[UE %d] Received SDU for BCCH on SRB %ld from eNB %d\n",module_idP,srb_idP,eNB_indexP);
     {
-      MessageDef *message_p;
-      int msg_sdu_size = sizeof(RRC_MAC_BCCH_DATA_IND (message_p).sdu);
-
-      if (sdu_lenP > msg_sdu_size) {
-        LOG_E(RRC, "SDU larger than BCCH SDU buffer size (%d, %d)", sdu_lenP, msg_sdu_size);
-        sdu_size = msg_sdu_size;
-      } else {
-        sdu_size = sdu_lenP;
-      }
+      protocol_ctxt_t ctxt2;
+      PROTOCOL_CTXT_SET_BY_MODULE_ID(&ctxt2, ctxt.instance, ENB_FLAG_NO, NOT_A_RNTI,
+                                     frameP, 0,
+                                     eNB_indexP);
+
+
+      //message_p = itti_alloc_new_message (TASK_MAC_UE, 0, RRC_MAC_BCCH_DATA_IND);
+      //memset (RRC_MAC_BCCH_DATA_IND (message_p).sdu, 0, BCCH_SDU_SIZE);
+      //RRC_MAC_BCCH_DATA_IND (message_p).frame     = frameP;
+      //RRC_MAC_BCCH_DATA_IND (message_p).sub_frame = sub_frameP;
+      //RRC_MAC_BCCH_DATA_IND (message_p).sdu_size  = sdu_size;
+      //memcpy (RRC_MAC_BCCH_DATA_IND (message_p).sdu, sduP, sdu_size);
+      //RRC_MAC_BCCH_DATA_IND (message_p).enb_index = eNB_indexP;
+      //RRC_MAC_BCCH_DATA_IND (message_p).rsrq      = 30 /* TODO change phy to report rspq */;
+      //RRC_MAC_BCCH_DATA_IND (message_p).rsrp      = 45 /* TODO change phy to report rspp */;
+      //itti_send_msg_to_task (TASK_RRC_UE, ctxt.instance, message_p);
+      decode_BCCH_DLSCH_Message (&ctxt2,
+                                 eNB_indexP,
+                                 sduP,
+                                 sdu_lenP,
+                                 30,
+                                 45);
 
-      message_p = itti_alloc_new_message (TASK_MAC_UE, 0, RRC_MAC_BCCH_DATA_IND);
-      memset (RRC_MAC_BCCH_DATA_IND (message_p).sdu, 0, BCCH_SDU_SIZE);
-      RRC_MAC_BCCH_DATA_IND (message_p).frame     = frameP;
-      RRC_MAC_BCCH_DATA_IND (message_p).sub_frame = sub_frameP;
-      RRC_MAC_BCCH_DATA_IND (message_p).sdu_size  = sdu_size;
-      memcpy (RRC_MAC_BCCH_DATA_IND (message_p).sdu, sduP, sdu_size);
-      RRC_MAC_BCCH_DATA_IND (message_p).enb_index = eNB_indexP;
-      RRC_MAC_BCCH_DATA_IND (message_p).rsrq      = 30 /* TODO change phy to report rspq */;
-      RRC_MAC_BCCH_DATA_IND (message_p).rsrp      = 45 /* TODO change phy to report rspp */;
-      itti_send_msg_to_task (TASK_RRC_UE, ctxt.instance, message_p);
     }
   }
 
@@ -347,14 +352,18 @@ rrc_data_ind_ue(
 //-------------------------------------------------------------------------------------------//
 void rrc_in_sync_ind(module_id_t Mod_idP, frame_t frameP, uint16_t eNB_index) {
   //-------------------------------------------------------------------------------------------//
-  {
-    MessageDef *message_p;
-    //LOG_I(RRC,"sending a message to task_mac_ue\n");
-    message_p = itti_alloc_new_message (TASK_MAC_UE, 0, RRC_MAC_IN_SYNC_IND);
-    RRC_MAC_IN_SYNC_IND (message_p).frame = frameP;
-    RRC_MAC_IN_SYNC_IND (message_p).enb_index = eNB_index;
-    itti_send_msg_to_task (TASK_RRC_UE, UE_MODULE_ID_TO_INSTANCE(Mod_idP), message_p);
-  }
+  //{
+  //  MessageDef *message_p;
+  //  //LOG_I(RRC,"sending a message to task_mac_ue\n");
+  //  message_p = itti_alloc_new_message (TASK_MAC_UE, 0, RRC_MAC_IN_SYNC_IND);
+  //  RRC_MAC_IN_SYNC_IND (message_p).frame = frameP;
+  //  RRC_MAC_IN_SYNC_IND (message_p).enb_index = eNB_index;
+  //  itti_send_msg_to_task (TASK_RRC_UE, UE_MODULE_ID_TO_INSTANCE(Mod_idP), message_p);
+  //}
+  UE_RRC_INFO *info = &UE_rrc_inst[Mod_idP].Info[eNB_index];
+  info->N310_cnt = 0;
+  if (info->T310_active)
+    info->N311_cnt++;
 }
 
 //-------------------------------------------------------------------------------------------//
diff --git a/openair2/RRC/LTE/MESSAGES/asn1_msg.c b/openair2/RRC/LTE/MESSAGES/asn1_msg.c
index ce26aeef87..8b5571f58e 100644
--- a/openair2/RRC/LTE/MESSAGES/asn1_msg.c
+++ b/openair2/RRC/LTE/MESSAGES/asn1_msg.c
@@ -2701,7 +2701,7 @@ do_RRCConnectionSetup(
   }
 
   if (carrier->sib1->tdd_Config == NULL) { // FDD
-    physicalConfigDedicated2->schedulingRequestConfig->choice.setup.sr_ConfigIndex = 5+(ue_context_pP->local_uid%10);  // Isr = 5 (every 10 subframes, offset=2+UE_id mod3)
+    physicalConfigDedicated2->schedulingRequestConfig->choice.setup.sr_ConfigIndex = (ue_context_pP->local_uid%5);  // Isr = 5 (every 10 subframes, offset=2+UE_id mod3)
   } else {
     switch (carrier->sib1->tdd_Config->subframeAssignment) {
       case 1:
diff --git a/openair2/RRC/LTE/rrc_UE.c b/openair2/RRC/LTE/rrc_UE.c
index b2230df623..ce00d6a771 100644
--- a/openair2/RRC/LTE/rrc_UE.c
+++ b/openair2/RRC/LTE/rrc_UE.c
@@ -2599,6 +2599,7 @@ int decode_BCCH_DLSCH_Message(
                     sizeof(LTE_SystemInformationBlockType1_t) );
             LOG_D( RRC, "[UE %"PRIu8"] Decoding First SIB1\n", ctxt_pP->module_id );
             decode_SIB1( ctxt_pP, eNB_index, rsrq, rsrp );
+            UE_mac_inst[ctxt_pP->module_id].SIB_Decoded = 1;
           }
         }
 
diff --git a/openair2/RRC/LTE/rrc_eNB.c b/openair2/RRC/LTE/rrc_eNB.c
index f86b0ddbae..905dd8f983 100644
--- a/openair2/RRC/LTE/rrc_eNB.c
+++ b/openair2/RRC/LTE/rrc_eNB.c
@@ -89,6 +89,17 @@
 #include "gtpv1u_eNB_task.h"
 #include <openair3/ocp-gtpu/gtp_itf.h>
 
+#ifdef USE_FLEXRIC
+extern struct e2ap_agent_s* flexric_ag;
+#define plmn_t plmn_t_WE_DONT_NEED
+#include "rrc_stats_rf.h"
+#include "rrc_event_rf.h"
+#undef plmn_t
+extern void fill_rrc_stats_msg(struct flatcc_builder*, const struct rrc_stats_report_style_s*, void*);
+void rrc_event_fill_attach_msg(struct flatcc_builder* B, const rrc_event_report_style_t* style, void* ctxt);
+void rrc_event_fill_complete_msg(struct flatcc_builder* B, const rrc_event_report_style_t* style, void *ctxt);
+#endif
+
 #include "intertask_interface.h"
 
 #if ENABLE_RAL
@@ -1102,6 +1113,9 @@ void release_UE_in_freeList(module_id_t mod_id) {
           flexran_agent_get_rrc_xface(mod_id)->flexran_agent_notify_ue_state_change(
             mod_id, rnti, PROTOCOL__FLEX_UE_STATE_CHANGE_TYPE__FLUESC_DEACTIVATED);
         }
+#ifdef USE_FLEXRIC
+            sm_rrc_event_trigger(flexric_ag, rnti, rrc_event_Event_Release, NULL, NULL);
+#endif
 
         for(j = 0; j < 10; j++) {
           ul_req_tmp = &eNB_MAC->UL_req_tmp[CC_id][j].ul_config_request_body;
@@ -4509,8 +4523,6 @@ static int encode_CG_ConfigInfo(
 
 
 
-
-
 //-----------------------------------------------------------------------------
 void
 rrc_eNB_process_MeasurementReport(
@@ -4665,8 +4677,13 @@ rrc_eNB_process_MeasurementReport(
     }
   }
 
-  if (measResults2->measResultNeighCells == NULL)
+  if (measResults2->measResultNeighCells == NULL) {
+    /* no neighboring cells, trigger before leaving */
+#ifdef USE_FLEXRIC
+    sm_rrc_stats_trigger_message(flexric_ag, ctxt_pP->rnti, fill_rrc_stats_msg, ue_context_pP);
+#endif
     return;
+  }
 
   if (measResults2->measResultNeighCells->choice.measResultListEUTRA.list.count > 0) {
     neighboring_cells = measResults2->measResultNeighCells->choice.measResultListEUTRA.list.count;
@@ -4687,11 +4704,11 @@ rrc_eNB_process_MeasurementReport(
         measResults2->measResultNeighCells->choice.measResultListEUTRA.list.array[i]->measResult.rsrpResult;
       ue_context_pP->ue_context.measResults->measResultNeighCells->choice.measResultListEUTRA.list.array[i]->measResult.rsrqResult =
         measResults2->measResultNeighCells->choice.measResultListEUTRA.list.array[i]->measResult.rsrqResult;
-      LOG_D(RRC, "Physical Cell Id %d\n",
+      LOG_I(RRC, "Physical Cell Id %d\n",
             (int)ue_context_pP->ue_context.measResults->measResultNeighCells->choice.measResultListEUTRA.list.array[i]->physCellId);
-      LOG_D(RRC, "RSRP of Target %ld\n",
+      LOG_I(RRC, "RSRP of Target %ld\n",
             (*ue_context_pP->ue_context.measResults->measResultNeighCells->choice.measResultListEUTRA.list.array[i]->measResult.rsrpResult)-140);
-      LOG_D(RRC, "RSRQ of Target %ld\n",
+      LOG_I(RRC, "RSRQ of Target %ld\n",
             (*ue_context_pP->ue_context.measResults->measResultNeighCells->choice.measResultListEUTRA.list.array[i]->measResult.rsrqResult)/2 - 20);
 
       if ( *measResults2->measResultNeighCells->choice.measResultListEUTRA.list.array[i]->measResult.rsrpResult >= ncell_max ) {
@@ -4708,7 +4725,13 @@ rrc_eNB_process_MeasurementReport(
       //(*(measResults2->measResultNeighCells->choice.measResultListEUTRA.list.array[i]->
       //measResult.rsrqResult))/2 - 20);
     }
+    ue_context_pP->ue_context.measResults->measResultNeighCells->present = LTE_MeasResults__measResultNeighCells_PR_measResultListEUTRA;
+    ue_context_pP->ue_context.measResults->measResultNeighCells->choice.measResultListEUTRA.list.count = neighboring_cells;
+    LOG_I(RRC, "measResultNeighCells %d EUTRA cells\n", neighboring_cells);
   }
+#ifdef USE_FLEXRIC
+  sm_rrc_stats_trigger_message(flexric_ag, ctxt_pP->rnti, fill_rrc_stats_msg, ue_context_pP);
+#endif
 
   /* Decide whether to trigger HO or not */
   if (!(measResults2->measId == 4))
@@ -7515,6 +7538,9 @@ rrc_eNB_decode_ccch(
                   ctxt_pP->rnti,
                   PROTOCOL__FLEX_UE_STATE_CHANGE_TYPE__FLUESC_DEACTIVATED);
             }
+#ifdef USE_FLEXRIC
+            sm_rrc_event_trigger(flexric_ag, ctxt_pP->rnti, rrc_event_Event_Release, NULL, NULL);
+#endif
 
             LOG_I(RRC, PROTOCOL_RRC_CTXT_UE_FMT" Can't create new context for UE random UE identity (0x%" PRIx64 ")\n",
                   PROTOCOL_RRC_CTXT_UE_ARGS(ctxt_pP),
@@ -8121,6 +8147,14 @@ rrc_eNB_decode_dcch(
                 ue_context_p->ue_id_rnti,
                 flexran_agent_handover?PROTOCOL__FLEX_UE_STATE_CHANGE_TYPE__FLUESC_ACTIVATED:PROTOCOL__FLEX_UE_STATE_CHANGE_TYPE__FLUESC_UPDATED);
           }
+#ifdef USE_FLEXRIC
+          // TODO IMSI?
+          sm_rrc_event_trigger(flexric_ag,
+                               ue_context_p->ue_id_rnti,
+                               rrc_event_Event_Complete,
+                               rrc_event_fill_complete_msg,
+                               ue_context_p);
+#endif
         }
 
         if (EPC_MODE_ENABLED) {
@@ -8277,6 +8311,13 @@ rrc_eNB_decode_dcch(
                   ue_context_p->ue_id_rnti,
                   PROTOCOL__FLEX_UE_STATE_CHANGE_TYPE__FLUESC_ACTIVATED);
             }
+#ifdef USE_FLEXRIC
+            sm_rrc_event_trigger(flexric_ag,
+                               ue_context_p->ue_id_rnti,
+                               rrc_event_Event_Attach,
+                               rrc_event_fill_attach_msg,
+                               NULL);
+#endif
           }
 
           //ue_context_p->ue_context.ue_release_timer = 0;
@@ -8332,6 +8373,14 @@ rrc_eNB_decode_dcch(
                   ue_context_p->ue_id_rnti,
                   PROTOCOL__FLEX_UE_STATE_CHANGE_TYPE__FLUESC_ACTIVATED);
             }
+#ifdef USE_FLEXRIC
+          LTE_RRCConnectionSetupComplete_r8_IEs_t* csc = &ul_dcch_msg->message.choice.c1.choice.rrcConnectionSetupComplete.criticalExtensions.choice.c1.choice.rrcConnectionSetupComplete_r8;
+          sm_rrc_event_trigger(flexric_ag,
+                               ue_context_p->ue_id_rnti,
+                               rrc_event_Event_Attach,
+                               rrc_event_fill_attach_msg,
+                               &csc->selectedPLMN_Identity);
+#endif
           }
         }
 
diff --git a/openair2/RRC/NR/nr_rrc_defs.h b/openair2/RRC/NR/nr_rrc_defs.h
index 7fd9e5d53a..26eadab8dd 100644
--- a/openair2/RRC/NR/nr_rrc_defs.h
+++ b/openair2/RRC/NR/nr_rrc_defs.h
@@ -472,6 +472,9 @@ typedef struct gNB_RRC_INST_s {
   hash_table_t                                        *initial_id2_ngap_ids;
   hash_table_t                                        *ngap_id2_ngap_ids   ;
 
+  gNB_RrcConfigurationReq configuration;
+  char* node_name;
+
   // other PLMN parameters
   /// Mobile country code
   int mcc;
diff --git a/openair2/RRC/NR/rrc_gNB.c b/openair2/RRC/NR/rrc_gNB.c
index bbaff81698..f2521d40fe 100755
--- a/openair2/RRC/NR/rrc_gNB.c
+++ b/openair2/RRC/NR/rrc_gNB.c
@@ -298,6 +298,7 @@ char openair_rrc_gNB_configuration(const module_id_t gnb_mod_idP, gNB_RrcConfigu
   AssertFatal(rrc != NULL, "RC.nrrrc not initialized!");
   AssertFatal(NUMBER_OF_UE_MAX < (module_id_t)0xFFFFFFFFFFFFFFFF, " variable overflow");
   AssertFatal(configuration!=NULL,"configuration input is null\n");
+  rrc->configuration = *configuration;
   rrc->module_id = gnb_mod_idP;
   rrc->Nb_ue = 0;
   rrc->carrier.Srb0.Active = 0;
diff --git a/openair2/RRC/NR/rrc_gNB_reconfig.c b/openair2/RRC/NR/rrc_gNB_reconfig.c
index 8ed19e9d82..ef0d507313 100644
--- a/openair2/RRC/NR/rrc_gNB_reconfig.c
+++ b/openair2/RRC/NR/rrc_gNB_reconfig.c
@@ -71,8 +71,8 @@ void fill_default_initialDownlinkBWP(NR_BWP_Downlink_t *bwp, NR_ServingCellConfi
   bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->scramblingID0=NULL;
   bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->scramblingID1=NULL;
   bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->phaseTrackingRS=NULL;
-  bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = calloc(1,sizeof(*bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition));
-  *bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NR_DMRS_DownlinkConfig__dmrs_AdditionalPosition_pos0;
+  bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NULL;//calloc(1,sizeof(*bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition));
+  //*bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NR_DMRS_DownlinkConfig__dmrs_AdditionalPosition_pos0;
 }
 
 void fill_default_coresetZero(NR_ControlResourceSet_t *coreset0, NR_ServingCellConfigCommon_t *servingcellconfigcommon) {
@@ -304,8 +304,8 @@ void fill_default_secondaryCellGroup(NR_ServingCellConfigCommon_t *servingcellco
  secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->scramblingID1=NULL;
  secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->phaseTrackingRS=NULL;
 
- secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = calloc(1,sizeof(*secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition));
- *secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NR_DMRS_DownlinkConfig__dmrs_AdditionalPosition_pos0;
+ secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NULL;//calloc(1,sizeof(*secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition));
+ //*secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NR_DMRS_DownlinkConfig__dmrs_AdditionalPosition_pos0;
 
 
  secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->tci_StatesToAddModList=calloc(1,sizeof(*secondaryCellGroup->spCellConfig->spCellConfigDedicated->initialDownlinkBWP->pdsch_Config->choice.setup->tci_StatesToAddModList));
@@ -651,8 +651,8 @@ void fill_default_secondaryCellGroup(NR_ServingCellConfigCommon_t *servingcellco
  if (!servingcellconfigdedicated) {
    bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->phaseTrackingRS=NULL;
  }
- bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = calloc(1,sizeof(*bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition));
- *bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NR_DMRS_DownlinkConfig__dmrs_AdditionalPosition_pos0;
+ bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NULL;//calloc(1,sizeof(*bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition));
+ //*bwp->bwp_Dedicated->pdsch_Config->choice.setup->dmrs_DownlinkForPDSCH_MappingTypeA->choice.setup->dmrs_AdditionalPosition = NR_DMRS_DownlinkConfig__dmrs_AdditionalPosition_pos0;
 
  bwp->bwp_Dedicated->pdsch_Config->choice.setup->tci_StatesToAddModList=calloc(1,sizeof(*bwp->bwp_Dedicated->pdsch_Config->choice.setup->tci_StatesToAddModList));
 
@@ -1012,8 +1012,8 @@ void fill_default_secondaryCellGroup(NR_ServingCellConfigCommon_t *servingcellco
  *pucchfmt2->maxCodeRate=NR_PUCCH_MaxCodeRate_zeroDot35;
  pucchfmt2->nrofSlots=NULL;
  pucchfmt2->pi2BPSK=NULL;
- pucchfmt2->simultaneousHARQ_ACK_CSI=calloc(1,sizeof(*pucchfmt2->simultaneousHARQ_ACK_CSI));
- *pucchfmt2->simultaneousHARQ_ACK_CSI=NR_PUCCH_FormatConfig__simultaneousHARQ_ACK_CSI_true;
+ pucchfmt2->simultaneousHARQ_ACK_CSI=NULL;//calloc(1,sizeof(*pucchfmt2->simultaneousHARQ_ACK_CSI));
+ //*pucchfmt2->simultaneousHARQ_ACK_CSI=NR_PUCCH_FormatConfig__simultaneousHARQ_ACK_CSI_true;
 
  // for scheduling requestresource
  pucch_Config->schedulingRequestResourceToAddModList = calloc(1,sizeof(*pucch_Config->schedulingRequestResourceToAddModList));
@@ -1303,7 +1303,7 @@ void fill_default_rbconfig(NR_RadioBearerConfig_t *rbconfig,
   drb_ToAddMod->pdcp_Config->moreThanOneRLC = NULL;
 
   drb_ToAddMod->pdcp_Config->t_Reordering = calloc(1,sizeof(*drb_ToAddMod->pdcp_Config->t_Reordering));
-  *drb_ToAddMod->pdcp_Config->t_Reordering = NR_PDCP_Config__t_Reordering_ms0;
+  *drb_ToAddMod->pdcp_Config->t_Reordering = NR_PDCP_Config__t_Reordering_ms100;
   drb_ToAddMod->pdcp_Config->ext1 = NULL;
 
   ASN_SEQUENCE_ADD(&rbconfig->drb_ToAddModList->list,drb_ToAddMod);
diff --git a/openair3/UTILS/mme_default_values.h b/openair3/UTILS/mme_default_values.h
index f02e94e2c5..384301ada9 100644
--- a/openair3/UTILS/mme_default_values.h
+++ b/openair3/UTILS/mme_default_values.h
@@ -62,7 +62,7 @@
  ******************************************************************************/
 
 #define MAX_NUMBER_OF_ENB       (2)
-#define MAX_NUMBER_OF_UE        (64)
+#define MAX_NUMBER_OF_UE        (128)
 
 #define MMEC                    (0)
 #define MMEGID                  (0)
diff --git a/targets/COMMON/openairinterface5g_limits.h b/targets/COMMON/openairinterface5g_limits.h
index de1502112b..2ee8eb1a14 100644
--- a/targets/COMMON/openairinterface5g_limits.h
+++ b/targets/COMMON/openairinterface5g_limits.h
@@ -27,7 +27,7 @@
 
 #        ifndef PHYSIM
 #            ifndef UE_EXPANSION
-#                    define NUMBER_OF_UE_MAX 4
+#                    define NUMBER_OF_UE_MAX 128
 #                    define NUMBER_OF_NR_UE_MAX 4
 #                    define NUMBER_OF_CONNECTED_eNB_MAX 1
 #                    define NUMBER_OF_CONNECTED_gNB_MAX 1
diff --git a/targets/RT/USER/lte-softmodem.c b/targets/RT/USER/lte-softmodem.c
index c21c04ba05..eeaf374db8 100644
--- a/targets/RT/USER/lte-softmodem.c
+++ b/targets/RT/USER/lte-softmodem.c
@@ -601,6 +601,12 @@ int main ( int argc, char **argv )
       if(NFAPI_MODE != NFAPI_MODE_PNF)
       flexran_agent_start(i);
     }
+#ifdef USE_FLEXRIC
+    extern void flexric_start(void);
+    flexric_start();
+#else
+#warning "compiling without FlexricAgent"
+#endif
     
     /* initializes PDCP and sets correct RLC Request/PDCP Indication callbacks
      * for monolithic/F1 modes */
diff --git a/targets/RT/USER/lte-ue.c b/targets/RT/USER/lte-ue.c
index cc084d18c5..71b271686f 100644
--- a/targets/RT/USER/lte-ue.c
+++ b/targets/RT/USER/lte-ue.c
@@ -65,6 +65,55 @@
 
 extern double cpuf;
 
+#include "common/utils/telnetsrv/telnetsrv.h"
+#include "common/utils/load_module_shlib.h"
+int ue_enable_cmd(char *s, int debug, telnet_printfunc_t prnt)
+{
+  const int ue = atoi(s);
+  LOG_W(MAC, "set UE %d UE_mode NOT_SYNCHED\n", ue);
+  UE_mac_inst[ue].UE_mode[0] = NOT_SYNCHED;
+  return 0;
+}
+extern int cqi[MAX_MOBILES_PER_ENB];
+int ue_cqi_set(char *s, int debug, telnet_printfunc_t prnt) {
+  LOG_W(MAC, "%s(): input %s\n", __func__, s);
+  const char *sue = strtok(s, " ");
+  if (!sue) {
+    LOG_E(MAC, "error: could not strtok() UE part of input!\n");
+    return -1;
+  }
+  /* try to convert: if valid number, use it, else if it might be zero, check
+   * that string was zero, otherwise give -1 (any) */
+  const int ue = atoi(sue) ? atoi(sue) : (strcmp(sue, "0") == 0 ? 0 : -1);
+  const char *scqi = strtok(NULL, " ");
+  if (!scqi) {
+    LOG_E(MAC, "error: could not strtok() CQI part of input!\n");
+    return -1;
+  }
+  const int c = atoi(scqi) ? atoi(scqi) : (strcmp(scqi, "0") == 0 ? 0 : -1);
+  if (ue >= 0)
+    cqi[ue] = c;
+  else
+    for (int i = 0; i < MAX_MOBILES_PER_ENB; ++i)
+      cqi[i] = c;
+  LOG_W(MAC,
+        "set ue %d (%s) to cqi %d (%s)\n",
+        ue,
+        ue < 0 ? "all UEs" : "single UE",
+        c,
+        c >= 0 && c <= 15 ? "fixed CQI" : "random CQI");
+  return 0;
+}
+telnetshell_cmddef_t ue_status_cmdarray[] = {
+   {"ue", "any number >=0", ue_enable_cmd},
+   {"cqi", "[UE] [CQI] -> UE=* for all, CQI=* for random", ue_cqi_set},
+   {"","",NULL},
+};
+telnetshell_vardef_t ue_status_vardef[] = {
+  {"", 0, NULL}
+};
+
+
 
 #define FRAME_PERIOD    100000000ULL
 #define DAQ_PERIOD      66667ULL
@@ -969,6 +1018,10 @@ static void *UE_phy_stub_single_thread_rxn_txnp4(void *arg)
     exit_fun("nothing to add");
   }
 
+  add_telnetcmd_func_t addcmd = (add_telnetcmd_func_t)get_shlibmodule_fptr("telnetsrv", TELNET_ADDCMD_FNAME);
+  if (addcmd)
+    addcmd("enable", ue_status_vardef, ue_status_cmdarray);
+
   UE_rxtx_proc_t *proc = rtd->proc;
   // settings for nfapi-L2-emulator mode
   module_id_t ue_thread_id = rtd->ue_thread_id;
-- 
2.25.1

